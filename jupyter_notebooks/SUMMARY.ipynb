{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUMMARY notebook\n",
    "\n",
    "This notebook scans the directory in which it lives to find all jupyter notebooks (other than itself) in that directory. It then prints for every notebook it finds (1) a hyperlink to the notebook, and (2) the first cell (which is always markdown) of the notebook. This way you can read a nice, automatically generated summary of all the notebooks without having to open all of them. If you find a notebook that you want to explore further, you can simply click on its link to open it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "<hr style=\"height:10px; background-color: blue;\">\n",
       "\n",
       "cc-train_test(pid=5).ipynb [<a href=\"cc-train_test(pid=5).ipynb\" target= \"_blank\">local link</a>]  [<a href=\"https://github.com/rrtucci/SentenceAx/blob/master/jupyter_notebooks/cc-train_test(pid=5).ipynb\">github link</a>] 1/9\n",
       "\n",
       "# cc-train_test(pid=5)\n",
       "\n",
       "SentenceAx uses 2 NNs, one for task=\"ex\" and another for task=\"cc\". This notebook trains the fullly-fledged (not a warmup) NN for the task=\"cc\". \n",
       "\n",
       "After running this notebook, append the suffix \".best\" to the checkpoint file that it outputs.\n",
       "\n",
       "<hr style=\"height:10px; background-color: blue;\">\n",
       "\n",
       "ex-train_test(pid=1).ipynb [<a href=\"ex-train_test(pid=1).ipynb\" target= \"_blank\">local link</a>]  [<a href=\"https://github.com/rrtucci/SentenceAx/blob/master/jupyter_notebooks/ex-train_test(pid=1).ipynb\">github link</a>] 2/9\n",
       "\n",
       "# ex-train_test(pid=1)\n",
       "\n",
       "SentenceAx uses 2 NNs, one for task=\"ex\" and another for task=\"cc\". This notebook trains the fullly-fledged (not a warmup) NN for the task=\"ex\". \n",
       "\n",
       "After running this notebook, append the suffix \".best\" to the checkpoint file that it outputs.\n",
       "\n",
       "<hr style=\"height:10px; background-color: blue;\">\n",
       "\n",
       "global_variables.ipynb [<a href=\"global_variables.ipynb\" target= \"_blank\">local link</a>]  [<a href=\"https://github.com/rrtucci/SentenceAx/blob/master/jupyter_notebooks/global_variables.ipynb\">github link</a>] 3/9\n",
       "\n",
       "# Global Variables\n",
       "\n",
       "This notebook prints the global variables in the file `sax_globals.py`.\n",
       "\n",
       "<hr style=\"height:10px; background-color: blue;\">\n",
       "\n",
       "tensorboard_tips.ipynb [<a href=\"tensorboard_tips.ipynb\" target= \"_blank\">local link</a>]  [<a href=\"https://github.com/rrtucci/SentenceAx/blob/master/jupyter_notebooks/tensorboard_tips.ipynb\">github link</a>] 4/9\n",
       "\n",
       "# Tensorboard tips\n",
       "\n",
       "make sure you have done \n",
       "\n",
       "    pip install tensorboard\n",
       "\n",
       "To view Tensorboard in Jupyter cell after run is finished, do this\n",
       "\n",
       "\n",
       "    %reload_ext tensorboard\n",
       "    %tensorboard --logdir=logs/ex\n",
       "\n",
       "To view Tensorboard in browser after run is finished, open terminal and do this\n",
       "\n",
       "    tensorboard --logdir=logs/ex\n",
       "    \n",
       "or \n",
       "\n",
       "    tensorboard --logdir=logs/cc\n",
       "\n",
       "I prefer viewing in a browser because there's a bug in Windows when try to display tensorboard logs in a jupyter cell. If a folder named \".tensorboard-info\" exists, it must be deleted or it won't display.\n",
       "\n",
       "<hr style=\"height:10px; background-color: blue;\">\n",
       "\n",
       "warmup-cc-train_test(pid=5).ipynb [<a href=\"warmup-cc-train_test(pid=5).ipynb\" target= \"_blank\">local link</a>]  [<a href=\"https://github.com/rrtucci/SentenceAx/blob/master/jupyter_notebooks/warmup-cc-train_test(pid=5).ipynb\">github link</a>] 5/9\n",
       "\n",
       "# warmup cc-train_test(pid=5)\n",
       "\n",
       "SentenceAx uses 2 NNs, one for task=\"ex\" and another for task=\"cc\". This warmup notebook trains the NN for the task=\"cc\". \n",
       "\n",
       "The warmup NN has small sizes for everything so that it can be trained quickly but not accurately without GPU.\n",
       "\n",
       "After running this notebook, append the suffix \".best\" to the checkpoint file that it outputs.\n",
       "\n",
       "<hr style=\"height:10px; background-color: blue;\">\n",
       "\n",
       "warmup-ex-extract(pid=3).ipynb [<a href=\"warmup-ex-extract(pid=3).ipynb\" target= \"_blank\">local link</a>]  [<a href=\"https://github.com/rrtucci/SentenceAx/blob/master/jupyter_notebooks/warmup-ex-extract(pid=3).ipynb\">github link</a>] 6/9\n",
       "\n",
       "# warmup ex-extract(pid=3)\n",
       "\n",
       "This warmup notebook performs action=\"extract\". For this action, the computer does no cc splitting, only ex extraction. If you want the computer do both, split and extract, set the action to \"splitextract\".\n",
       "\n",
       "The notebook reads the file:\n",
       "\n",
       "`predicting/small_pred.txt`\n",
       "\n",
       "with 6 sentences we want to extract from, and it writes the file\n",
       "\n",
       "`predicting/small_pred_extract_ssents.txt`\n",
       "\n",
       "with the predictions (i.e., ssents= simple sentences extracted from the original sentences.)\n",
       "\n",
       "This notebook requires that you derive the ex and  cc  weights first by running the notebooks `warmup-ex-train_test(pid=1)` \n",
       "and `warmup-cc-train_test(pid=5)`.\n",
       "\n",
       "<hr style=\"height:10px; background-color: blue;\">\n",
       "\n",
       "warmup-ex-splitextract(pid=6).ipynb [<a href=\"warmup-ex-splitextract(pid=6).ipynb\" target= \"_blank\">local link</a>]  [<a href=\"https://github.com/rrtucci/SentenceAx/blob/master/jupyter_notebooks/warmup-ex-splitextract(pid=6).ipynb\">github link</a>] 7/9\n",
       "\n",
       "# warmup ex-splitextract(pid=6)\n",
       "\n",
       "This warmup notebook performs action=\"splitextract\". By setting split_only=False, we ask it to do both the cc splitting and the ex extraction.\n",
       "\n",
       "The notebook reads the file:\n",
       "\n",
       "`predicting/small_pred.txt`\n",
       "\n",
       "with 6 sentences we want to splitextract, and it writes the file\n",
       "\n",
       "`predicting/small_pred_splitextract_ssents.txt`\n",
       "\n",
       "with the predictions (i.e., ssents= simple sentences extracted from the original sentences.)\n",
       "\n",
       "This notebook requires that you derive the ex and  cc  weights first by running the notebooks `warmup-ex-train_test(pid=1)` \n",
       "and `warmup-cc-train_test(pid=5)`.\n",
       "\n",
       "<hr style=\"height:10px; background-color: blue;\">\n",
       "\n",
       "warmup-ex-splitextract(pid=6, split_only=True).ipynb [<a href=\"warmup-ex-splitextract(pid=6, split_only=True).ipynb\" target= \"_blank\">local link</a>]  [<a href=\"https://github.com/rrtucci/SentenceAx/blob/master/jupyter_notebooks/warmup-ex-splitextract(pid=6, split_only=True).ipynb\">github link</a>] 8/9\n",
       "\n",
       "# warmup ex-splitextract(pid=6, split_only=True)\n",
       "\n",
       "This warmup notebook performs action=\"splitextract\". By setting split_only=True, we ask it to do the cc splitting but not the ex extraction.\n",
       "\n",
       "The notebook reads the file:\n",
       "\n",
       "`predicting/small_pred.txt`\n",
       "\n",
       "with 6 sentences we want to split, and it writes the file\n",
       "\n",
       "`predicting/small_pred_split_ssents.txt`\n",
       "\n",
       "with the predictions (i.e., ssents= simple sentences extracted from the original sentences.)\n",
       "\n",
       "The warmup NN has small sizes for everything so that it can be trained quickly but not accurately without GPU.\n",
       "\n",
       "This notebook requires that you derive the ex and  cc  weights first by running the notebooks `warmup-ex-train_test(pid=1)` \n",
       "and `warmup-cc-train_test(pid=5)`.\n",
       "\n",
       "<hr style=\"height:10px; background-color: blue;\">\n",
       "\n",
       "warmup-ex-train_test(pid=1).ipynb [<a href=\"warmup-ex-train_test(pid=1).ipynb\" target= \"_blank\">local link</a>]  [<a href=\"https://github.com/rrtucci/SentenceAx/blob/master/jupyter_notebooks/warmup-ex-train_test(pid=1).ipynb\">github link</a>] 9/9\n",
       "\n",
       "# warmup ex-train_test(pid=1)\n",
       "\n",
       "SentenceAx uses 2 NNs, one for task=\"ex\" and another for task=\"cc\". This warmup notebook trains the NN for the task=\"ex\".\n",
       "\n",
       "The warmup NN has small sizes for everything so that it can be trained quickly but not accurately without GPU.\n",
       "\n",
       "After running this notebook, append the suffix \".best\" to the checkpoint file that it outputs."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Version: 2\n",
    "import os\n",
    "import json\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# the name of this file\n",
    "this_fname = 'SUMMARY.ipynb'\n",
    "fname_to_md = {}\n",
    "for fname in sorted([x for x in os.listdir('./')]):\n",
    "    if fname[-6:] == '.ipynb'  and fname != this_fname:\n",
    "        # print('------------', fname)\n",
    "        with open(fname, 'r', encoding=\"utf-8\") as f:\n",
    "            fdata = json.load(f)\n",
    "            fname_to_md[fname] = ''.join(fdata['cells'][0]['source'])\n",
    "# print(fname_to_md)\n",
    "pre_sep = '\\n\\n<hr style=\"height:10px; background-color: blue;\">\\n\\n'\n",
    "full_md = ''\n",
    "k = 1\n",
    "num_nb = len(fname_to_md)\n",
    "project_name =\"SentenceAx\"\n",
    "who =\"rrtucci\"\n",
    "where = \"jupyter_notebooks\"\n",
    "for fname, md in fname_to_md.items():\n",
    "    sep = pre_sep\n",
    "    local_link = f' [<a href=\"{fname}\" target= \"_blank\">local link</a>] '\n",
    "    github_link = f' [<a href=\"https://github.com/{who}/{project_name}/blob/master/{where}/' +\\\n",
    "        f'{fname}\">github link</a>] '\n",
    "    sep += fname + local_link + github_link + str(k) + '/' + str(num_nb) + '\\n\\n'\n",
    "    full_md += sep + md\n",
    "    k += 1\n",
    "display(Markdown(full_md))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
