{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUMMARY notebook\n",
    "\n",
    "This notebook scans the directory in which it lives to find all jupyter notebooks (other than itself) in that directory. It then prints for every notebook it finds (1) a hyperlink to the notebook, and (2) the first cell (which is always markdown) of the notebook. This way you can read a nice, automatically generated summary of all the notebooks without having to open all of them. If you find a notebook that you want to explore further, you can simply click on its link to open it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "<hr style=\"height:10px; background-color: blue;\">\n",
       "\n",
       "cc-train_test(pid=5)-warmup.ipynb [<a href=\"cc-train_test(pid=5)-warmup.ipynb\" target= \"_blank\">local link</a>]  [<a href=\"https://nbviewer.org/github/rrtucci/scumpy/blob/master/jupyter_notebooks/cc-train_test(pid=5)-warmup.ipynb\" target= \"_blank\">web link</a>] 1/8\n",
       "\n",
       "# cc-train_test(pid=5) warmup\n",
       "\n",
       "SentenceAx uses 2 NNs, one for task=\"ex\" and another for task=\"cc\". This warmup notebook trains the NN for the task=\"cc\". \n",
       "\n",
       "The warmup NN has small sizes for everything so that it can be trained quickly but not accurately without GPU.\n",
       "\n",
       "After running this notebook, append the suffix \".best\" to the checkpoint file that it outputs.\n",
       "\n",
       "<hr style=\"height:10px; background-color: blue;\">\n",
       "\n",
       "cc-train_test(pid=5).ipynb [<a href=\"cc-train_test(pid=5).ipynb\" target= \"_blank\">local link</a>]  [<a href=\"https://nbviewer.org/github/rrtucci/scumpy/blob/master/jupyter_notebooks/cc-train_test(pid=5).ipynb\" target= \"_blank\">web link</a>] 2/8\n",
       "\n",
       "# cc-train_test(pid=5)\n",
       "\n",
       "SentenceAx uses 2 NNs, one for task=\"ex\" and another for task=\"cc\". This notebook trains the fullly-fledged (not a warmup) NN for the task=\"cc\". \n",
       "\n",
       "After running this notebook, append the suffix \".best\" to the checkpoint file that it outputs.\n",
       "\n",
       "<hr style=\"height:10px; background-color: blue;\">\n",
       "\n",
       "ex-extract(pid=3)-warmup.ipynb [<a href=\"ex-extract(pid=3)-warmup.ipynb\" target= \"_blank\">local link</a>]  [<a href=\"https://nbviewer.org/github/rrtucci/scumpy/blob/master/jupyter_notebooks/ex-extract(pid=3)-warmup.ipynb\" target= \"_blank\">web link</a>] 3/8\n",
       "\n",
       "# ex-extract(pid=3) warmup\n",
       "\n",
       "This warmup notebook performs action=\"extract\". For this action, the computer does no cc splitting, only ex extraction. If you want the computer do both, split and extract, set the action to \"splitextract\".\n",
       "\n",
       "The notebook reads the file:\n",
       "\n",
       "`predicting/small_pred.txt`\n",
       "\n",
       "with 6 sentences we want to extract from, and it writes the file\n",
       "\n",
       "`predicting/small_pred_extract_ssents.txt`\n",
       "\n",
       "with the predictions (i.e., ssents= simple sentences extracted from the original sentences.)\n",
       "\n",
       "This notebook requires that you derive the ex and  cc  weights first by running the notebooks `ex-train_test(pid=1)-warmup` \n",
       "and `cc-train_test(pid=5)-warmup`.\n",
       "\n",
       "<hr style=\"height:10px; background-color: blue;\">\n",
       "\n",
       "ex-splitextract(pid=6)-warmup.ipynb [<a href=\"ex-splitextract(pid=6)-warmup.ipynb\" target= \"_blank\">local link</a>]  [<a href=\"https://nbviewer.org/github/rrtucci/scumpy/blob/master/jupyter_notebooks/ex-splitextract(pid=6)-warmup.ipynb\" target= \"_blank\">web link</a>] 4/8\n",
       "\n",
       "# ex-splitextract(pid=6) warmup\n",
       "\n",
       "This warmup notebook performs action=\"splitextract\". By setting split_only=False, we ask it to do both the cc splitting and the ex extraction.\n",
       "\n",
       "The notebook reads the file:\n",
       "\n",
       "`predicting/small_pred.txt`\n",
       "\n",
       "with 6 sentences we want to splitextract, and it writes the file\n",
       "\n",
       "`predicting/small_pred_splitextract_ssents.txt`\n",
       "\n",
       "with the predictions (i.e., ssents= simple sentences extracted from the original sentences.)\n",
       "\n",
       "This notebook requires that you derive the ex and  cc  weights first by running the notebooks `ex-train_test(pid=1)-warmup` \n",
       "and `cc-train_test(pid=5)-warmup`.\n",
       "\n",
       "<hr style=\"height:10px; background-color: blue;\">\n",
       "\n",
       "ex-splitextract(pid=6, split_only=true)-warmup.ipynb [<a href=\"ex-splitextract(pid=6, split_only=true)-warmup.ipynb\" target= \"_blank\">local link</a>]  [<a href=\"https://nbviewer.org/github/rrtucci/scumpy/blob/master/jupyter_notebooks/ex-splitextract(pid=6, split_only=true)-warmup.ipynb\" target= \"_blank\">web link</a>] 5/8\n",
       "\n",
       "# ex-splitextract(pid=6, split_only=True) warmup\n",
       "\n",
       "This warmup notebook performs action=\"splitpredict\". By setting split_only=True, we ask it to do the cc splitting but not the ex extraction.\n",
       "\n",
       "The notebook reads the file:\n",
       "\n",
       "`predicting/small_pred.txt`\n",
       "\n",
       "with 6 sentences we want to split, and it writes the file\n",
       "\n",
       "`predicting/small_pred_split_ssents.txt`\n",
       "\n",
       "with the predictions (i.e., ssents= simple sentences extracted from the original sentences.)\n",
       "\n",
       "The warmup NN has small sizes for everything so that it can be trained quickly but not accurately without GPU.\n",
       "\n",
       "This notebook requires that you derive the ex and  cc  weights first by running the notebooks `ex-train_test(pid=1)-warmup` \n",
       "and `cc-train_test(pid=5)-warmup`.\n",
       "\n",
       "<hr style=\"height:10px; background-color: blue;\">\n",
       "\n",
       "ex-train_test(pid=1)-warmup.ipynb [<a href=\"ex-train_test(pid=1)-warmup.ipynb\" target= \"_blank\">local link</a>]  [<a href=\"https://nbviewer.org/github/rrtucci/scumpy/blob/master/jupyter_notebooks/ex-train_test(pid=1)-warmup.ipynb\" target= \"_blank\">web link</a>] 6/8\n",
       "\n",
       "# ex-train_test(pid=1) warmup\n",
       "\n",
       "SentenceAx uses 2 NNs, one for task=\"ex\" and another for task=\"cc\". This warmup notebook trains the NN for the task=\"ex\".\n",
       "\n",
       "The warmup NN has small sizes for everything so that it can be trained quickly but not accurately without GPU.\n",
       "\n",
       "After running this notebook, append the suffix \".best\" to the checkpoint file that it outputs.\n",
       "\n",
       "<hr style=\"height:10px; background-color: blue;\">\n",
       "\n",
       "ex-train_test(pid=1).ipynb [<a href=\"ex-train_test(pid=1).ipynb\" target= \"_blank\">local link</a>]  [<a href=\"https://nbviewer.org/github/rrtucci/scumpy/blob/master/jupyter_notebooks/ex-train_test(pid=1).ipynb\" target= \"_blank\">web link</a>] 7/8\n",
       "\n",
       "# ex-train_test(pid=1)\n",
       "\n",
       "SentenceAx uses 2 NNs, one for task=\"ex\" and another for task=\"cc\". This notebook trains the fullly-fledged (not a warmup) NN for the task=\"ex\". \n",
       "\n",
       "After running this notebook, append the suffix \".best\" to the checkpoint file that it outputs.\n",
       "\n",
       "<hr style=\"height:10px; background-color: blue;\">\n",
       "\n",
       "global_variables.ipynb [<a href=\"global_variables.ipynb\" target= \"_blank\">local link</a>]  [<a href=\"https://nbviewer.org/github/rrtucci/scumpy/blob/master/jupyter_notebooks/global_variables.ipynb\" target= \"_blank\">web link</a>] 8/8\n",
       "\n",
       "# Global Variables\n",
       "\n",
       "This notebook prints the global variables in the file `sax_globals.py`."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "\n",
    "# the name of this file\n",
    "this_fname = 'SUMMARY.ipynb'.lower()\n",
    "fname_to_md = {}\n",
    "for fname in sorted([x.lower() for x in os.listdir('./')]):\n",
    "    if fname[-6:] == '.ipynb'  and fname != this_fname:\n",
    "        # print('------------', fname)\n",
    "        with open(fname, 'r', encoding=\"utf-8\") as f:\n",
    "            fdata = json.load(f)\n",
    "            fname_to_md[fname] = ''.join(fdata['cells'][0]['source'])\n",
    "# print(fname_to_md)\n",
    "pre_sep = '\\n\\n<hr style=\"height:10px; background-color: blue;\">\\n\\n'\n",
    "full_md = ''\n",
    "k = 1\n",
    "num_nb = len(fname_to_md)\n",
    "for fname, md in fname_to_md.items():\n",
    "    sep = pre_sep\n",
    "    link = ' [<a href=\"' +\\\n",
    "        fname + '\" target= \"_blank\">' + 'local link' + '</a>] '\n",
    "    web_link = ' [<a href=\"https://nbviewer.org/github/rrtucci/scumpy/blob/master/jupyter_notebooks/' +\\\n",
    "        fname + '\" target= \"_blank\">' + 'web link' + '</a>] '\n",
    "    sep += fname + link + web_link + str(k) + '/' + str(num_nb) + '\\n\\n'\n",
    "    full_md += sep + md\n",
    "    k += 1\n",
    "display(Markdown(full_md))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
