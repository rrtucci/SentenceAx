{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a21bfe53-38da-4383-8f22-72a6612a24f0",
   "metadata": {},
   "source": [
    "# cc-train_test(pid=5) warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9e3a604-724d-4fa1-bdc1-486cc8322d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/SentenceAx\n"
     ]
    }
   ],
   "source": [
    "# this makes sure it starts looking for things from the SentenceAx folder down.\n",
    "import os\n",
    "import sys\n",
    "os.chdir('../')\n",
    "sys.path.insert(0,os.getcwd())\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "752f3d00-67db-4e93-bf08-7169fe092e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(os.environ[\"TOKENIZERS_PARALLELISM\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91bf119f-ae39-4070-b9b3-c5cfe13b0a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightning version is 2.1.0 so it is >= 2.0.1 as required.\n",
      "SEED= 777\n"
     ]
    }
   ],
   "source": [
    "from Params import *\n",
    "from ActionConductor import *\n",
    "\n",
    "\n",
    "def main(pid):\n",
    "    params = Params(pid)\n",
    "    params.d[\"refresh_cache\"] = True\n",
    "    params.d[\"gpus\"] = 0\n",
    "    params.d[\"batch_size\"] = 4\n",
    "    params.d[\"num_epochs\"] = 3\n",
    "    params.d[\"num_steps_per_epoch\"] = 3\n",
    "    params.d[\"model_str\"] = \"bert-base-cased\"\n",
    "    params.describe_self()\n",
    "    \n",
    "    # in sax_globals.py file, \n",
    "    # set CCTAGS_TRAIN_FP = \"tests/small_cctags.txt\" for this warmup run\n",
    "    print(\"CCTAGS_TRAIN_FP=\", CCTAGS_TRAIN_FP)\n",
    "    \n",
    "    conductor = ActionConductor(params, verbose=True)\n",
    "    conductor.delete_all_checkpoints()\n",
    "    print(\"checkpoints:\", conductor.get_all_checkpoint_fp())\n",
    "    conductor.run()\n",
    "    print(\"checkpoints:\", conductor.get_all_checkpoint_fp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfed0d9d-76ea-4231-9fab-1e8d0e9b5a67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************** new params\n",
      "new params: pid=5, task='cc', action='train_test'\n",
      "params=\n",
      "{'accumulate_grad_batches': 1,\n",
      " 'action': 'train_test',\n",
      " 'batch_size': 4,\n",
      " 'best_checkpoint_fp': '',\n",
      " 'con_weight_str': '1',\n",
      " 'do_rescoring': False,\n",
      " 'dropout_fun': 0.0,\n",
      " 'gpus': 0,\n",
      " 'gradient_clip_val': 5,\n",
      " 'lr': 2e-05,\n",
      " 'model_str': 'bert-base-cased',\n",
      " 'num_epochs': 3,\n",
      " 'num_extractions': 5,\n",
      " 'num_iterative_layers': 2,\n",
      " 'num_steps_per_epoch': 3,\n",
      " 'optimizer': 'adamW',\n",
      " 'refresh_cache': True,\n",
      " 'save_k': 1,\n",
      " 'task': 'cc',\n",
      " 'val_check_interval': 1.0,\n",
      " 'verbose': False,\n",
      " 'wreg': 0,\n",
      " 'write_allen_file': True,\n",
      " 'write_extags_file': True}\n",
      "CCTAGS_TRAIN_FP= tests/small_cctags.txt\n",
      "\n",
      "MInput started reading 'tests/small_cctags.txt'\n",
      "...\n",
      "1. Line 16 has no valid extractions.\n",
      "2. Line 111 has no valid extractions.\n",
      "3. Line 116 has no valid extractions.\n",
      "4. Line 246 has no valid extractions.\n",
      "5. Line 251 has no valid extractions.\n",
      "6. Line 311 has no valid extractions.\n",
      "7. Line 316 has no valid extractions.\n",
      "8. Line 321 has no valid extractions.\n",
      "9. Line 461 has no valid extractions.\n",
      "10. Line 516 has no valid extractions.\n",
      "11. Line 591 has no valid extractions.\n",
      "12. Line 911 has no valid extractions.\n",
      "13. Line 946 has no valid extractions.\n",
      "MInput finished reading 'tests/small_cctags.txt'\n",
      "number of lines= 995\n",
      "number of used samples=  186\n",
      "number of omitted samples=  13\n",
      "\n",
      "\n",
      "MInput started reading 'input_data/openie-data/ptb-dev.labels'\n",
      "...\n",
      "1. Line 16 has no valid extractions.\n",
      "2. Line 111 has no valid extractions.\n",
      "3. Line 116 has no valid extractions.\n",
      "4. Line 246 has no valid extractions.\n",
      "5. Line 251 has no valid extractions.\n",
      "6. Line 311 has no valid extractions.\n",
      "7. Line 316 has no valid extractions.\n",
      "8. Line 321 has no valid extractions.\n",
      "9. Line 461 has no valid extractions.\n",
      "10. Line 516 has no valid extractions.\n",
      "11. Line 591 has no valid extractions.\n",
      "12. Line 911 has no valid extractions.\n",
      "13. Line 946 has no valid extractions.\n",
      "14. Line 1021 has no valid extractions.\n",
      "15. Line 1061 has no valid extractions.\n",
      "16. Line 1106 has no valid extractions.\n",
      "17. Line 1161 has no valid extractions.\n",
      "18. Line 1181 has no valid extractions.\n",
      "19. Line 1206 has no valid extractions.\n",
      "20. Line 1226 has no valid extractions.\n",
      "21. Line 1236 has no valid extractions.\n",
      "22. Line 1241 has no valid extractions.\n",
      "23. Line 1286 has no valid extractions.\n",
      "24. Line 1291 has no valid extractions.\n",
      "25. Line 1306 has > 100 words. length=117\n",
      "[It would like to peg the ceiling on Federal Housing Administ]\n",
      "26. Line 1356 has no valid extractions.\n",
      "27. Line 1366 has no valid extractions.\n",
      "28. Line 1381 has no valid extractions.\n",
      "29. Line 1501 has no valid extractions.\n",
      "30. Line 1526 has no valid extractions.\n",
      "31. Line 1541 has no valid extractions.\n",
      "32. Line 1561 has no valid extractions.\n",
      "33. Line 1571 has no valid extractions.\n",
      "34. Line 1621 has no valid extractions.\n",
      "35. Line 1631 has no valid extractions.\n",
      "36. Line 1696 has no valid extractions.\n",
      "37. Line 1766 has no valid extractions.\n",
      "38. Line 1796 has no valid extractions.\n",
      "39. Line 1806 has no valid extractions.\n",
      "40. Line 1841 has no valid extractions.\n",
      "41. Line 1881 has no valid extractions.\n",
      "42. Line 1961 has no valid extractions.\n",
      "43. Line 1976 has no valid extractions.\n",
      "44. Line 1996 has no valid extractions.\n",
      "45. Line 2011 has no valid extractions.\n",
      "46. Line 2026 has no valid extractions.\n",
      "47. Line 2121 has no valid extractions.\n",
      "48. Line 2151 has no valid extractions.\n",
      "49. Line 2191 has no valid extractions.\n",
      "50. Line 2246 has no valid extractions.\n",
      "51. Line 2431 has no valid extractions.\n",
      "52. Line 2446 has no valid extractions.\n",
      "53. Line 2561 has no valid extractions.\n",
      "54. Line 2571 has no valid extractions.\n",
      "55. Line 2661 has no valid extractions.\n",
      "56. Line 2791 has no valid extractions.\n",
      "57. Line 2796 has no valid extractions.\n",
      "58. Line 2801 has no valid extractions.\n",
      "59. Line 3011 has no valid extractions.\n",
      "60. Line 3026 has no valid extractions.\n",
      "61. Line 3211 has no valid extractions.\n",
      "62. Line 3246 has no valid extractions.\n",
      "63. Line 3301 has no valid extractions.\n",
      "64. Line 3306 has no valid extractions.\n",
      "65. Line 3311 has no valid extractions.\n",
      "66. Line 3341 has no valid extractions.\n",
      "67. Line 3376 has no valid extractions.\n",
      "68. Line 3616 has no valid extractions.\n",
      "69. Line 3641 has no valid extractions.\n",
      "70. Line 3671 has no valid extractions.\n",
      "MInput finished reading 'input_data/openie-data/ptb-dev.labels'\n",
      "number of lines= 3710\n",
      "number of used samples=  672\n",
      "number of omitted samples=  70\n",
      "\n",
      "\n",
      "MInput started reading 'input_data/openie-data/ptb-test.labels'\n",
      "...\n",
      "1. Line 1 has no valid extractions.\n",
      "2. Line 46 has no valid extractions.\n",
      "3. Line 91 has no valid extractions.\n",
      "4. Line 131 has no valid extractions.\n",
      "5. Line 136 has no valid extractions.\n",
      "6. Line 156 has no valid extractions.\n",
      "7. Line 161 has no valid extractions.\n",
      "8. Line 296 has no valid extractions.\n",
      "9. Line 321 has no valid extractions.\n",
      "10. Line 356 has no valid extractions.\n",
      "11. Line 361 has no valid extractions.\n",
      "12. Line 496 has no valid extractions.\n",
      "13. Line 611 has no valid extractions.\n",
      "14. Line 656 has no valid extractions.\n",
      "15. Line 686 has no valid extractions.\n",
      "16. Line 751 has no valid extractions.\n",
      "17. Line 846 has no valid extractions.\n",
      "18. Line 851 has no valid extractions.\n",
      "19. Line 856 has no valid extractions.\n",
      "20. Line 901 has no valid extractions.\n",
      "21. Line 906 has no valid extractions.\n",
      "22. Line 951 has no valid extractions.\n",
      "23. Line 1081 has no valid extractions.\n",
      "24. Line 1151 has no valid extractions.\n",
      "25. Line 1166 has no valid extractions.\n",
      "26. Line 1171 has no valid extractions.\n",
      "27. Line 1186 has no valid extractions.\n",
      "28. Line 1201 has no valid extractions.\n",
      "29. Line 1241 has no valid extractions.\n",
      "30. Line 1276 has no valid extractions.\n",
      "31. Line 1286 has no valid extractions.\n",
      "32. Line 1291 has no valid extractions.\n",
      "33. Line 1796 has no valid extractions.\n",
      "34. Line 1891 has no valid extractions.\n",
      "35. Line 1981 has no valid extractions.\n",
      "36. Line 1986 has no valid extractions.\n",
      "37. Line 2016 has no valid extractions.\n",
      "38. Line 2031 has no valid extractions.\n",
      "39. Line 2046 has no valid extractions.\n",
      "40. Line 2066 has no valid extractions.\n",
      "41. Line 2096 has no valid extractions.\n",
      "42. Line 2101 has no valid extractions.\n",
      "43. Line 2141 has no valid extractions.\n",
      "44. Line 2216 has no valid extractions.\n",
      "45. Line 2236 has no valid extractions.\n",
      "46. Line 2261 has no valid extractions.\n",
      "47. Line 2271 has no valid extractions.\n",
      "48. Line 2296 has no valid extractions.\n",
      "49. Line 2301 has no valid extractions.\n",
      "50. Line 2376 has no valid extractions.\n",
      "51. Line 2386 has no valid extractions.\n",
      "52. Line 2391 has no valid extractions.\n",
      "53. Line 2446 has no valid extractions.\n",
      "54. Line 2466 has no valid extractions.\n",
      "55. Line 2551 has no valid extractions.\n",
      "56. Line 2571 has no valid extractions.\n",
      "57. Line 2586 has no valid extractions.\n",
      "58. Line 2711 has no valid extractions.\n",
      "59. Line 2721 has no valid extractions.\n",
      "60. Line 2761 has no valid extractions.\n",
      "61. Line 2791 has no valid extractions.\n",
      "62. Line 2966 has no valid extractions.\n",
      "63. Line 3011 has no valid extractions.\n",
      "64. Line 3086 has no valid extractions.\n",
      "65. Line 3136 has no valid extractions.\n",
      "66. Line 3186 has no valid extractions.\n",
      "67. Line 3226 has no valid extractions.\n",
      "68. Line 3251 has no valid extractions.\n",
      "69. Line 3271 has no valid extractions.\n",
      "70. Line 3276 has no valid extractions.\n",
      "71. Line 3286 has no valid extractions.\n",
      "72. Line 3331 has no valid extractions.\n",
      "73. Line 3356 has no valid extractions.\n",
      "74. Line 3411 has no valid extractions.\n",
      "75. Line 3416 has no valid extractions.\n",
      "76. Line 3451 has no valid extractions.\n",
      "77. Line 3581 has no valid extractions.\n",
      "78. Line 3626 has no valid extractions.\n",
      "79. Line 3656 has no valid extractions.\n",
      "80. Line 3661 has no valid extractions.\n",
      "81. Line 3671 has no valid extractions.\n",
      "82. Line 3766 has no valid extractions.\n",
      "83. Line 3776 has no valid extractions.\n",
      "84. Line 3841 has no valid extractions.\n",
      "85. Line 3856 has no valid extractions.\n",
      "86. Line 3861 has no valid extractions.\n",
      "87. Line 3911 has no valid extractions.\n",
      "88. Line 3921 has no valid extractions.\n",
      "89. Line 3936 has no valid extractions.\n",
      "90. Line 3946 has no valid extractions.\n",
      "91. Line 3976 has no valid extractions.\n",
      "92. Line 4006 has no valid extractions.\n",
      "93. Line 4011 has no valid extractions.\n",
      "94. Line 4021 has no valid extractions.\n",
      "95. Line 4036 has no valid extractions.\n",
      "96. Line 4106 has no valid extractions.\n",
      "97. Line 4146 has no valid extractions.\n",
      "98. Line 4176 has no valid extractions.\n",
      "99. Line 4196 has no valid extractions.\n",
      "100. Line 4266 has no valid extractions.\n",
      "101. Line 4311 has no valid extractions.\n",
      "102. Line 4366 has no valid extractions.\n",
      "103. Line 4376 has no valid extractions.\n",
      "104. Line 4391 has no valid extractions.\n",
      "105. Line 4576 has no valid extractions.\n",
      "106. Line 4701 has no valid extractions.\n",
      "107. Line 4736 has no valid extractions.\n",
      "108. Line 4766 has no valid extractions.\n",
      "109. Line 4786 has no valid extractions.\n",
      "110. Line 4846 has no valid extractions.\n",
      "111. Line 4856 has no valid extractions.\n",
      "112. Line 4871 has no valid extractions.\n",
      "MInput finished reading 'input_data/openie-data/ptb-test.labels'\n",
      "number of lines= 4925\n",
      "number of used samples=  873\n",
      "number of omitted samples=  112\n",
      "\n",
      "checkpoints: []\n",
      "****** model name=  train\n",
      "hidden size= 768\n",
      "num_iterative_layers=  2\n",
      "num_encoder_layers=  10\n",
      "total num layers=  12\n",
      "iterative_transformer= ModuleList(\n",
      "  (0-1): 2 x BertLayer(\n",
      "    (attention): BertAttention(\n",
      "      (self): BertSelfAttention(\n",
      "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (output): BertSelfOutput(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (intermediate): BertIntermediate(\n",
      "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (intermediate_act_fn): GELUActivation()\n",
      "    )\n",
      "    (output): BertOutput(\n",
      "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "CCMetric deleting previous pkl files.\n",
      "Retiring current log file by changing its name\n",
      "logs/cc/train_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name                  | Type             | Params\n",
      "-----------------------------------------------------------\n",
      "0 | start_model           | BertModel        | 94.1 M\n",
      "1 | iterative_transformer | ModuleList       | 14.2 M\n",
      "2 | dropout_fun           | Dropout          | 0     \n",
      "3 | embedding             | Embedding        | 76.8 K\n",
      "4 | merge_layer           | Linear           | 230 K \n",
      "5 | ilabelling_layer      | Linear           | 1.8 K \n",
      "6 | loss_fun              | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------------------\n",
      "108 M     Trainable params\n",
      "0         Non-trainable params\n",
      "108 M     Total params\n",
      "434.478   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22d2841d41cb41cf9a85256e170f2ed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering Model.training_step method, batch_idx=0\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 85])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 85, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 64, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 64, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 64, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 64, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 64, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 64, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 64, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 64, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 64, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 64, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 64, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 64, 6])\n",
      "len(llll_word_score)= 3\n",
      "llll_word_score[0].shape torch.Size([4, 64, 6])\n",
      "Entering Model.training_step method, batch_idx=1\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 85])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 85, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 64, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 64, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 64, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 64, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 64, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 64, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 64, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 64, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 64, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 64, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 64, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 64, 6])\n",
      "len(llll_word_score)= 3\n",
      "llll_word_score[0].shape torch.Size([4, 64, 6])\n",
      "Entering Model.training_step method, batch_idx=2\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 85])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 85, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 64, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 64, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 64, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 64, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 64, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 64, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 64, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 64, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 64, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 64, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 64, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 64, 6])\n",
      "len(llll_word_score)= 3\n",
      "llll_word_score[0].shape torch.Size([4, 64, 6])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering Model.validation_step method, batch_idx=0\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 115])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 115, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 68, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 68, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 68, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 68, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 68, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 68, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 68, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 68, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 68, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 68, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 68, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 68, 6])\n",
      "len(llll_word_score)= 3\n",
      "llll_word_score[0].shape torch.Size([4, 68, 6])\n",
      "Entering Model.validation_step method, batch_idx=1\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 115])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 115, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 68, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 68, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 68, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 68, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 68, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 68, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 68, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 68, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 68, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 68, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 68, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 68, 6])\n",
      "len(llll_word_score)= 3\n",
      "llll_word_score[0].shape torch.Size([4, 68, 6])\n",
      "Entering Model.validation_step method, batch_idx=2\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 115])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 115, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 68, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 68, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 68, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 68, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 68, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 68, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 68, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 68, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 68, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 68, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 68, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 68, 6])\n",
      "len(llll_word_score)= 3\n",
      "llll_word_score[0].shape torch.Size([4, 68, 6])\n",
      "Entering Model.on_validation_epoch_end method\n",
      "Entering CCMetric.__call__() method.\n",
      "number of samples= 4\n",
      "Entering CCMetric.__call__() method.\n",
      "number of samples= 4\n",
      "Entering CCMetric.__call__() method.\n",
      "number of samples= 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 3: 'epoch_acc' reached 0.23530 (best 0.23530), saving model to '/home/studio-lab-user/sagemaker-studiolab-notebooks/SentenceAx/weights/cc_model/epoch=00_epoch_acc=0.235.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering CCMetric.get_score_d method.\n",
      "\n",
      "Scores at end of epoch 0:\n",
      "{'F1_exact': 0.2353,\n",
      " 'F1_inner': 0.2353,\n",
      " 'F1_outer': 0.2353,\n",
      " 'F1_whole': 0.2353,\n",
      " 'P_exact': 1.0,\n",
      " 'R_exact': 0.1333,\n",
      " 'epoch_acc': 0.2353}\n",
      "Entering Model.training_step method, batch_idx=0\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 85])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 85, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 64, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 64, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 64, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 64, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 64, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 64, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 64, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 64, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 64, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 64, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 64, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 64, 6])\n",
      "len(llll_word_score)= 3\n",
      "llll_word_score[0].shape torch.Size([4, 64, 6])\n",
      "Entering Model.training_step method, batch_idx=1\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 85])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 85, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 64, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 64, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 64, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 64, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 64, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 64, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 64, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 64, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 64, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 64, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 64, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 64, 6])\n",
      "len(llll_word_score)= 3\n",
      "llll_word_score[0].shape torch.Size([4, 64, 6])\n",
      "Entering Model.training_step method, batch_idx=2\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 85])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 85, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 64, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 64, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 64, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 64, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 64, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 64, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 64, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 64, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 64, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 64, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 64, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 64, 6])\n",
      "len(llll_word_score)= 3\n",
      "llll_word_score[0].shape torch.Size([4, 64, 6])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering Model.validation_step method, batch_idx=0\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 115])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 115, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 68, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 68, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 68, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 68, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 68, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 68, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 68, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 68, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 68, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 68, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 68, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 68, 6])\n",
      "len(llll_word_score)= 3\n",
      "llll_word_score[0].shape torch.Size([4, 68, 6])\n",
      "Entering Model.validation_step method, batch_idx=1\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 115])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 115, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 68, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 68, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 68, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 68, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 68, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 68, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 68, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 68, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 68, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 68, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 68, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 68, 6])\n",
      "len(llll_word_score)= 3\n",
      "llll_word_score[0].shape torch.Size([4, 68, 6])\n",
      "Entering Model.validation_step method, batch_idx=2\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 115])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 115, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 68, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 68, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 68, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 68, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 68, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 68, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 68, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 68, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 68, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 68, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 68, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 68, 6])\n",
      "len(llll_word_score)= 3\n",
      "llll_word_score[0].shape torch.Size([4, 68, 6])\n",
      "Entering Model.on_validation_epoch_end method\n",
      "Entering CCMetric.__call__() method.\n",
      "number of samples= 4\n",
      "Entering CCMetric.__call__() method.\n",
      "number of samples= 4\n",
      "Entering CCMetric.__call__() method.\n",
      "number of samples= 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 6: 'epoch_acc' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering CCMetric.get_score_d method.\n",
      "\n",
      "Scores at end of epoch 1:\n",
      "{'F1_exact': 0.2353,\n",
      " 'F1_inner': 0.2353,\n",
      " 'F1_outer': 0.2353,\n",
      " 'F1_whole': 0.2353,\n",
      " 'P_exact': 1.0,\n",
      " 'R_exact': 0.1333,\n",
      " 'epoch_acc': 0.2353}\n",
      "Entering Model.training_step method, batch_idx=0\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 85])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 85, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 64, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 64, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 64, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 64, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 64, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 64, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 64, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 64, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 64, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 64, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 64, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 64, 6])\n",
      "len(llll_word_score)= 3\n",
      "llll_word_score[0].shape torch.Size([4, 64, 6])\n",
      "Entering Model.training_step method, batch_idx=1\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 85])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 85, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 64, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 64, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 64, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 64, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 64, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 64, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 64, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 64, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 64, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 64, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 64, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 64, 6])\n",
      "len(llll_word_score)= 3\n",
      "llll_word_score[0].shape torch.Size([4, 64, 6])\n",
      "Entering Model.training_step method, batch_idx=2\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 85])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 85, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 85, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 64, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 64, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 64, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 64, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 85, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 64, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 64, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 64, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 64, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 85, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 64, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 64, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 64, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 64, 6])\n",
      "len(llll_word_score)= 3\n",
      "llll_word_score[0].shape torch.Size([4, 64, 6])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering Model.validation_step method, batch_idx=0\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 115])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 115, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 68, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 68, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 68, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 68, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 68, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 68, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 68, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 68, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 68, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 68, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 68, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 68, 6])\n",
      "len(llll_word_score)= 3\n",
      "llll_word_score[0].shape torch.Size([4, 68, 6])\n",
      "Entering Model.validation_step method, batch_idx=1\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 115])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 115, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 68, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 68, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 68, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 68, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 68, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 68, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 68, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 68, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 68, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 68, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 68, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 68, 6])\n",
      "len(llll_word_score)= 3\n",
      "llll_word_score[0].shape torch.Size([4, 68, 6])\n",
      "Entering Model.validation_step method, batch_idx=2\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 115])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 115, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 115, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 68, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 68, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 68, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 68, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 115, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 68, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 68, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 68, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 68, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 115, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 68, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 68, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 68, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 68, 6])\n",
      "len(llll_word_score)= 3\n",
      "llll_word_score[0].shape torch.Size([4, 68, 6])\n",
      "Entering Model.on_validation_epoch_end method\n",
      "Entering CCMetric.__call__() method.\n",
      "number of samples= 4\n",
      "Entering CCMetric.__call__() method.\n",
      "number of samples= 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 9: 'epoch_acc' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering CCMetric.__call__() method.\n",
      "number of samples= 4\n",
      "Entering CCMetric.get_score_d method.\n",
      "\n",
      "Scores at end of epoch 2:\n",
      "{'F1_exact': 0.2353,\n",
      " 'F1_inner': 0.2353,\n",
      " 'F1_outer': 0.2353,\n",
      " 'F1_whole': 0.2353,\n",
      " 'P_exact': 1.0,\n",
      " 'R_exact': 0.1333,\n",
      " 'epoch_acc': 0.2353}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Restoring states from the checkpoint path at weights/cc_model/epoch=00_epoch_acc=0.235.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** model name=  test\n",
      "hidden size= 768\n",
      "num_iterative_layers=  2\n",
      "num_encoder_layers=  10\n",
      "total num layers=  12\n",
      "iterative_transformer= ModuleList(\n",
      "  (0-1): 2 x BertLayer(\n",
      "    (attention): BertAttention(\n",
      "      (self): BertSelfAttention(\n",
      "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (output): BertSelfOutput(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (intermediate): BertIntermediate(\n",
      "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (intermediate_act_fn): GELUActivation()\n",
      "    )\n",
      "    (output): BertOutput(\n",
      "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "CCMetric deleting previous pkl files.\n",
      "Retiring current log file by changing its name\n",
      "logs/cc/test_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded model weights from the checkpoint at weights/cc_model/epoch=00_epoch_acc=0.235.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c2d7465fc8342558b58d33ce56f2fab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering Model.test_step method, batch_idx=0\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 106])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 106, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 106, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 106, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 106, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 106, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 106, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 106, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 68, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 68, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 68, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 68, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 106, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 106, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 106, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 106, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 106, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 106, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 68, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 68, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 68, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 68, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 106, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 106, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 106, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 106, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 106, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 106, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 68, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 68, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 68, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 68, 6])\n",
      "len(llll_word_score)= 3\n",
      "llll_word_score[0].shape torch.Size([4, 68, 6])\n",
      "Entering Model.test_step method, batch_idx=1\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 106])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 106, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 106, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 106, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 106, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 106, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 106, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 106, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 68, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 68, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 68, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 68, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 106, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 106, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 106, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 106, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 106, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 106, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 68, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 68, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 68, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 68, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 106, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 106, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 106, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 106, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 106, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 106, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 68, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 68, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 68, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 68, 6])\n",
      "len(llll_word_score)= 3\n",
      "llll_word_score[0].shape torch.Size([4, 68, 6])\n",
      "Entering Model.test_step method, batch_idx=2\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 106])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 106, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 106, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 106, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 106, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 106, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 106, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 106, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 68, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 68, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 68, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 68, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 106, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 106, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 106, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 106, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 106, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 106, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 68, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 68, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 68, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 68, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 106, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 106, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 106, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 106, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 106, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 106, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 68, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 68, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 68, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 68, 6])\n",
      "len(llll_word_score)= 3\n",
      "llll_word_score[0].shape torch.Size([4, 68, 6])\n",
      "Entering Model.on_test_epoch_end method\n",
      "Entering CCMetric.__call__() method.\n",
      "number of samples= 4\n",
      "Entering CCMetric.__call__() method.\n",
      "number of samples= 4\n",
      "Entering CCMetric.__call__() method.\n",
      "number of samples= 4\n",
      "Entering CCMetric.get_score_d method.\n",
      "\n",
      "Scores at end of epoch 0:\n",
      "{'F1_exact': 0.0,\n",
      " 'F1_inner': 0.0,\n",
      " 'F1_outer': 0.0,\n",
      " 'F1_whole': 0.0,\n",
      " 'P_exact': 0.0,\n",
      " 'R_exact': 0.0,\n",
      " 'epoch_acc': 0.0}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         epoch_acc         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        loss_epoch         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        epoch_acc        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       loss_epoch        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints: ['weights/cc_model/epoch=00_epoch_acc=0.235.ckpt']\n"
     ]
    }
   ],
   "source": [
    "main(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "03e8ab015823425486408796acf26ec7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_37b8b1c23b7e4736a3abdf52e0fdf7ab",
       "max": 3,
       "style": "IPY_MODEL_80d6c54cff844208b8e872f5a0421921",
       "value": 3
      }
     },
     "098b80aefc1d429fbbebf0eea8517ddf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "0998eaa81c5347199c7c025f3ae6b365": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_75aac946eed84906a7dc0ab777933052",
       "style": "IPY_MODEL_28a74362057341179e4edac8fe8bc125",
       "value": " 3/3 [00:10&lt;00:00,  0.28it/s]"
      }
     },
     "15de23cca24a4c7b9c161242208c99d0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_a3ebb0ce3a234532af1c6376d03bd113",
       "style": "IPY_MODEL_afb462231bb5407f8463110677026f4e",
       "value": "Validation DataLoader 0: 100%"
      }
     },
     "1816714a849547d3967437cc0eddb2fb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "100%"
      }
     },
     "1c2d7465fc8342558b58d33ce56f2fab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_6aeaad442626412ca84e9d89444e4ed5",
        "IPY_MODEL_c4b0c9f6f2b54309828fc4e5cd7f16f3",
        "IPY_MODEL_7516d8a153c641db97bd172c1d337208"
       ],
       "layout": "IPY_MODEL_5567f3d43ad04fd2865ffd58fda59dda"
      }
     },
     "22d2841d41cb41cf9a85256e170f2ed3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_cd655336b8cd42ff882d356f0edd739d",
        "IPY_MODEL_03e8ab015823425486408796acf26ec7",
        "IPY_MODEL_70ffddfbd0734184b125a265b06c0255"
       ],
       "layout": "IPY_MODEL_1816714a849547d3967437cc0eddb2fb"
      }
     },
     "23d1982d38d04ebbb361c76f5fa3abca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "28a74362057341179e4edac8fe8bc125": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "2bbf2d3550574f379273e68a456fba85": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "37b8b1c23b7e4736a3abdf52e0fdf7ab": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "403e86190ec94f76874bc9ab4d039f07": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "43bf7c5b25f744ed87674ca8d9a38e71": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "4ad1fb58b32e49469515835757669d22": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "5567f3d43ad04fd2865ffd58fda59dda": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "100%"
      }
     },
     "5b9ccaea9bd646d2afc38905156663d2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "653a5f3fa0634b829f757f1dcbc79d78": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_2bbf2d3550574f379273e68a456fba85",
       "style": "IPY_MODEL_9c727f1c82654db6a0d0499c8adc87d0",
       "value": " 3/3 [00:07&lt;00:00,  0.39it/s]"
      }
     },
     "6aeaad442626412ca84e9d89444e4ed5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_d9b5328fa0de4733b6913815bb03aa93",
       "style": "IPY_MODEL_b7d7447580ef42ce93783048ddfb4d15",
       "value": "Testing DataLoader 0: 100%"
      }
     },
     "6ece0881182e4a7e95bc9c35747a224f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_a356b2b758f444419f508697b02b2357",
       "max": 3,
       "style": "IPY_MODEL_b02db2ff11144ddb9c91ed4a16d133bd",
       "value": 3
      }
     },
     "70ffddfbd0734184b125a265b06c0255": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_8b953b14dbd844a98309eaae6e2ee444",
       "style": "IPY_MODEL_5b9ccaea9bd646d2afc38905156663d2",
       "value": " 3/3 [00:18&lt;00:00,  0.16it/s, v_num=part, loss=5.040, loss_step=0.000, loss_epoch=0.000, epoch_acc=0.235]"
      }
     },
     "7516d8a153c641db97bd172c1d337208": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_b7fd6948ff444a169130c355b9f44135",
       "style": "IPY_MODEL_8769bcb28c4e4fd0ac8dae04ce452ee2",
       "value": " 3/3 [00:06&lt;00:00,  0.44it/s]"
      }
     },
     "75aac946eed84906a7dc0ab777933052": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7defbd5869de401e841fd39f2d5bc680": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_403e86190ec94f76874bc9ab4d039f07",
       "max": 3,
       "style": "IPY_MODEL_23d1982d38d04ebbb361c76f5fa3abca",
       "value": 3
      }
     },
     "80d6c54cff844208b8e872f5a0421921": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "8769bcb28c4e4fd0ac8dae04ce452ee2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "8b953b14dbd844a98309eaae6e2ee444": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "912e6eebe5164fd2843907b5f5fc59e7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "visibility": "hidden",
       "width": "100%"
      }
     },
     "9698af8c386c49e08f10edc0556256b5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "99012d625ffa44b981060b9876e23e2a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "9c727f1c82654db6a0d0499c8adc87d0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "a356b2b758f444419f508697b02b2357": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "a3ebb0ce3a234532af1c6376d03bd113": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ae4ffb9776c74b288c6b94bf4b82e9fa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "afb462231bb5407f8463110677026f4e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "b02db2ff11144ddb9c91ed4a16d133bd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "b7d7447580ef42ce93783048ddfb4d15": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "b7fd6948ff444a169130c355b9f44135": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bd30969c00d8408eb307051fce2b17d9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c04b025558f94fe1801a2762cfb47bef": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c2da8f5e8094429fa23aebd5a7c5127c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "visibility": "hidden",
       "width": "100%"
      }
     },
     "c4b0c9f6f2b54309828fc4e5cd7f16f3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_e8e8b2ee8e0e48b8957f56c5f4d10a18",
       "max": 3,
       "style": "IPY_MODEL_99012d625ffa44b981060b9876e23e2a",
       "value": 3
      }
     },
     "c63bf30ab47f4c8d9fdf792a02dc4601": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_9698af8c386c49e08f10edc0556256b5",
       "style": "IPY_MODEL_df4121e1ec3848cc8f1f0450f681ec03",
       "value": "Validation DataLoader 0: 100%"
      }
     },
     "c8c9468916624a118559f1fe40e888a1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_098b80aefc1d429fbbebf0eea8517ddf",
       "max": 3,
       "style": "IPY_MODEL_43bf7c5b25f744ed87674ca8d9a38e71",
       "value": 3
      }
     },
     "cd655336b8cd42ff882d356f0edd739d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_d1f8764499ba43a084520e4d7e62ab26",
       "style": "IPY_MODEL_ae4ffb9776c74b288c6b94bf4b82e9fa",
       "value": "Epoch 2: 100%"
      }
     },
     "d1f8764499ba43a084520e4d7e62ab26": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d473882c0ed1473a95962d259f759d54": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_c04b025558f94fe1801a2762cfb47bef",
       "style": "IPY_MODEL_fe6e484441a84c0b9a495caa0e51ff5e",
       "value": " 3/3 [00:08&lt;00:00,  0.37it/s]"
      }
     },
     "d732939e65494a2ab30d5c585068475e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "visibility": "hidden",
       "width": "100%"
      }
     },
     "d9b5328fa0de4733b6913815bb03aa93": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "df4121e1ec3848cc8f1f0450f681ec03": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "e8e8b2ee8e0e48b8957f56c5f4d10a18": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "f2b2474d8a9d46c4af64652fc086c66e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_bd30969c00d8408eb307051fce2b17d9",
       "style": "IPY_MODEL_4ad1fb58b32e49469515835757669d22",
       "value": "Validation DataLoader 0: 100%"
      }
     },
     "fe6e484441a84c0b9a495caa0e51ff5e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
