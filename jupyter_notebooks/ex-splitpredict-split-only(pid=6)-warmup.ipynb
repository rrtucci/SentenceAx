{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07c438f4-4a6c-48f1-be15-b60ad25888ca",
   "metadata": {},
   "source": [
    "# ex-splitprediction-split-only (pid=6) warmup\n",
    "\n",
    "This warmup notebook performs action=\"splitpredct\". By setting split_only=True, we ask it to do the cc splitting but not the ex extraction.\n",
    "\n",
    "The notebook reads the file:\n",
    "\n",
    "`predicting/small_pred.txt`\n",
    "\n",
    "with 6 sentences we want to split, and it writes the file\n",
    "\n",
    "`predicting/small_pred_split_ssents.txt`\n",
    "\n",
    "with the predictions (i.e., ssents= simple sentences extracted from the original sentences.)\n",
    "\n",
    "The warmup NN has small sizes for everything so that it can be trained quickly but not accurately without GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bdaa0e0-3004-4eaa-9877-bbca287eccd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rrtuc\\Desktop\\backed-up\\python-projects\\SentenceAx\n"
     ]
    }
   ],
   "source": [
    "# this makes sure it starts looking for things from the SentenceAx folder down.\n",
    "import os\n",
    "import sys\n",
    "os.chdir('../')\n",
    "sys.path.insert(0,os.getcwd())\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0f9fa23-d7c2-4c5a-a16f-38dfd02c2f89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(os.environ[\"TOKENIZERS_PARALLELISM\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf61af3b-4c82-4860-9641-e631e5107e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Params import *\n",
    "from ActionConductor import *\n",
    "\n",
    "\n",
    "def main(pid, pred_in_fp=None, split_only=False):\n",
    "    params = Params(pid)\n",
    "    params.d[\"refresh_cache\"] = True\n",
    "    params.d[\"gpus\"] = 0\n",
    "    params.d[\"batch_size\"] = 4\n",
    "    params.d[\"num_epochs\"] = 3\n",
    "    params.d[\"num_steps_per_epoch\"] = 3\n",
    "    params.d[\"model_str\"] = \"bert-base-cased\"\n",
    "    params.d[\"small_train\"] = True\n",
    "    params.describe_self()\n",
    "    \n",
    "    conductor = ActionConductor(params, verbose=True)\n",
    "    conductor.delete_all_checkpoints()\n",
    "    print(\"checkpoints:\", conductor.get_all_checkpoint_fp())\n",
    "    conductor.run(pred_in_fp, split_only)\n",
    "    print(\"checkpoints:\", conductor.get_all_checkpoint_fp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a2a9f60-9297-4129-8dd0-edc71196421d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************** new params\n",
      "new params: pid=6, task='ex', action='splitpredict'\n",
      "params=\n",
      "{'accumulate_grad_batches': 1,\n",
      " 'action': 'splitpredict',\n",
      " 'batch_size': 4,\n",
      " 'cc_weights_fp': 'weights/cc_epoch=28_eval_acc=0.854.ckpt',\n",
      " 'con_weight_str': '1',\n",
      " 'dropout_fun': 0.0,\n",
      " 'ex_weights_fp': 'weights/ex_epoch=14_eval_acc=0.551_v0.ckpt',\n",
      " 'gpus': 0,\n",
      " 'gradient_clip_val': 5,\n",
      " 'lr': 2e-05,\n",
      " 'model_str': 'bert-base-cased',\n",
      " 'num_epochs': 3,\n",
      " 'num_iterative_layers': 2,\n",
      " 'num_steps_per_epoch': 3,\n",
      " 'optimizer': 'adamW',\n",
      " 'refresh_cache': True,\n",
      " 'save_k': 1,\n",
      " 'small_train': True,\n",
      " 'task': 'ex',\n",
      " 'val_check_interval': 1.0,\n",
      " 'verbose': False,\n",
      " 'wreg': 0}\n",
      "lightning version is 2.1.0 so it is >= 2.0.1 as required.\n",
      "SEED= 777\n",
      "checkpoints: []\n",
      "Checkpoint keywords:\n",
      "dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'loops', 'callbacks', 'optimizer_states', 'lr_schedulers', 'hparams_name', 'hyper_parameters'])\n",
      "\n",
      "MInput started reading 'predicting/small_pred.txt'\n",
      "...\n",
      "MInput finished reading 'predicting/small_pred.txt'\n",
      "number of lines= 6\n",
      "number of used samples=  6\n",
      "number of omitted samples=  0\n",
      "\n",
      "self.hparams \"pi_test\": 3.14\n",
      "****** model name=  pred\n",
      "hidden size= 768\n",
      "num_iterative_layers=  2\n",
      "num_encoder_layers=  10\n",
      "total num layers=  12\n",
      "iterative_transformer= ModuleList(\n",
      "  (0): BertLayer(\n",
      "    (attention): BertAttention(\n",
      "      (self): BertSelfAttention(\n",
      "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (output): BertSelfOutput(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (intermediate): BertIntermediate(\n",
      "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (intermediate_act_fn): GELUActivation()\n",
      "    )\n",
      "    (output): BertOutput(\n",
      "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (1): BertLayer(\n",
      "    (attention): BertAttention(\n",
      "      (self): BertSelfAttention(\n",
      "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (output): BertSelfOutput(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (intermediate): BertIntermediate(\n",
      "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (intermediate_act_fn): GELUActivation()\n",
      "    )\n",
      "    (output): BertOutput(\n",
      "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "CCMetric deleting previous pkl files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Restoring states from the checkpoint path at weights/cc_model\\epoch=00_epoch_acc=0.235.ckpt.best\n",
      "Loaded model weights from the checkpoint at weights/cc_model\\epoch=00_epoch_acc=0.235.ckpt.best\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c263073f1aec41cbac3c2268aae86909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                                                  | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering Model.test_step method, batch_idx=0\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 49])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 49, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 49, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 49, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 49, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 49, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 49, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 49, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 42, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 42, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 42, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 42, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 49, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 49, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 49, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 49, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 49, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 49, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 42, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 42, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 42, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 42, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 49, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 49, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 49, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 49, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 49, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 49, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 42, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 42, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 42, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 42, 6])\n",
      "len(llll_word_score)= 3\n",
      "llll_word_score[0].shape torch.Size([4, 42, 6])\n",
      "Entering Model.test_step method, batch_idx=1\n",
      "\n",
      "ll_osent_icode.shape torch.Size([2, 49])\n",
      "after start_model, lll_hidden_state.shape torch.Size([2, 49, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([2, 49, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([2, 49, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([2, 49, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([2, 49, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([2, 49, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([2, 49, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([2, 42, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([2, 42, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([2, 42, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([2, 42, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([2, 49, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([2, 49, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([2, 49, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([2, 49, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([2, 49, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([2, 49, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([2, 42, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([2, 42, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([2, 42, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([2, 42, 6])\n",
      "len(llll_word_score)= 2\n",
      "llll_word_score[0].shape torch.Size([2, 42, 6])\n",
      "Entering Model.on_test_epoch_end method\n",
      "\n",
      "Scores at end of epoch 0:\n",
      "{'F1_exact': 0.0,\n",
      " 'F1_inner': 0.0,\n",
      " 'F1_outer': 0.0,\n",
      " 'F1_whole': 0.0,\n",
      " 'P_exact': 0.0,\n",
      " 'R_exact': 0.0,\n",
      " 'epoch_acc': 0.0}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         epoch_acc         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        loss_epoch         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        epoch_acc        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       loss_epoch        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time taken =  0.141295 minutes\n",
      "checkpoints: []\n"
     ]
    }
   ],
   "source": [
    "main(6, pred_in_fp=\"predicting/small_pred.txt\",\n",
    "     split_only=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "060d7bcb2f824491a39edb15104e9749": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "0792efe2d16544b7a1ffa7beabfcb002": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "0b633974f1fd4a3e9659c84d8aa3b750": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_1482f5a19dd7452aa636802bed758f45",
       "style": "IPY_MODEL_d90f2006d9304213971ff3d6b3c2057b",
       "value": "Validation DataLoader 0: 100%"
      }
     },
     "1482f5a19dd7452aa636802bed758f45": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "19d8772960a248ffab56208398e897df": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "1b90db9dbbf74c67b606cf0b2fc8655f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "215b4e40f89d4e5ba0e9be7f3ff627c6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "25e629289bd5471d8256e2aaa8d39970": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_e34e8f84a2b941ca83f486f2d96b555d",
       "style": "IPY_MODEL_215b4e40f89d4e5ba0e9be7f3ff627c6",
       "value": " 3/3 [00:02&lt;00:00,  1.30it/s]"
      }
     },
     "2d28a0c9a5eb41c0ba10445620d13af5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "100%"
      }
     },
     "2f0b594ad8a74c6ea57273389fa98174": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_f4931c98ae1f42c694716a6b7a0a1348",
       "max": 3,
       "style": "IPY_MODEL_39589f583f1c4339bd56e7574bec51f4",
       "value": 3
      }
     },
     "32360b80a00f4886a72eef7ac65a292b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "39589f583f1c4339bd56e7574bec51f4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "3e5aa2f441ce43bba9ac02fd70de4a62": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_b39662fed1a34f8d92c0cbcaadbd3aed",
        "IPY_MODEL_2f0b594ad8a74c6ea57273389fa98174",
        "IPY_MODEL_25e629289bd5471d8256e2aaa8d39970"
       ],
       "layout": "IPY_MODEL_ba6760cfa80c4e0281fc0e144ea6fd8f"
      }
     },
     "3ef9c27a109c42ee97f6367c6455d107": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "44f40484cb8a440fbf184baed4f21c40": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_7f356c0dcc1645b09df55131e0ee71a4",
       "style": "IPY_MODEL_8463aa09a44c4833a043c3c9c7661efe",
       "value": "Validation DataLoader 0: 100%"
      }
     },
     "48e12fcf0c774d709dcc7cbc8fae7b45": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "583aacc6eb534dd8af6d79d79ddabdaa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_7112d7c10a7b407789e5deb5ffa52526",
       "style": "IPY_MODEL_48e12fcf0c774d709dcc7cbc8fae7b45",
       "value": " 3/3 [00:03&lt;00:00,  0.88it/s]"
      }
     },
     "65a7fe683e43463bbcb4bc892767d508": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_dbc77a3380b54847b76d5d730b670630",
        "IPY_MODEL_ec26617e10584ebda2d75dfe60fc431e",
        "IPY_MODEL_a83e28e1b659461ea9dd94031a9fde8f"
       ],
       "layout": "IPY_MODEL_2d28a0c9a5eb41c0ba10445620d13af5"
      }
     },
     "660030051de94766bbf3979eea5729f9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6afc6696947b44b1a8acf1aa0579c1f0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "6b774c617b2945b7b3e024c11ab876bc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "visibility": "hidden",
       "width": "100%"
      }
     },
     "7112d7c10a7b407789e5deb5ffa52526": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "741e835a3f004fefaa47a51d913886e7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "79883f345ad0472c99d17b3eaf931e06": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "79989c66782447168c40856840bff186": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "7f356c0dcc1645b09df55131e0ee71a4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8463aa09a44c4833a043c3c9c7661efe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "8c008a62d114492e87397e002fe7b393": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "8cc213b41717445ea1e6b1ba93bfc5e5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "8db1a154aa8d43b28cd979d826fad424": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_f8e544e0219247769dcc9d99cb2c450d",
       "style": "IPY_MODEL_8cc213b41717445ea1e6b1ba93bfc5e5",
       "value": "Validation DataLoader 0: 100%"
      }
     },
     "92980f7ac1814e4197b67f41e5d8fa30": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "95abba42ebd14ed1832762c4f270a68c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "a83e28e1b659461ea9dd94031a9fde8f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_741e835a3f004fefaa47a51d913886e7",
       "style": "IPY_MODEL_19d8772960a248ffab56208398e897df",
       "value": " 3/3 [00:09&lt;00:00,  0.30it/s, v_num=part, loss=8.050, loss_step=0.000, loss_epoch=0.000, epoch_acc=0.0057]"
      }
     },
     "adaca67d22e448449dc709dc1f8d0e6d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_6afc6696947b44b1a8acf1aa0579c1f0",
       "max": 3,
       "style": "IPY_MODEL_060d7bcb2f824491a39edb15104e9749",
       "value": 3
      }
     },
     "b39662fed1a34f8d92c0cbcaadbd3aed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_1b90db9dbbf74c67b606cf0b2fc8655f",
       "style": "IPY_MODEL_cdb9480c90014bd29fb52d2a0f0e1e89",
       "value": "Testing DataLoader 0: 100%"
      }
     },
     "b824f79e603a4f718cd8bee4c16a289a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_79883f345ad0472c99d17b3eaf931e06",
       "max": 3,
       "style": "IPY_MODEL_95abba42ebd14ed1832762c4f270a68c",
       "value": 3
      }
     },
     "ba6760cfa80c4e0281fc0e144ea6fd8f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "100%"
      }
     },
     "bd75f58ee1644a18a8fd817563553885": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_ee5880bcb64f412ca164ed7032a38474",
       "style": "IPY_MODEL_92980f7ac1814e4197b67f41e5d8fa30",
       "value": " 3/3 [00:03&lt;00:00,  0.94it/s]"
      }
     },
     "cdb9480c90014bd29fb52d2a0f0e1e89": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "cf6280b747444da2bb24eacb781f0835": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "visibility": "hidden",
       "width": "100%"
      }
     },
     "d90f2006d9304213971ff3d6b3c2057b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "dbc77a3380b54847b76d5d730b670630": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_660030051de94766bbf3979eea5729f9",
       "style": "IPY_MODEL_79989c66782447168c40856840bff186",
       "value": "Epoch 2: 100%"
      }
     },
     "dd39c8617b9d4808aaedfc6299a7368f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e0497098579344a5a89019c8d19a519d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_dd39c8617b9d4808aaedfc6299a7368f",
       "style": "IPY_MODEL_0792efe2d16544b7a1ffa7beabfcb002",
       "value": " 3/3 [00:03&lt;00:00,  0.88it/s]"
      }
     },
     "e0f683a45d6446d4bc42824eb7d0d814": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "e34e8f84a2b941ca83f486f2d96b555d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ec26617e10584ebda2d75dfe60fc431e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_3ef9c27a109c42ee97f6367c6455d107",
       "max": 3,
       "style": "IPY_MODEL_8c008a62d114492e87397e002fe7b393",
       "value": 3
      }
     },
     "ec54541f66be44ce8226442f5aa866cb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_e0f683a45d6446d4bc42824eb7d0d814",
       "max": 3,
       "style": "IPY_MODEL_32360b80a00f4886a72eef7ac65a292b",
       "value": 3
      }
     },
     "ee5880bcb64f412ca164ed7032a38474": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f4931c98ae1f42c694716a6b7a0a1348": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "f8e544e0219247769dcc9d99cb2c450d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "faadd47416bb437aa13842c29ae50058": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "visibility": "hidden",
       "width": "100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
