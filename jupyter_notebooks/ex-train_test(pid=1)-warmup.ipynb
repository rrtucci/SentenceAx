{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07c438f4-4a6c-48f1-be15-b60ad25888ca",
   "metadata": {},
   "source": [
    "# ex-train_test(pid=1) warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bdaa0e0-3004-4eaa-9877-bbca287eccd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/SentenceAx\n"
     ]
    }
   ],
   "source": [
    "# this makes sure it starts looking for things from the SentenceAx folder down.\n",
    "import os\n",
    "import sys\n",
    "os.chdir('../')\n",
    "sys.path.insert(0,os.getcwd())\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0f9fa23-d7c2-4c5a-a16f-38dfd02c2f89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(os.environ[\"TOKENIZERS_PARALLELISM\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf61af3b-4c82-4860-9641-e631e5107e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightning version is 2.1.0 so it is >= 2.0.1 as required.\n",
      "SEED= 777\n"
     ]
    }
   ],
   "source": [
    "from Params import *\n",
    "from ActionConductor import *\n",
    "\n",
    "\n",
    "def main(pid):\n",
    "    params = Params(pid)\n",
    "    params.d[\"refresh_cache\"] = True\n",
    "    params.d[\"gpus\"] = 0\n",
    "    params.d[\"batch_size\"] = 4\n",
    "    params.d[\"num_epochs\"] = 3\n",
    "    params.d[\"num_steps_per_epoch\"] = 3\n",
    "    params.d[\"model_str\"] = \"bert-base-cased\"\n",
    "    params.describe_self()\n",
    "    \n",
    "    # in sax_globals.py file, \n",
    "    # set EXTAGS_TRAIN_FP = \"tests/small_extags.txt\" for this warmup run\n",
    "    print(\"EXTAGS_TRAIN_FP=\", EXTAGS_TRAIN_FP)\n",
    "    \n",
    "    conductor = ActionConductor(params, verbose=True)\n",
    "    conductor.delete_all_checkpoints()\n",
    "    print(\"checkpoints:\", conductor.get_all_checkpoint_fp())\n",
    "    conductor.run()\n",
    "    print(\"checkpoints:\", conductor.get_all_checkpoint_fp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a2a9f60-9297-4129-8dd0-edc71196421d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************** new params\n",
      "new params: pid=1, task='ex', action='train_test'\n",
      "params=\n",
      "{'accumulate_grad_batches': 1,\n",
      " 'action': 'train_test',\n",
      " 'batch_size': 4,\n",
      " 'best_checkpoint_fp': '',\n",
      " 'con_weight_str': '1',\n",
      " 'do_rescoring': False,\n",
      " 'dropout_fun': 0.0,\n",
      " 'gpus': 0,\n",
      " 'gradient_clip_val': 5,\n",
      " 'lr': 2e-05,\n",
      " 'model_str': 'bert-base-cased',\n",
      " 'num_epochs': 3,\n",
      " 'num_extractions': 5,\n",
      " 'num_iterative_layers': 2,\n",
      " 'num_steps_per_epoch': 3,\n",
      " 'optimizer': 'adamW',\n",
      " 'refresh_cache': True,\n",
      " 'save_k': 1,\n",
      " 'task': 'ex',\n",
      " 'val_check_interval': 1.0,\n",
      " 'verbose': False,\n",
      " 'wreg': 0,\n",
      " 'write_allen_file': True,\n",
      " 'write_extags_file': True}\n",
      "EXTAGS_TRAIN_FP= tests/small_extags.txt\n",
      "\n",
      "MInput started reading 'tests/small_extags.txt'\n",
      "...\n",
      "1. Line 521 has no valid extractions.\n",
      "2. Line 1337 has no valid extractions.\n",
      "3. Line 1339 has no valid extractions.\n",
      "MInput finished reading 'tests/small_extags.txt'\n",
      "number of lines= 1471\n",
      "number of used samples=  471\n",
      "number of omitted samples=  3\n",
      "\n",
      "\n",
      "MInput started reading 'input_data/carb-data/dev.txt'\n",
      "...\n",
      "MInput finished reading 'input_data/carb-data/dev.txt'\n",
      "number of lines= 1283\n",
      "number of used samples=  641\n",
      "number of omitted samples=  0\n",
      "\n",
      "\n",
      "MInput started reading 'input_data/carb-data/test.txt'\n",
      "...\n",
      "MInput finished reading 'input_data/carb-data/test.txt'\n",
      "number of lines= 1283\n",
      "number of used samples=  641\n",
      "number of omitted samples=  0\n",
      "\n",
      "PaddedMInput omitting these extractions: sample= 96, depths=[5, 6, 7, 8, 9]\n",
      "PaddedMInput omitting these extractions: sample= 135, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 365, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 387, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 410, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 463, depths=[5, 6]\n",
      "checkpoints: []\n",
      "****** model name=  train\n",
      "hidden size= 768\n",
      "num_iterative_layers=  2\n",
      "num_encoder_layers=  10\n",
      "total num layers=  12\n",
      "iterative_transformer= ModuleList(\n",
      "  (0-1): 2 x BertLayer(\n",
      "    (attention): BertAttention(\n",
      "      (self): BertSelfAttention(\n",
      "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (output): BertSelfOutput(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (intermediate): BertIntermediate(\n",
      "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (intermediate_act_fn): GELUActivation()\n",
      "    )\n",
      "    (output): BertOutput(\n",
      "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Retiring current log file by changing its name\n",
      "logs/ex/train_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name                  | Type             | Params\n",
      "-----------------------------------------------------------\n",
      "0 | start_model           | BertModel        | 94.1 M\n",
      "1 | iterative_transformer | ModuleList       | 14.2 M\n",
      "2 | dropout_fun           | Dropout          | 0     \n",
      "3 | embedding             | Embedding        | 76.8 K\n",
      "4 | merge_layer           | Linear           | 230 K \n",
      "5 | ilabelling_layer      | Linear           | 1.8 K \n",
      "6 | loss_fun              | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------------------\n",
      "108 M     Trainable params\n",
      "0         Non-trainable params\n",
      "108 M     Total params\n",
      "434.478   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a848454a286f4dc58efd23ab98726fb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering Model.training_step method, batch_idx=0\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 121])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 4, torch.Size([4, 86, 6])\n",
      "len(llll_word_score)= 5\n",
      "llll_word_score[0].shape torch.Size([4, 86, 6])\n",
      "Entering Model.training_step method, batch_idx=1\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 121])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 4, torch.Size([4, 86, 6])\n",
      "len(llll_word_score)= 5\n",
      "llll_word_score[0].shape torch.Size([4, 86, 6])\n",
      "Entering Model.training_step method, batch_idx=2\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 121])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 4, torch.Size([4, 86, 6])\n",
      "len(llll_word_score)= 5\n",
      "llll_word_score[0].shape torch.Size([4, 86, 6])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering Model.validation_step method, batch_idx=0\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 105])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 84, 6])\n",
      "len(llll_word_score)= 4\n",
      "llll_word_score[0].shape torch.Size([4, 84, 6])\n",
      "Entering Model.validation_step method, batch_idx=1\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 105])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 84, 6])\n",
      "len(llll_word_score)= 4\n",
      "llll_word_score[0].shape torch.Size([4, 84, 6])\n",
      "Entering Model.validation_step method, batch_idx=2\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 105])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 84, 6])\n",
      "len(llll_word_score)= 4\n",
      "llll_word_score[0].shape torch.Size([4, 84, 6])\n",
      "Entering Model.on_validation_epoch_end method\n",
      "Entering ExMetric.__call__() method.\n",
      "len(self.osentL_to_exs) before merge= 0\n",
      "len(self.osentL_to_exs) after merge= 4\n",
      "Entering ExMetric.__call__() method.\n",
      "len(self.osentL_to_exs) before merge= 4\n",
      "len(self.osentL_to_exs) after merge= 8\n",
      "Entering ExMetric.__call__() method.\n",
      "len(self.osentL_to_exs) before merge= 8\n",
      "len(self.osentL_to_exs) after merge= 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 3: 'epoch_acc' reached 0.00570 (best 0.00570), saving model to '/home/studio-lab-user/sagemaker-studiolab-notebooks/SentenceAx/weights/ex_model/epoch=00_epoch_acc=0.006.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering ExMetric.get_score_d() method.\n",
      "\n",
      "Scores at end of epoch 0:\n",
      "OrderedDict([('AUC', 0.0003), ('F1', 0.0057), ('last_F1', 0.0057), ('epoch_acc', 0.0057)])\n",
      "Entering Model.training_step method, batch_idx=0\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 121])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 4, torch.Size([4, 86, 6])\n",
      "len(llll_word_score)= 5\n",
      "llll_word_score[0].shape torch.Size([4, 86, 6])\n",
      "Entering Model.training_step method, batch_idx=1\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 121])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 4, torch.Size([4, 86, 6])\n",
      "len(llll_word_score)= 5\n",
      "llll_word_score[0].shape torch.Size([4, 86, 6])\n",
      "Entering Model.training_step method, batch_idx=2\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 121])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 4, torch.Size([4, 86, 6])\n",
      "len(llll_word_score)= 5\n",
      "llll_word_score[0].shape torch.Size([4, 86, 6])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering Model.validation_step method, batch_idx=0\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 105])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 84, 6])\n",
      "len(llll_word_score)= 4\n",
      "llll_word_score[0].shape torch.Size([4, 84, 6])\n",
      "Entering Model.validation_step method, batch_idx=1\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 105])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 84, 6])\n",
      "len(llll_word_score)= 4\n",
      "llll_word_score[0].shape torch.Size([4, 84, 6])\n",
      "Entering Model.validation_step method, batch_idx=2\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 105])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 6: 'epoch_acc' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 84, 6])\n",
      "len(llll_word_score)= 4\n",
      "llll_word_score[0].shape torch.Size([4, 84, 6])\n",
      "Entering Model.on_validation_epoch_end method\n",
      "Entering ExMetric.__call__() method.\n",
      "len(self.osentL_to_exs) before merge= 0\n",
      "len(self.osentL_to_exs) after merge= 4\n",
      "Entering ExMetric.__call__() method.\n",
      "len(self.osentL_to_exs) before merge= 4\n",
      "len(self.osentL_to_exs) after merge= 8\n",
      "Entering ExMetric.__call__() method.\n",
      "len(self.osentL_to_exs) before merge= 8\n",
      "len(self.osentL_to_exs) after merge= 12\n",
      "Entering ExMetric.get_score_d() method.\n",
      "\n",
      "Scores at end of epoch 1:\n",
      "OrderedDict([('AUC', 0.0003), ('F1', 0.0057), ('last_F1', 0.0057), ('epoch_acc', 0.0057)])\n",
      "Entering Model.training_step method, batch_idx=0\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 121])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 4, torch.Size([4, 86, 6])\n",
      "len(llll_word_score)= 5\n",
      "llll_word_score[0].shape torch.Size([4, 86, 6])\n",
      "Entering Model.training_step method, batch_idx=1\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 121])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 4, torch.Size([4, 86, 6])\n",
      "len(llll_word_score)= 5\n",
      "llll_word_score[0].shape torch.Size([4, 86, 6])\n",
      "Entering Model.training_step method, batch_idx=2\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 121])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 4, torch.Size([4, 86, 6])\n",
      "len(llll_word_score)= 5\n",
      "llll_word_score[0].shape torch.Size([4, 86, 6])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering Model.validation_step method, batch_idx=0\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 105])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 84, 6])\n",
      "len(llll_word_score)= 4\n",
      "llll_word_score[0].shape torch.Size([4, 84, 6])\n",
      "Entering Model.validation_step method, batch_idx=1\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 105])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 84, 6])\n",
      "len(llll_word_score)= 4\n",
      "llll_word_score[0].shape torch.Size([4, 84, 6])\n",
      "Entering Model.validation_step method, batch_idx=2\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 105])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 9: 'epoch_acc' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 84, 6])\n",
      "len(llll_word_score)= 4\n",
      "llll_word_score[0].shape torch.Size([4, 84, 6])\n",
      "Entering Model.on_validation_epoch_end method\n",
      "Entering ExMetric.__call__() method.\n",
      "len(self.osentL_to_exs) before merge= 0\n",
      "len(self.osentL_to_exs) after merge= 4\n",
      "Entering ExMetric.__call__() method.\n",
      "len(self.osentL_to_exs) before merge= 4\n",
      "len(self.osentL_to_exs) after merge= 8\n",
      "Entering ExMetric.__call__() method.\n",
      "len(self.osentL_to_exs) before merge= 8\n",
      "len(self.osentL_to_exs) after merge= 12\n",
      "Entering ExMetric.get_score_d() method.\n",
      "\n",
      "Scores at end of epoch 2:\n",
      "OrderedDict([('AUC', 0.0003), ('F1', 0.0057), ('last_F1', 0.0057), ('epoch_acc', 0.0057)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Restoring states from the checkpoint path at weights/ex_model/epoch=00_epoch_acc=0.006.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** model name=  test\n",
      "hidden size= 768\n",
      "num_iterative_layers=  2\n",
      "num_encoder_layers=  10\n",
      "total num layers=  12\n",
      "iterative_transformer= ModuleList(\n",
      "  (0-1): 2 x BertLayer(\n",
      "    (attention): BertAttention(\n",
      "      (self): BertSelfAttention(\n",
      "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (output): BertSelfOutput(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (intermediate): BertIntermediate(\n",
      "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (intermediate_act_fn): GELUActivation()\n",
      "    )\n",
      "    (output): BertOutput(\n",
      "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Retiring current log file by changing its name\n",
      "logs/ex/test_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded model weights from the checkpoint at weights/ex_model/epoch=00_epoch_acc=0.006.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c463fda66b0456690968285eaf0741f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering Model.test_step method, batch_idx=0\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 77])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 77, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 66, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 66, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 66, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 66, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 66, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 66, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 66, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 66, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 66, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 66, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 66, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 66, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 66, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 66, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 66, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 66, 6])\n",
      "len(llll_word_score)= 4\n",
      "llll_word_score[0].shape torch.Size([4, 66, 6])\n",
      "Entering Model.test_step method, batch_idx=1\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 77])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 77, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 66, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 66, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 66, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 66, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 66, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 66, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 66, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 66, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 66, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 66, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 66, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 66, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 66, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 66, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 66, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 66, 6])\n",
      "len(llll_word_score)= 4\n",
      "llll_word_score[0].shape torch.Size([4, 66, 6])\n",
      "Entering Model.test_step method, batch_idx=2\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 77])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 77, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 66, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 66, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 66, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 66, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 66, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 66, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 66, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 66, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 66, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 66, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 66, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 66, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 66, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 66, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 66, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 66, 6])\n",
      "len(llll_word_score)= 4\n",
      "llll_word_score[0].shape torch.Size([4, 66, 6])\n",
      "Entering Model.on_test_epoch_end method\n",
      "Entering ExMetric.__call__() method.\n",
      "len(self.osentL_to_exs) before merge= 0\n",
      "len(self.osentL_to_exs) after merge= 4\n",
      "Entering ExMetric.__call__() method.\n",
      "len(self.osentL_to_exs) before merge= 4\n",
      "len(self.osentL_to_exs) after merge= 8\n",
      "Entering ExMetric.__call__() method.\n",
      "len(self.osentL_to_exs) before merge= 8\n",
      "len(self.osentL_to_exs) after merge= 12\n",
      "Entering ExMetric.get_score_d() method.\n",
      "\n",
      "Scores at end of epoch 0:\n",
      "OrderedDict([('AUC', 0.0003), ('F1', 0.0026), ('last_F1', 0.0026), ('epoch_acc', 0.0026)])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">        Test metric        </span><span style=\"font-weight: bold\">       DataLoader 0        </span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">         epoch_acc         </span><span style=\"color: #800080; text-decoration-color: #800080\">          0.0026           </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">        loss_epoch         </span><span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       "\u001b[36m \u001b[0m\u001b[36m        epoch_acc        \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.0026          \u001b[0m\u001b[35m \u001b[0m\n",
       "\u001b[36m \u001b[0m\u001b[36m       loss_epoch        \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints: ['weights/ex_model/epoch=00_epoch_acc=0.006.ckpt']\n"
     ]
    }
   ],
   "source": [
    "main(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0280c25dba99421e90d4d911a4f1afb2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "100%"
      }
     },
     "030d1f58fe5144e3bb9f87672083496c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "visibility": "hidden",
       "width": "100%"
      }
     },
     "07887c1f0b43499a9d08489b77111359": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "09d6de65a1e3455fa07a5ce89c052bd5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "118c766b9dc94a399c4278fb805f5bbe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "11d59b71cb8546cd88cf143b989677fe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_5e0692ff192741c4a679e5148b38ec8e",
       "style": "IPY_MODEL_b99e2129fdf243e19480d732b335a3f5",
       "value": "Validation DataLoader 0: 100%"
      }
     },
     "15c1b542fa974590a94dd459639da5b0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "1c463fda66b0456690968285eaf0741f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_a7f3aa1d8e4541a5ab127d7fb97c4027",
        "IPY_MODEL_4845ec91012349d7a99ebc0c4c0c9a33",
        "IPY_MODEL_5e10476b1e0346a798a957c1c81cc5e1"
       ],
       "layout": "IPY_MODEL_3e6a0c86fe6f410aae58f8074ee8dcce"
      }
     },
     "1e728d0b4cfc468fbd30b2c39d915873": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_1fa5cafd549f4e5da2d3c03485c5e0c2",
       "max": 3,
       "style": "IPY_MODEL_e5407a46eb2e43f2ae53bc537d8771fa",
       "value": 3
      }
     },
     "1fa5cafd549f4e5da2d3c03485c5e0c2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "2092a6992887463ab155ce8c2b6b5897": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "286a6991e37d46268fdb40aa0574bc86": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3228568f432a4c7cad102466974d3221": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "36bfe9757935403ab16a13de30d8394e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "36e57019bd1c4c61b8c155bbfc3be005": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_4554c5b280ee4e9fac76d4a58133076e",
       "style": "IPY_MODEL_96db14430d96455ba3b48470c4c99139",
       "value": " 3/3 [00:02&lt;00:00,  1.17it/s]"
      }
     },
     "3e6a0c86fe6f410aae58f8074ee8dcce": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "100%"
      }
     },
     "45310a74f8244110aa806ec8d3a383d9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "4554c5b280ee4e9fac76d4a58133076e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4845ec91012349d7a99ebc0c4c0c9a33": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_992f8b796c7f4941af336c02d267f8e7",
       "max": 3,
       "style": "IPY_MODEL_7cd312966880428d8a870a5f37f42115",
       "value": 3
      }
     },
     "4c6205bec19d42cb8671799b5f61172b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4edf74ad0ad3412b82127d0dbfe85bfb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "visibility": "hidden",
       "width": "100%"
      }
     },
     "51562836f459470a9c5daadb593e0718": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5d343d7896dd4e5488c20fbd1b6bf883": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_09d6de65a1e3455fa07a5ce89c052bd5",
       "style": "IPY_MODEL_f02ed93e9ed6465aba8c966552749ae0",
       "value": "Validation DataLoader 0: 100%"
      }
     },
     "5e0692ff192741c4a679e5148b38ec8e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5e10476b1e0346a798a957c1c81cc5e1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_4c6205bec19d42cb8671799b5f61172b",
       "style": "IPY_MODEL_45310a74f8244110aa806ec8d3a383d9",
       "value": " 3/3 [00:02&lt;00:00,  1.47it/s]"
      }
     },
     "612917b360c743f1b7b21035025a92a8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6458210d520c4d17a9f65bf7fd778628": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_db84fa6a17444715b689cd13c6c2e4eb",
       "style": "IPY_MODEL_3228568f432a4c7cad102466974d3221",
       "value": " 3/3 [00:07&lt;00:00,  0.41it/s, v_num=part, loss=8.050, loss_step=0.000, loss_epoch=0.000, epoch_acc=0.0057]"
      }
     },
     "650c5dbfd1424498a97ece83e7eb2d03": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "68b35b5f011541578062d8c4e5524026": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "753aaf3b42534c9a89d03087a942efd6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_51562836f459470a9c5daadb593e0718",
       "style": "IPY_MODEL_f8a1ead6d13645478f070884a548fa1f",
       "value": "Epoch 2: 100%"
      }
     },
     "781ef94d54f8430e8212c59fdd1d74d9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "7cd312966880428d8a870a5f37f42115": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "8bd97290d4344d6892da6cfc1f6285c4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_118c766b9dc94a399c4278fb805f5bbe",
       "max": 3,
       "style": "IPY_MODEL_a0dfd60eeac74ed48e5e03a28d01b2db",
       "value": 3
      }
     },
     "96b81ec68264444881888680315135c3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_15c1b542fa974590a94dd459639da5b0",
       "max": 3,
       "style": "IPY_MODEL_781ef94d54f8430e8212c59fdd1d74d9",
       "value": 3
      }
     },
     "96db14430d96455ba3b48470c4c99139": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "992f8b796c7f4941af336c02d267f8e7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "9b11e15a38a4406691e823ef91d99ea2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_9bdf0cd6bca04961b87fe8f76baa390e",
       "style": "IPY_MODEL_fe9222d7af5c4c48a2d97c840ff489bf",
       "value": "Validation DataLoader 0: 100%"
      }
     },
     "9bdf0cd6bca04961b87fe8f76baa390e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a0dfd60eeac74ed48e5e03a28d01b2db": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "a253d95050d9457599268953f5efa587": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_36bfe9757935403ab16a13de30d8394e",
       "style": "IPY_MODEL_650c5dbfd1424498a97ece83e7eb2d03",
       "value": " 3/3 [00:02&lt;00:00,  1.15it/s]"
      }
     },
     "a7f3aa1d8e4541a5ab127d7fb97c4027": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_612917b360c743f1b7b21035025a92a8",
       "style": "IPY_MODEL_07887c1f0b43499a9d08489b77111359",
       "value": "Testing DataLoader 0: 100%"
      }
     },
     "a848454a286f4dc58efd23ab98726fb3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_753aaf3b42534c9a89d03087a942efd6",
        "IPY_MODEL_96b81ec68264444881888680315135c3",
        "IPY_MODEL_6458210d520c4d17a9f65bf7fd778628"
       ],
       "layout": "IPY_MODEL_0280c25dba99421e90d4d911a4f1afb2"
      }
     },
     "b3d6df839f9d484d88ea2567ab181640": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_286a6991e37d46268fdb40aa0574bc86",
       "style": "IPY_MODEL_be442d69a7844dc0be7770630ba54867",
       "value": " 3/3 [00:02&lt;00:00,  1.11it/s]"
      }
     },
     "b7ce7a05996b42ef9ee04212c1f98dba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_68b35b5f011541578062d8c4e5524026",
       "max": 3,
       "style": "IPY_MODEL_2092a6992887463ab155ce8c2b6b5897",
       "value": 3
      }
     },
     "b99e2129fdf243e19480d732b335a3f5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "be442d69a7844dc0be7770630ba54867": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "db84fa6a17444715b689cd13c6c2e4eb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e5407a46eb2e43f2ae53bc537d8771fa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "e932543947c1454f8b83fd806da41fc5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "visibility": "hidden",
       "width": "100%"
      }
     },
     "f02ed93e9ed6465aba8c966552749ae0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "f8a1ead6d13645478f070884a548fa1f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "fe9222d7af5c4c48a2d97c840ff489bf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
