{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07c438f4-4a6c-48f1-be15-b60ad25888ca",
   "metadata": {},
   "source": [
    "# ex-train_test(pid=1) warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bdaa0e0-3004-4eaa-9877-bbca287eccd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/SentenceAx\n"
     ]
    }
   ],
   "source": [
    "# this makes sure it starts looking for things from the SentenceAx folder down.\n",
    "import os\n",
    "import sys\n",
    "os.chdir('../')\n",
    "sys.path.insert(0,os.getcwd())\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0f9fa23-d7c2-4c5a-a16f-38dfd02c2f89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(os.environ[\"TOKENIZERS_PARALLELISM\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf61af3b-4c82-4860-9641-e631e5107e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightning version is 2.1.0 so it is >= 2.0.1 as required.\n",
      "SEED= 777\n"
     ]
    }
   ],
   "source": [
    "from Params import *\n",
    "from ActionConductor import *\n",
    "\n",
    "\n",
    "def main(pid):\n",
    "    params = Params(pid)\n",
    "    params.d[\"refresh_cache\"] = True\n",
    "    params.d[\"gpus\"] = 0\n",
    "    params.d[\"batch_size\"] = 4\n",
    "    params.d[\"num_epochs\"] = 3\n",
    "    params.d[\"num_steps_per_epoch\"] = 3\n",
    "    params.d[\"model_str\"] = \"bert-base-cased\"\n",
    "    params.describe_self()\n",
    "    \n",
    "    # in sax_globals.py file, \n",
    "    # set EXTAGS_TRAIN_FP = \"tests/small_extags.txt\" for this warmup run\n",
    "    print(\"EXTAGS_TRAIN_FP=\", EXTAGS_TRAIN_FP)\n",
    "    \n",
    "    conductor = ActionConductor(params, verbose=True)\n",
    "    conductor.delete_all_checkpoints()\n",
    "    print(\"checkpoints:\", conductor.get_all_checkpoint_fp())\n",
    "    conductor.run()\n",
    "    print(\"checkpoints:\", conductor.get_all_checkpoint_fp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a2a9f60-9297-4129-8dd0-edc71196421d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************** new params\n",
      "new params: pid=1, task='ex', action='train_test'\n",
      "params=\n",
      "{'accumulate_grad_batches': 1,\n",
      " 'action': 'train_test',\n",
      " 'batch_size': 4,\n",
      " 'best_checkpoint_fp': '',\n",
      " 'con_weight_str': '1',\n",
      " 'do_rescoring': False,\n",
      " 'dropout_fun': 0.0,\n",
      " 'gpus': 0,\n",
      " 'gradient_clip_val': 5,\n",
      " 'lr': 2e-05,\n",
      " 'model_str': 'bert-base-cased',\n",
      " 'num_epochs': 3,\n",
      " 'num_extractions': 5,\n",
      " 'num_iterative_layers': 2,\n",
      " 'num_steps_per_epoch': 3,\n",
      " 'optimizer': 'adamW',\n",
      " 'refresh_cache': True,\n",
      " 'save_k': 1,\n",
      " 'task': 'ex',\n",
      " 'val_check_interval': 1.0,\n",
      " 'verbose': False,\n",
      " 'wreg': 0,\n",
      " 'write_allen_file': True,\n",
      " 'write_extags_file': True}\n",
      "EXTAGS_TRAIN_FP= tests/small_extags.txt\n",
      "\n",
      "MInput started reading 'tests/small_extags.txt'\n",
      "...\n",
      "1. Line 521 has no valid extractions.\n",
      "2. Line 1337 has no valid extractions.\n",
      "3. Line 1339 has no valid extractions.\n",
      "MInput finished reading 'tests/small_extags.txt'\n",
      "number of lines= 1471\n",
      "number of used samples=  471\n",
      "number of omitted samples=  3\n",
      "\n",
      "\n",
      "MInput started reading 'input_data/carb-data/dev.txt'\n",
      "...\n",
      "MInput finished reading 'input_data/carb-data/dev.txt'\n",
      "number of lines= 1283\n",
      "number of used samples=  641\n",
      "number of omitted samples=  0\n",
      "\n",
      "\n",
      "MInput started reading 'input_data/carb-data/test.txt'\n",
      "...\n",
      "MInput finished reading 'input_data/carb-data/test.txt'\n",
      "number of lines= 1283\n",
      "number of used samples=  641\n",
      "number of omitted samples=  0\n",
      "\n",
      "PaddedMInput omitting these extractions: sample= 96, depths=[5, 6, 7, 8, 9]\n",
      "PaddedMInput omitting these extractions: sample= 135, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 365, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 387, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 410, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 463, depths=[5, 6]\n",
      "An error occurred: [Errno 2] No such file or directory: 'weights/ex_model'\n",
      "checkpoints: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** model name=  train\n",
      "hidden size= 768\n",
      "num_iterative_layers=  2\n",
      "num_encoder_layers=  10\n",
      "total num layers=  12\n",
      "iterative_transformer= ModuleList(\n",
      "  (0-1): 2 x BertLayer(\n",
      "    (attention): BertAttention(\n",
      "      (self): BertSelfAttention(\n",
      "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (output): BertSelfOutput(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (intermediate): BertIntermediate(\n",
      "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (intermediate_act_fn): GELUActivation()\n",
      "    )\n",
      "    (output): BertOutput(\n",
      "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name                  | Type             | Params\n",
      "-----------------------------------------------------------\n",
      "0 | start_model           | BertModel        | 94.1 M\n",
      "1 | iterative_transformer | ModuleList       | 14.2 M\n",
      "2 | dropout_fun           | Dropout          | 0     \n",
      "3 | embedding             | Embedding        | 76.8 K\n",
      "4 | merge_layer           | Linear           | 230 K \n",
      "5 | ilabelling_layer      | Linear           | 1.8 K \n",
      "6 | loss_fun              | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------------------\n",
      "108 M     Trainable params\n",
      "0         Non-trainable params\n",
      "108 M     Total params\n",
      "434.478   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24f707738f6544b49fd5153403b5f531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering Model.training_step method, batch_idx=0\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 121])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 4, torch.Size([4, 86, 6])\n",
      "len(llll_word_score)= 5\n",
      "llll_word_score[0].shape torch.Size([4, 86, 6])\n",
      "Entering Model.training_step method, batch_idx=1\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 121])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 4, torch.Size([4, 86, 6])\n",
      "len(llll_word_score)= 5\n",
      "llll_word_score[0].shape torch.Size([4, 86, 6])\n",
      "Entering Model.training_step method, batch_idx=2\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 121])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 4, torch.Size([4, 86, 6])\n",
      "len(llll_word_score)= 5\n",
      "llll_word_score[0].shape torch.Size([4, 86, 6])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering Model.validation_step method, batch_idx=0\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 105])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 84, 6])\n",
      "len(llll_word_score)= 4\n",
      "llll_word_score[0].shape torch.Size([4, 84, 6])\n",
      "Entering Model.validation_step method, batch_idx=1\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 105])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 84, 6])\n",
      "len(llll_word_score)= 4\n",
      "llll_word_score[0].shape torch.Size([4, 84, 6])\n",
      "Entering Model.validation_step method, batch_idx=2\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 105])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 84, 6])\n",
      "len(llll_word_score)= 4\n",
      "llll_word_score[0].shape torch.Size([4, 84, 6])\n",
      "Entering Model.on_validation_epoch_end method\n",
      "Entering ExMetric.__call__() method.\n",
      "len(self.osentL_to_exs) before merge= 0\n",
      "len(self.osentL_to_exs) after merge= 4\n",
      "Entering ExMetric.__call__() method.\n",
      "len(self.osentL_to_exs) before merge= 4\n",
      "len(self.osentL_to_exs) after merge= 8\n",
      "Entering ExMetric.__call__() method.\n",
      "len(self.osentL_to_exs) before merge= 8\n",
      "len(self.osentL_to_exs) after merge= 12\n",
      "Entering ExMetric.get_score_d() method.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 3: 'epoch_acc' reached 0.00570 (best 0.00570), saving model to '/home/studio-lab-user/sagemaker-studiolab-notebooks/SentenceAx/weights/ex_model/epoch=00_epoch_acc=0.006.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores at end of epoch 0:\n",
      "OrderedDict([('AUC', 0.0003), ('F1', 0.0057), ('last_F1', 0.0057), ('epoch_acc', 0.0057)])\n",
      "Entering Model.training_step method, batch_idx=0\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 121])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 4, torch.Size([4, 86, 6])\n",
      "len(llll_word_score)= 5\n",
      "llll_word_score[0].shape torch.Size([4, 86, 6])\n",
      "Entering Model.training_step method, batch_idx=1\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 121])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 4, torch.Size([4, 86, 6])\n",
      "len(llll_word_score)= 5\n",
      "llll_word_score[0].shape torch.Size([4, 86, 6])\n",
      "Entering Model.training_step method, batch_idx=2\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 121])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 4, torch.Size([4, 86, 6])\n",
      "len(llll_word_score)= 5\n",
      "llll_word_score[0].shape torch.Size([4, 86, 6])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering Model.validation_step method, batch_idx=0\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 105])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 84, 6])\n",
      "len(llll_word_score)= 4\n",
      "llll_word_score[0].shape torch.Size([4, 84, 6])\n",
      "Entering Model.validation_step method, batch_idx=1\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 105])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 84, 6])\n",
      "len(llll_word_score)= 4\n",
      "llll_word_score[0].shape torch.Size([4, 84, 6])\n",
      "Entering Model.validation_step method, batch_idx=2\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 105])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 6: 'epoch_acc' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 84, 6])\n",
      "len(llll_word_score)= 4\n",
      "llll_word_score[0].shape torch.Size([4, 84, 6])\n",
      "Entering Model.on_validation_epoch_end method\n",
      "Entering ExMetric.__call__() method.\n",
      "len(self.osentL_to_exs) before merge= 0\n",
      "len(self.osentL_to_exs) after merge= 4\n",
      "Entering ExMetric.__call__() method.\n",
      "len(self.osentL_to_exs) before merge= 4\n",
      "len(self.osentL_to_exs) after merge= 8\n",
      "Entering ExMetric.__call__() method.\n",
      "len(self.osentL_to_exs) before merge= 8\n",
      "len(self.osentL_to_exs) after merge= 12\n",
      "Entering ExMetric.get_score_d() method.\n",
      "\n",
      "Scores at end of epoch 1:\n",
      "OrderedDict([('AUC', 0.0003), ('F1', 0.0057), ('last_F1', 0.0057), ('epoch_acc', 0.0057)])\n",
      "Entering Model.training_step method, batch_idx=0\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 121])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 4, torch.Size([4, 86, 6])\n",
      "len(llll_word_score)= 5\n",
      "llll_word_score[0].shape torch.Size([4, 86, 6])\n",
      "Entering Model.training_step method, batch_idx=1\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 121])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 4, torch.Size([4, 86, 6])\n",
      "len(llll_word_score)= 5\n",
      "llll_word_score[0].shape torch.Size([4, 86, 6])\n",
      "Entering Model.training_step method, batch_idx=2\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 121])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 4, torch.Size([4, 86, 6])\n",
      "len(llll_word_score)= 5\n",
      "llll_word_score[0].shape torch.Size([4, 86, 6])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering Model.validation_step method, batch_idx=0\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 105])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 84, 6])\n",
      "len(llll_word_score)= 4\n",
      "llll_word_score[0].shape torch.Size([4, 84, 6])\n",
      "Entering Model.validation_step method, batch_idx=1\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 105])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 84, 6])\n",
      "len(llll_word_score)= 4\n",
      "llll_word_score[0].shape torch.Size([4, 84, 6])\n",
      "Entering Model.validation_step method, batch_idx=2\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 105])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 9: 'epoch_acc' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 84, 6])\n",
      "len(llll_word_score)= 4\n",
      "llll_word_score[0].shape torch.Size([4, 84, 6])\n",
      "Entering Model.on_validation_epoch_end method\n",
      "Entering ExMetric.__call__() method.\n",
      "len(self.osentL_to_exs) before merge= 0\n",
      "len(self.osentL_to_exs) after merge= 4\n",
      "Entering ExMetric.__call__() method.\n",
      "len(self.osentL_to_exs) before merge= 4\n",
      "len(self.osentL_to_exs) after merge= 8\n",
      "Entering ExMetric.__call__() method.\n",
      "len(self.osentL_to_exs) before merge= 8\n",
      "len(self.osentL_to_exs) after merge= 12\n",
      "Entering ExMetric.get_score_d() method.\n",
      "\n",
      "Scores at end of epoch 2:\n",
      "OrderedDict([('AUC', 0.0003), ('F1', 0.0057), ('last_F1', 0.0057), ('epoch_acc', 0.0057)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Restoring states from the checkpoint path at weights/ex_model/epoch=00_epoch_acc=0.006.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** model name=  test\n",
      "hidden size= 768\n",
      "num_iterative_layers=  2\n",
      "num_encoder_layers=  10\n",
      "total num layers=  12\n",
      "iterative_transformer= ModuleList(\n",
      "  (0-1): 2 x BertLayer(\n",
      "    (attention): BertAttention(\n",
      "      (self): BertSelfAttention(\n",
      "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (output): BertSelfOutput(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (intermediate): BertIntermediate(\n",
      "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (intermediate_act_fn): GELUActivation()\n",
      "    )\n",
      "    (output): BertOutput(\n",
      "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded model weights from the checkpoint at weights/ex_model/epoch=00_epoch_acc=0.006.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1652df3128914992b4b873dd561642db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering Model.test_step method, batch_idx=0\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 77])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 77, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 66, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 66, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 66, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 66, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 66, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 66, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 66, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 66, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 66, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 66, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 66, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 66, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 66, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 66, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 66, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 66, 6])\n",
      "len(llll_word_score)= 4\n",
      "llll_word_score[0].shape torch.Size([4, 66, 6])\n",
      "Entering Model.test_step method, batch_idx=1\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 77])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 77, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 66, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 66, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 66, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 66, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 66, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 66, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 66, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 66, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 66, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 66, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 66, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 66, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 66, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 66, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 66, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 66, 6])\n",
      "len(llll_word_score)= 4\n",
      "llll_word_score[0].shape torch.Size([4, 66, 6])\n",
      "Entering Model.test_step method, batch_idx=2\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 77])\n",
      "after start_model, lll_hidden_state.shape torch.Size([4, 77, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 66, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 66, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 66, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 66, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 66, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 66, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 66, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 66, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 66, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 66, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 66, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 66, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 66, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 66, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 66, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 66, 6])\n",
      "len(llll_word_score)= 4\n",
      "llll_word_score[0].shape torch.Size([4, 66, 6])\n",
      "Entering Model.on_test_epoch_end method\n",
      "Entering ExMetric.__call__() method.\n",
      "len(self.osentL_to_exs) before merge= 0\n",
      "len(self.osentL_to_exs) after merge= 4\n",
      "Entering ExMetric.__call__() method.\n",
      "len(self.osentL_to_exs) before merge= 4\n",
      "len(self.osentL_to_exs) after merge= 8\n",
      "Entering ExMetric.__call__() method.\n",
      "len(self.osentL_to_exs) before merge= 8\n",
      "len(self.osentL_to_exs) after merge= 12\n",
      "Entering ExMetric.get_score_d() method.\n",
      "\n",
      "Scores at end of epoch 0:\n",
      "OrderedDict([('AUC', 0.0003), ('F1', 0.0026), ('last_F1', 0.0026), ('epoch_acc', 0.0026)])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         epoch_acc         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">          0.0026           </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   train_step_loss_epoch   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        epoch_acc        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m         0.0026          \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m  train_step_loss_epoch  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints: ['weights/ex_model/epoch=00_epoch_acc=0.006.ckpt']\n"
     ]
    }
   ],
   "source": [
    "main(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "001b22906ead478cbb1631ec703a1e97": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "054a77fcc8dd4069b9f99855bedcd7dd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "0957ca2ad3e24478922d52fc3c711be7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "0ac12e1f8e9c454ba12f57a53389d8d6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_0de988e95851441d923af0c42d063f0f",
       "max": 3,
       "style": "IPY_MODEL_2f2df94d39ab418e9f89a330a1641e7a",
       "value": 3
      }
     },
     "0d95984f9fae40f49c6e7696f5a71b65": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_8c753e58cdd745eeb609de45fdb7c538",
       "style": "IPY_MODEL_50fa2c86c4a048639af5554f1d583e9c",
       "value": " 3/3 [00:02&lt;00:00,  1.15it/s]"
      }
     },
     "0de988e95851441d923af0c42d063f0f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "1652df3128914992b4b873dd561642db": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_524aaacf926841278d0f0366623a8ee8",
        "IPY_MODEL_e5050922d20b4353a663e888880927da",
        "IPY_MODEL_f0949682a2264200a231e46669a4dcdb"
       ],
       "layout": "IPY_MODEL_72f39a031d6e4cff88fd36874a9680de"
      }
     },
     "17734a9fd0274127b62a77e4535ecb82": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "19ff4d7f72cf46138447f50bab59c7ae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_de2f0bf5b83f4dcca843ef7d13a657ec",
       "max": 3,
       "style": "IPY_MODEL_f55f53b23e3047ecb9905a5683470e56",
       "value": 3
      }
     },
     "24f707738f6544b49fd5153403b5f531": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_4630cde0bf384cd2941a77e75ef7df22",
        "IPY_MODEL_19ff4d7f72cf46138447f50bab59c7ae",
        "IPY_MODEL_b1e202f309b141739589a8c97e5f12a9"
       ],
       "layout": "IPY_MODEL_afe5ed077b364097894ee0d1b7008c80"
      }
     },
     "25c88454e3f74e67833a05d466bdff3e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "2f2df94d39ab418e9f89a330a1641e7a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "318bdda2b1844dd4b8324f711c348152": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_97fc2b8473de4a1c861c6b484158f379",
       "max": 3,
       "style": "IPY_MODEL_70cda2b5403b4d139fe462dd407e6565",
       "value": 3
      }
     },
     "34581efa12b2491598d6ef69a74e6680": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "4059e1b60717453abf3e86f87ee8a885": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "visibility": "hidden",
       "width": "100%"
      }
     },
     "449e9f0946db4c90b11d9e60af67c2a5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4630cde0bf384cd2941a77e75ef7df22": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_b90234e57da84b1ab216d608d15a8520",
       "style": "IPY_MODEL_0957ca2ad3e24478922d52fc3c711be7",
       "value": "Epoch 2: 100%"
      }
     },
     "4954117c729d4743a8c3415567028066": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_d9bdacafd237465a9e67dd264c59f5d7",
       "style": "IPY_MODEL_001b22906ead478cbb1631ec703a1e97",
       "value": "Validation DataLoader 0: 100%"
      }
     },
     "50fa2c86c4a048639af5554f1d583e9c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "524aaacf926841278d0f0366623a8ee8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_054a77fcc8dd4069b9f99855bedcd7dd",
       "style": "IPY_MODEL_ef30f0b6114e46bbb36a82276b3c1149",
       "value": "Testing DataLoader 0: 100%"
      }
     },
     "5750ffe1bead4edba4ad471df6ac12e9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5d570fa2ed424eaf83bfee69fac56a49": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_17734a9fd0274127b62a77e4535ecb82",
       "style": "IPY_MODEL_25c88454e3f74e67833a05d466bdff3e",
       "value": "Validation DataLoader 0: 100%"
      }
     },
     "64585ac1b44b4eb3984f82dc9f649768": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_5750ffe1bead4edba4ad471df6ac12e9",
       "style": "IPY_MODEL_edeaa9e30c8b4106909bbd0c825b5660",
       "value": " 3/3 [00:02&lt;00:00,  1.15it/s]"
      }
     },
     "6dd74cd2729a4c179e177a93cb3c2127": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_a5288ef19ec5469aaa6d443b4e3e68d0",
       "style": "IPY_MODEL_bc529508c33649bbac907c038eb1c5a2",
       "value": "Validation DataLoader 0: 100%"
      }
     },
     "70cda2b5403b4d139fe462dd407e6565": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "72f39a031d6e4cff88fd36874a9680de": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "100%"
      }
     },
     "7331c485057a4f41ad320e78f8a62f4c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_9e5194ec7d6b47f48bcefb6729721921",
       "style": "IPY_MODEL_a491d1659a204ef0879b965a53c0207c",
       "value": " 3/3 [00:02&lt;00:00,  1.10it/s]"
      }
     },
     "78ac826f8d8a48c58efa54e01f38da76": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "7c244f31885044c9b4f81a69bd87d3a5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "visibility": "hidden",
       "width": "100%"
      }
     },
     "7cc0eb5691da4feb855dfd43f2aaf12a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8aeb740c96fc482ea3cd53cf3df242a2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "8c753e58cdd745eeb609de45fdb7c538": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "97fc2b8473de4a1c861c6b484158f379": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "9e5194ec7d6b47f48bcefb6729721921": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a491d1659a204ef0879b965a53c0207c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "a5288ef19ec5469aaa6d443b4e3e68d0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ae06e33f75d04739b5ecefa67a54fa47": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "afe5ed077b364097894ee0d1b7008c80": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "100%"
      }
     },
     "b1e202f309b141739589a8c97e5f12a9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_449e9f0946db4c90b11d9e60af67c2a5",
       "style": "IPY_MODEL_e5e4aa04e50b4d02b0610be96c535cb0",
       "value": " 3/3 [00:07&lt;00:00,  0.41it/s, v_num=part, train_step_loss=8.050, train_step_loss_step=0.000, train_step_loss_epoch=0.000, epoch_acc=0.0057]"
      }
     },
     "b90234e57da84b1ab216d608d15a8520": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bc529508c33649bbac907c038eb1c5a2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "cdce458aadf84e4d92dac586d38f8479": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "d9bdacafd237465a9e67dd264c59f5d7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "de2f0bf5b83f4dcca843ef7d13a657ec": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "e1aa898186494c5591c48e5fad87bbc0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_8aeb740c96fc482ea3cd53cf3df242a2",
       "max": 3,
       "style": "IPY_MODEL_34581efa12b2491598d6ef69a74e6680",
       "value": 3
      }
     },
     "e5050922d20b4353a663e888880927da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_ae06e33f75d04739b5ecefa67a54fa47",
       "max": 3,
       "style": "IPY_MODEL_78ac826f8d8a48c58efa54e01f38da76",
       "value": 3
      }
     },
     "e5e4aa04e50b4d02b0610be96c535cb0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "edeaa9e30c8b4106909bbd0c825b5660": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "ef30f0b6114e46bbb36a82276b3c1149": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "f0949682a2264200a231e46669a4dcdb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_7cc0eb5691da4feb855dfd43f2aaf12a",
       "style": "IPY_MODEL_cdce458aadf84e4d92dac586d38f8479",
       "value": " 3/3 [00:01&lt;00:00,  1.53it/s]"
      }
     },
     "f55f53b23e3047ecb9905a5683470e56": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "f896f30926fb42d3b7508873853d5016": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "visibility": "hidden",
       "width": "100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
