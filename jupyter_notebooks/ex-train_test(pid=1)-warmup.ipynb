{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07c438f4-4a6c-48f1-be15-b60ad25888ca",
   "metadata": {},
   "source": [
    "# ex-train_test(pid=1) warmup\n",
    "\n",
    "SentenceAx uses 2 NNs, one for task=\"ex\" and another for task=\"cc\". This warmup notebook trains the NN for the task=\"ex\".\n",
    "\n",
    "The warmup NN has small sizes for everything so that it can be trained quickly but not accurately without GPU.\n",
    "\n",
    "After running this notebook, append the suffix \".best\" to the checkpoint file that it outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bdaa0e0-3004-4eaa-9877-bbca287eccd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rrtuc\\Desktop\\backed-up\\python-projects\\SentenceAx\n"
     ]
    }
   ],
   "source": [
    "# this makes sure it starts looking for things from the SentenceAx folder down.\n",
    "import os\n",
    "import sys\n",
    "os.chdir('../')\n",
    "sys.path.insert(0,os.getcwd())\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0f9fa23-d7c2-4c5a-a16f-38dfd02c2f89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(os.environ[\"TOKENIZERS_PARALLELISM\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf61af3b-4c82-4860-9641-e631e5107e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Params import *\n",
    "from ActionConductor import *\n",
    "\n",
    "\n",
    "def main(pid, pred_in_fp=None, split_only=False):\n",
    "    params = Params(pid)\n",
    "    params.d[\"refresh_cache\"] = True\n",
    "    params.d[\"gpus\"] = 0\n",
    "    params.d[\"batch_size\"] = 4\n",
    "    params.d[\"num_epochs\"] = 3\n",
    "    params.d[\"num_steps_per_epoch\"] = 3\n",
    "    params.d[\"model_str\"] = \"bert-base-cased\"\n",
    "    params.d[\"small_train\"] = True\n",
    "    params.d[\"weights_dir\"] = \"weights_warmup\"\n",
    "    params.describe_self()\n",
    "    \n",
    "    conductor = ActionConductor(params, verbose=True)\n",
    "    conductor.delete_all_checkpoints()\n",
    "    print(\"checkpoints:\", conductor.get_all_checkpoint_fp())\n",
    "    conductor.run(pred_in_fp, split_only)\n",
    "    print(\"checkpoints:\", conductor.get_all_checkpoint_fp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a2a9f60-9297-4129-8dd0-edc71196421d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************** new params\n",
      "new params: pid=1, task='ex', action='train_test'\n",
      "params=\n",
      "{'accumulate_grad_batches': 1,\n",
      " 'action': 'train_test',\n",
      " 'batch_size': 4,\n",
      " 'con_weight_str': '1',\n",
      " 'dropout_fun': 0.0,\n",
      " 'gpus': 0,\n",
      " 'gradient_clip_val': 5,\n",
      " 'lr': 2e-05,\n",
      " 'model_str': 'bert-base-cased',\n",
      " 'num_epochs': 3,\n",
      " 'num_iterative_layers': 2,\n",
      " 'num_steps_per_epoch': 3,\n",
      " 'optimizer': 'adamW',\n",
      " 'refresh_cache': True,\n",
      " 'save_k': 1,\n",
      " 'small_train': True,\n",
      " 'task': 'ex',\n",
      " 'val_check_interval': 1.0,\n",
      " 'verbose': False,\n",
      " 'wreg': 0}\n",
      "lightning version is 2.1.0 so it is >= 2.0.1 as required.\n",
      "SEED= 777\n",
      "\n",
      "MInput started reading 'tests/small_extags.txt'\n",
      "...\n",
      "1. Line 521 has no valid extractions.\n",
      "2. Line 1337 has no valid extractions.\n",
      "3. Line 1339 has no valid extractions.\n",
      "MInput finished reading 'tests/small_extags.txt'\n",
      "number of lines= 1471\n",
      "number of used samples=  471\n",
      "number of omitted samples=  3\n",
      "\n",
      "\n",
      "MInput started reading 'input_data/carb-data/dev.txt'\n",
      "...\n",
      "MInput finished reading 'input_data/carb-data/dev.txt'\n",
      "number of lines= 1283\n",
      "number of used samples=  641\n",
      "number of omitted samples=  0\n",
      "\n",
      "\n",
      "MInput started reading 'input_data/carb-data/test.txt'\n",
      "...\n",
      "MInput finished reading 'input_data/carb-data/test.txt'\n",
      "number of lines= 1283\n",
      "number of used samples=  641\n",
      "number of omitted samples=  0\n",
      "\n",
      "PaddedMInput omitting these extractions: sample= 96, depths=[5, 6, 7, 8, 9]\n",
      "PaddedMInput omitting these extractions: sample= 135, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 365, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 387, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 410, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 463, depths=[5, 6]\n",
      "checkpoints: []\n",
      "Saving self.hparams=  \"pi_test\": 3.14\n",
      "****** model name=  train\n",
      "hidden size= 768\n",
      "num_iterative_layers=  2\n",
      "num_encoder_layers=  10\n",
      "total num layers=  12\n",
      "iterative_transformer= ModuleList(\n",
      "  (0): BertLayer(\n",
      "    (attention): BertAttention(\n",
      "      (self): BertSelfAttention(\n",
      "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (output): BertSelfOutput(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (intermediate): BertIntermediate(\n",
      "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (intermediate_act_fn): GELUActivation()\n",
      "    )\n",
      "    (output): BertOutput(\n",
      "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (1): BertLayer(\n",
      "    (attention): BertAttention(\n",
      "      (self): BertSelfAttention(\n",
      "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (output): BertSelfOutput(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (intermediate): BertIntermediate(\n",
      "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (intermediate_act_fn): GELUActivation()\n",
      "    )\n",
      "    (output): BertOutput(\n",
      "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name                  | Type             | Params\n",
      "-----------------------------------------------------------\n",
      "0 | starting_model        | BertModel        | 94.1 M\n",
      "1 | iterative_transformer | ModuleList       | 14.2 M\n",
      "2 | dropout_fun           | Dropout          | 0     \n",
      "3 | embedding             | Embedding        | 76.8 K\n",
      "4 | merge_layer           | Linear           | 230 K \n",
      "5 | ilabelling_layer      | Linear           | 1.8 K \n",
      "6 | loss_fun              | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------------------\n",
      "108 M     Trainable params\n",
      "0         Non-trainable params\n",
      "108 M     Total params\n",
      "434.478   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4168be49e914355ac3f7f6735a9dfcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                 | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering Model.training_step method, batch_idx=0\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 121])\n",
      "after starting_model, lll_hidden_state.shape torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 4, torch.Size([4, 86, 6])\n",
      "len(llll_word_score)= 5\n",
      "llll_word_score[0].shape torch.Size([4, 86, 6])\n",
      "Entering Model.training_step method, batch_idx=1\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 121])\n",
      "after starting_model, lll_hidden_state.shape torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 4, torch.Size([4, 86, 6])\n",
      "len(llll_word_score)= 5\n",
      "llll_word_score[0].shape torch.Size([4, 86, 6])\n",
      "Entering Model.training_step method, batch_idx=2\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 121])\n",
      "after starting_model, lll_hidden_state.shape torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 4, torch.Size([4, 86, 6])\n",
      "len(llll_word_score)= 5\n",
      "llll_word_score[0].shape torch.Size([4, 86, 6])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering Model.validation_step method, batch_idx=0\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 105])\n",
      "after starting_model, lll_hidden_state.shape torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 84, 6])\n",
      "len(llll_word_score)= 4\n",
      "llll_word_score[0].shape torch.Size([4, 84, 6])\n",
      "Entering Model.validation_step method, batch_idx=1\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 105])\n",
      "after starting_model, lll_hidden_state.shape torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 84, 6])\n",
      "len(llll_word_score)= 4\n",
      "llll_word_score[0].shape torch.Size([4, 84, 6])\n",
      "Entering Model.validation_step method, batch_idx=2\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 105])\n",
      "after starting_model, lll_hidden_state.shape torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 84, 6])\n",
      "len(llll_word_score)= 4\n",
      "llll_word_score[0].shape torch.Size([4, 84, 6])\n",
      "Entering Model.on_validation_epoch_end method\n",
      "Entering ExMetric.__call__() method.\n",
      "len(self.osentL_to_exs) before merge= 0\n",
      "len(self.osentL_to_exs) after merge= 4\n",
      "Entering ExMetric.__call__() method.\n",
      "len(self.osentL_to_exs) before merge= 4\n",
      "len(self.osentL_to_exs) after merge= 8\n",
      "Entering ExMetric.__call__() method.\n",
      "len(self.osentL_to_exs) before merge= 8\n",
      "len(self.osentL_to_exs) after merge= 12\n",
      "Entering ExMetric.get_score_d() method.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 3: 'epoch_acc' reached 0.00570 (best 0.00570), saving model to 'C:\\\\Users\\\\rrtuc\\\\Desktop\\\\backed-up\\\\python-projects\\\\SentenceAx\\\\weights\\\\ex_model\\\\epoch=00_epoch_acc=0.006.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores at end of epoch 0:\n",
      "{'AUC': 0.0003, 'F1': 0.0057, 'epoch_acc': 0.0057, 'last_F1': 0.0057}\n",
      "Entering Model.training_step method, batch_idx=0\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 121])\n",
      "after starting_model, lll_hidden_state.shape torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 4, torch.Size([4, 86, 6])\n",
      "len(llll_word_score)= 5\n",
      "llll_word_score[0].shape torch.Size([4, 86, 6])\n",
      "Entering Model.training_step method, batch_idx=1\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 121])\n",
      "after starting_model, lll_hidden_state.shape torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 4, torch.Size([4, 86, 6])\n",
      "len(llll_word_score)= 5\n",
      "llll_word_score[0].shape torch.Size([4, 86, 6])\n",
      "Entering Model.training_step method, batch_idx=2\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 121])\n",
      "after starting_model, lll_hidden_state.shape torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 4, torch.Size([4, 86, 6])\n",
      "len(llll_word_score)= 5\n",
      "llll_word_score[0].shape torch.Size([4, 86, 6])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering Model.validation_step method, batch_idx=0\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 105])\n",
      "after starting_model, lll_hidden_state.shape torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 84, 6])\n",
      "len(llll_word_score)= 4\n",
      "llll_word_score[0].shape torch.Size([4, 84, 6])\n",
      "Entering Model.validation_step method, batch_idx=1\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 105])\n",
      "after starting_model, lll_hidden_state.shape torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 84, 6])\n",
      "len(llll_word_score)= 4\n",
      "llll_word_score[0].shape torch.Size([4, 84, 6])\n",
      "Entering Model.validation_step method, batch_idx=2\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 105])\n",
      "after starting_model, lll_hidden_state.shape torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 84, 6])\n",
      "len(llll_word_score)= 4\n",
      "llll_word_score[0].shape torch.Size([4, 84, 6])\n",
      "Entering Model.on_validation_epoch_end method\n",
      "Entering ExMetric.__call__() method.\n",
      "len(self.osentL_to_exs) before merge= 0\n",
      "len(self.osentL_to_exs) after merge= 4\n",
      "Entering ExMetric.__call__() method.\n",
      "len(self.osentL_to_exs) before merge= 4\n",
      "len(self.osentL_to_exs) after merge= 8\n",
      "Entering ExMetric.__call__() method.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 6: 'epoch_acc' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(self.osentL_to_exs) before merge= 8\n",
      "len(self.osentL_to_exs) after merge= 12\n",
      "Entering ExMetric.get_score_d() method.\n",
      "\n",
      "Scores at end of epoch 1:\n",
      "{'AUC': 0.0003, 'F1': 0.0057, 'epoch_acc': 0.0057, 'last_F1': 0.0057}\n",
      "Entering Model.training_step method, batch_idx=0\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 121])\n",
      "after starting_model, lll_hidden_state.shape torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 4, torch.Size([4, 86, 6])\n",
      "len(llll_word_score)= 5\n",
      "llll_word_score[0].shape torch.Size([4, 86, 6])\n",
      "Entering Model.training_step method, batch_idx=1\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 121])\n",
      "after starting_model, lll_hidden_state.shape torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 4, torch.Size([4, 86, 6])\n",
      "len(llll_word_score)= 5\n",
      "llll_word_score[0].shape torch.Size([4, 86, 6])\n",
      "Entering Model.training_step method, batch_idx=2\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 121])\n",
      "after starting_model, lll_hidden_state.shape torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([4, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([4, 86, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 4, torch.Size([4, 86, 6])\n",
      "len(llll_word_score)= 5\n",
      "llll_word_score[0].shape torch.Size([4, 86, 6])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering Model.validation_step method, batch_idx=0\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 105])\n",
      "after starting_model, lll_hidden_state.shape torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 84, 6])\n",
      "len(llll_word_score)= 4\n",
      "llll_word_score[0].shape torch.Size([4, 84, 6])\n",
      "Entering Model.validation_step method, batch_idx=1\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 105])\n",
      "after starting_model, lll_hidden_state.shape torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 84, 6])\n",
      "len(llll_word_score)= 4\n",
      "llll_word_score[0].shape torch.Size([4, 84, 6])\n",
      "Entering Model.validation_step method, batch_idx=2\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 105])\n",
      "after starting_model, lll_hidden_state.shape torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 84, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 84, 6])\n",
      "len(llll_word_score)= 4\n",
      "llll_word_score[0].shape torch.Size([4, 84, 6])\n",
      "Entering Model.on_validation_epoch_end method\n",
      "Entering ExMetric.__call__() method.\n",
      "len(self.osentL_to_exs) before merge= 0\n",
      "len(self.osentL_to_exs) after merge= 4\n",
      "Entering ExMetric.__call__() method.\n",
      "len(self.osentL_to_exs) before merge= 4\n",
      "len(self.osentL_to_exs) after merge= 8\n",
      "Entering ExMetric.__call__() method.\n",
      "len(self.osentL_to_exs) before merge= 8\n",
      "len(self.osentL_to_exs) after merge= 12\n",
      "Entering ExMetric.get_score_d() method.\n",
      "\n",
      "Scores at end of epoch 2:\n",
      "{'AUC': 0.0003, 'F1': 0.0057, 'epoch_acc': 0.0057, 'last_F1': 0.0057}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 9: 'epoch_acc' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving self.hparams=  \"pi_test\": 3.14\n",
      "****** model name=  test\n",
      "hidden size= 768\n",
      "num_iterative_layers=  2\n",
      "num_encoder_layers=  10\n",
      "total num layers=  12\n",
      "iterative_transformer= ModuleList(\n",
      "  (0): BertLayer(\n",
      "    (attention): BertAttention(\n",
      "      (self): BertSelfAttention(\n",
      "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (output): BertSelfOutput(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (intermediate): BertIntermediate(\n",
      "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (intermediate_act_fn): GELUActivation()\n",
      "    )\n",
      "    (output): BertOutput(\n",
      "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (1): BertLayer(\n",
      "    (attention): BertAttention(\n",
      "      (self): BertSelfAttention(\n",
      "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (output): BertSelfOutput(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (intermediate): BertIntermediate(\n",
      "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (intermediate_act_fn): GELUActivation()\n",
      "    )\n",
      "    (output): BertOutput(\n",
      "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Restoring states from the checkpoint path at weights/ex_model\\epoch=00_epoch_acc=0.006.ckpt\n",
      "Loaded model weights from the checkpoint at weights/ex_model\\epoch=00_epoch_acc=0.006.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da9abd28de1c4ab4ab54c9766822d42f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                                                  | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering Model.test_step method, batch_idx=0\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 77])\n",
      "after starting_model, lll_hidden_state.shape torch.Size([4, 77, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 66, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 66, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 66, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 66, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 66, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 66, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 66, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 66, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 66, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 66, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 66, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 66, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 66, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 66, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 66, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 66, 6])\n",
      "len(llll_word_score)= 4\n",
      "llll_word_score[0].shape torch.Size([4, 66, 6])\n",
      "Entering Model.test_step method, batch_idx=1\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 77])\n",
      "after starting_model, lll_hidden_state.shape torch.Size([4, 77, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 66, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 66, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 66, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 66, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 66, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 66, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 66, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 66, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 66, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 66, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 66, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 66, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 66, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 66, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 66, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 66, 6])\n",
      "len(llll_word_score)= 4\n",
      "llll_word_score[0].shape torch.Size([4, 66, 6])\n",
      "Entering Model.test_step method, batch_idx=2\n",
      "\n",
      "ll_osent_icode.shape torch.Size([4, 77])\n",
      "after starting_model, lll_hidden_state.shape torch.Size([4, 77, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([4, 77, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 66, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 66, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([4, 66, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([4, 66, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([4, 77, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 66, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 66, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([4, 66, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([4, 66, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([4, 77, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 66, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 66, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([4, 66, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([4, 66, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([4, 77, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 66, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 66, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([4, 66, 300])\n",
      "after ilabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([4, 66, 6])\n",
      "len(llll_word_score)= 4\n",
      "llll_word_score[0].shape torch.Size([4, 66, 6])\n",
      "Entering Model.on_test_epoch_end method\n",
      "Entering ExMetric.__call__() method.\n",
      "len(self.osentL_to_exs) before merge= 0\n",
      "len(self.osentL_to_exs) after merge= 4\n",
      "Entering ExMetric.__call__() method.\n",
      "len(self.osentL_to_exs) before merge= 4\n",
      "len(self.osentL_to_exs) after merge= 8\n",
      "Entering ExMetric.__call__() method.\n",
      "len(self.osentL_to_exs) before merge= 8\n",
      "len(self.osentL_to_exs) after merge= 12\n",
      "Entering ExMetric.get_score_d() method.\n",
      "\n",
      "Scores at end of epoch 0:\n",
      "{'AUC': 0.0003, 'F1': 0.0026, 'epoch_acc': 0.0026, 'last_F1': 0.0026}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         epoch_acc         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.0026000000070780516   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        loss_epoch         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        epoch_acc        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0026000000070780516  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       loss_epoch        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints: ['weights/ex_model\\\\epoch=00_epoch_acc=0.006.ckpt']\n"
     ]
    }
   ],
   "source": [
    "main(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "060d7bcb2f824491a39edb15104e9749": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "0792efe2d16544b7a1ffa7beabfcb002": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "0b633974f1fd4a3e9659c84d8aa3b750": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_1482f5a19dd7452aa636802bed758f45",
       "style": "IPY_MODEL_d90f2006d9304213971ff3d6b3c2057b",
       "value": "Validation DataLoader 0: 100%"
      }
     },
     "1482f5a19dd7452aa636802bed758f45": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "19d8772960a248ffab56208398e897df": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "1b90db9dbbf74c67b606cf0b2fc8655f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "215b4e40f89d4e5ba0e9be7f3ff627c6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "25e629289bd5471d8256e2aaa8d39970": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_e34e8f84a2b941ca83f486f2d96b555d",
       "style": "IPY_MODEL_215b4e40f89d4e5ba0e9be7f3ff627c6",
       "value": " 3/3 [00:02&lt;00:00,  1.30it/s]"
      }
     },
     "2d28a0c9a5eb41c0ba10445620d13af5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "100%"
      }
     },
     "2f0b594ad8a74c6ea57273389fa98174": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_f4931c98ae1f42c694716a6b7a0a1348",
       "max": 3,
       "style": "IPY_MODEL_39589f583f1c4339bd56e7574bec51f4",
       "value": 3
      }
     },
     "32360b80a00f4886a72eef7ac65a292b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "39589f583f1c4339bd56e7574bec51f4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "3e5aa2f441ce43bba9ac02fd70de4a62": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_b39662fed1a34f8d92c0cbcaadbd3aed",
        "IPY_MODEL_2f0b594ad8a74c6ea57273389fa98174",
        "IPY_MODEL_25e629289bd5471d8256e2aaa8d39970"
       ],
       "layout": "IPY_MODEL_ba6760cfa80c4e0281fc0e144ea6fd8f"
      }
     },
     "3ef9c27a109c42ee97f6367c6455d107": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "44f40484cb8a440fbf184baed4f21c40": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_7f356c0dcc1645b09df55131e0ee71a4",
       "style": "IPY_MODEL_8463aa09a44c4833a043c3c9c7661efe",
       "value": "Validation DataLoader 0: 100%"
      }
     },
     "48e12fcf0c774d709dcc7cbc8fae7b45": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "583aacc6eb534dd8af6d79d79ddabdaa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_7112d7c10a7b407789e5deb5ffa52526",
       "style": "IPY_MODEL_48e12fcf0c774d709dcc7cbc8fae7b45",
       "value": " 3/3 [00:03&lt;00:00,  0.88it/s]"
      }
     },
     "65a7fe683e43463bbcb4bc892767d508": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_dbc77a3380b54847b76d5d730b670630",
        "IPY_MODEL_ec26617e10584ebda2d75dfe60fc431e",
        "IPY_MODEL_a83e28e1b659461ea9dd94031a9fde8f"
       ],
       "layout": "IPY_MODEL_2d28a0c9a5eb41c0ba10445620d13af5"
      }
     },
     "660030051de94766bbf3979eea5729f9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6afc6696947b44b1a8acf1aa0579c1f0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "6b774c617b2945b7b3e024c11ab876bc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "visibility": "hidden",
       "width": "100%"
      }
     },
     "7112d7c10a7b407789e5deb5ffa52526": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "741e835a3f004fefaa47a51d913886e7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "79883f345ad0472c99d17b3eaf931e06": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "79989c66782447168c40856840bff186": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "7f356c0dcc1645b09df55131e0ee71a4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8463aa09a44c4833a043c3c9c7661efe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "8c008a62d114492e87397e002fe7b393": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "8cc213b41717445ea1e6b1ba93bfc5e5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "8db1a154aa8d43b28cd979d826fad424": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_f8e544e0219247769dcc9d99cb2c450d",
       "style": "IPY_MODEL_8cc213b41717445ea1e6b1ba93bfc5e5",
       "value": "Validation DataLoader 0: 100%"
      }
     },
     "92980f7ac1814e4197b67f41e5d8fa30": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "95abba42ebd14ed1832762c4f270a68c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "a83e28e1b659461ea9dd94031a9fde8f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_741e835a3f004fefaa47a51d913886e7",
       "style": "IPY_MODEL_19d8772960a248ffab56208398e897df",
       "value": " 3/3 [00:09&lt;00:00,  0.30it/s, v_num=part, loss=8.050, loss_step=0.000, loss_epoch=0.000, epoch_acc=0.0057]"
      }
     },
     "adaca67d22e448449dc709dc1f8d0e6d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_6afc6696947b44b1a8acf1aa0579c1f0",
       "max": 3,
       "style": "IPY_MODEL_060d7bcb2f824491a39edb15104e9749",
       "value": 3
      }
     },
     "b39662fed1a34f8d92c0cbcaadbd3aed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_1b90db9dbbf74c67b606cf0b2fc8655f",
       "style": "IPY_MODEL_cdb9480c90014bd29fb52d2a0f0e1e89",
       "value": "Testing DataLoader 0: 100%"
      }
     },
     "b824f79e603a4f718cd8bee4c16a289a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_79883f345ad0472c99d17b3eaf931e06",
       "max": 3,
       "style": "IPY_MODEL_95abba42ebd14ed1832762c4f270a68c",
       "value": 3
      }
     },
     "ba6760cfa80c4e0281fc0e144ea6fd8f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "100%"
      }
     },
     "bd75f58ee1644a18a8fd817563553885": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_ee5880bcb64f412ca164ed7032a38474",
       "style": "IPY_MODEL_92980f7ac1814e4197b67f41e5d8fa30",
       "value": " 3/3 [00:03&lt;00:00,  0.94it/s]"
      }
     },
     "cdb9480c90014bd29fb52d2a0f0e1e89": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "cf6280b747444da2bb24eacb781f0835": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "visibility": "hidden",
       "width": "100%"
      }
     },
     "d90f2006d9304213971ff3d6b3c2057b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "dbc77a3380b54847b76d5d730b670630": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_660030051de94766bbf3979eea5729f9",
       "style": "IPY_MODEL_79989c66782447168c40856840bff186",
       "value": "Epoch 2: 100%"
      }
     },
     "dd39c8617b9d4808aaedfc6299a7368f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e0497098579344a5a89019c8d19a519d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_dd39c8617b9d4808aaedfc6299a7368f",
       "style": "IPY_MODEL_0792efe2d16544b7a1ffa7beabfcb002",
       "value": " 3/3 [00:03&lt;00:00,  0.88it/s]"
      }
     },
     "e0f683a45d6446d4bc42824eb7d0d814": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "e34e8f84a2b941ca83f486f2d96b555d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ec26617e10584ebda2d75dfe60fc431e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_3ef9c27a109c42ee97f6367c6455d107",
       "max": 3,
       "style": "IPY_MODEL_8c008a62d114492e87397e002fe7b393",
       "value": 3
      }
     },
     "ec54541f66be44ce8226442f5aa866cb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_e0f683a45d6446d4bc42824eb7d0d814",
       "max": 3,
       "style": "IPY_MODEL_32360b80a00f4886a72eef7ac65a292b",
       "value": 3
      }
     },
     "ee5880bcb64f412ca164ed7032a38474": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f4931c98ae1f42c694716a6b7a0a1348": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "f8e544e0219247769dcc9d99cb2c450d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "faadd47416bb437aa13842c29ae50058": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "visibility": "hidden",
       "width": "100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
