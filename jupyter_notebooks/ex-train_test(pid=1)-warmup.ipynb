{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07c438f4-4a6c-48f1-be15-b60ad25888ca",
   "metadata": {},
   "source": [
    "# ex-train_test(pid=1) warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bdaa0e0-3004-4eaa-9877-bbca287eccd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/SentenceAx\n"
     ]
    }
   ],
   "source": [
    "# this makes sure it starts looking for things from the SentenceAx folder down.\n",
    "import os\n",
    "import sys\n",
    "os.chdir('../')\n",
    "sys.path.insert(0,os.getcwd())\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0f9fa23-d7c2-4c5a-a16f-38dfd02c2f89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(os.environ[\"TOKENIZERS_PARALLELISM\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf61af3b-4c82-4860-9641-e631e5107e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightning version is 2.1.0 so it is >= 2.0.1 as required.\n"
     ]
    }
   ],
   "source": [
    "from Params import *\n",
    "from ActionConductor import *\n",
    "\n",
    "\n",
    "def main(pid):\n",
    "    params = Params(pid)\n",
    "    params.d[\"refresh_cache\"] = True\n",
    "    params.d[\"gpus\"] = 0\n",
    "    params.d[\"num_epochs\"] = 1\n",
    "    params.d[\"num_steps_per_epoch\"] = 1\n",
    "    params.d[\"model_str\"] = \"bert-base-cased\"\n",
    "    params.describe_self()\n",
    "    \n",
    "    # in sax_globals.py file, \n",
    "    # set EXTAGS_TRAIN_FP = \"tests/small_extags.txt\" for this warmup run\n",
    "    print(\"EXTAGS_TRAIN_FP=\", EXTAGS_TRAIN_FP)\n",
    "    \n",
    "    conductor = ActionConductor(params, verbose=True)\n",
    "    conductor.delete_all_checkpoints()\n",
    "    print(\"checkpoints:\", conductor.get_all_checkpoint_fp())\n",
    "    conductor.run()\n",
    "    print(\"checkpoints:\", conductor.get_all_checkpoint_fp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a2a9f60-9297-4129-8dd0-edc71196421d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************** new params\n",
      "new params: pid=1, task='ex', action='train_test'\n",
      "params=\n",
      "{'accumulate_grad_batches': 1,\n",
      " 'action': 'train_test',\n",
      " 'batch_size': 24,\n",
      " 'best_checkpoint_fp': '',\n",
      " 'con_weight_str': '1',\n",
      " 'do_rescoring': False,\n",
      " 'dropout_fun': 0.0,\n",
      " 'gpus': 0,\n",
      " 'gradient_clip_val': 5,\n",
      " 'lr': 2e-05,\n",
      " 'model_str': 'bert-base-cased',\n",
      " 'num_epochs': 1,\n",
      " 'num_extractions': 5,\n",
      " 'num_iterative_layers': 2,\n",
      " 'num_steps_per_epoch': 1,\n",
      " 'optimizer': 'adamW',\n",
      " 'refresh_cache': True,\n",
      " 'save_k': 1,\n",
      " 'task': 'ex',\n",
      " 'val_check_interval': 1.0,\n",
      " 'verbose': False,\n",
      " 'wreg': 0,\n",
      " 'write_allen_file': True,\n",
      " 'write_extags_file': True}\n",
      "VERBOSE= True\n",
      "EXTAGS_TRAIN_FP= tests/extags_train.txt\n",
      "\n",
      "MInput started reading 'tests/extags_train.txt'\n",
      "...\n",
      "1. Line 364 has no valid extractions.\n",
      "2. Line 375 has no valid extractions.\n",
      "3. Line 450 has no valid extractions.\n",
      "4. Line 521 has no valid extractions.\n",
      "5. Line 794 has no valid extractions.\n",
      "MInput finished reading 'tests/extags_train.txt'\n",
      "number of lines= 872\n",
      "number of used samples=  281\n",
      "number of omitted samples=  5\n",
      "\n",
      "\n",
      "MInput started reading 'input_data/carb-data/dev.txt'\n",
      "...\n",
      "MInput finished reading 'input_data/carb-data/dev.txt'\n",
      "number of lines= 1283\n",
      "number of used samples=  641\n",
      "number of omitted samples=  0\n",
      "\n",
      "\n",
      "MInput started reading 'input_data/carb-data/test.txt'\n",
      "...\n",
      "MInput finished reading 'input_data/carb-data/test.txt'\n",
      "number of lines= 1283\n",
      "number of used samples=  641\n",
      "number of omitted samples=  0\n",
      "\n",
      "PaddedMInput omitting these extractions: sample= 96, depths=[5, 6, 7, 8, 9]\n",
      "PaddedMInput omitting these extractions: sample= 133, depths=[5]\n",
      "checkpoints: []\n",
      "****** model name=  train\n",
      "hidden size= 768\n",
      "num_iterative_layers=  2\n",
      "num_encoder_layers=  10\n",
      "total num layers=  12\n",
      "iterative_transformer= ModuleList(\n",
      "  (0-1): 2 x BertLayer(\n",
      "    (attention): BertAttention(\n",
      "      (self): BertSelfAttention(\n",
      "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (output): BertSelfOutput(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (intermediate): BertIntermediate(\n",
      "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (intermediate_act_fn): GELUActivation()\n",
      "    )\n",
      "    (output): BertOutput(\n",
      "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Retiring current log file by changing its name\n",
      "logs/ex/train_7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_train_batches=1)` was configured so 1 batch per epoch will be used.\n",
      "`Trainer(limit_val_batches=1)` was configured so 1 batch will be used.\n",
      "`Trainer(limit_test_batches=1)` was configured so 1 batch will be used.\n",
      "\n",
      "  | Name                  | Type             | Params\n",
      "-----------------------------------------------------------\n",
      "0 | start_model           | BertModel        | 94.1 M\n",
      "1 | iterative_transformer | ModuleList       | 14.2 M\n",
      "2 | dropout_fun           | Dropout          | 0     \n",
      "3 | embedding             | Embedding        | 76.8 K\n",
      "4 | merge_layer           | Linear           | 230 K \n",
      "5 | ilabelling_layer      | Linear           | 1.8 K \n",
      "6 | loss_fun              | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------------------\n",
      "108 M     Trainable params\n",
      "0         Non-trainable params\n",
      "108 M     Total params\n",
      "434.478   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering Model.validation_step method, batch_idx=0\n",
      "\n",
      "ll_osent_icode.shape torch.Size([24, 105])\n",
      "after start_model, lll_hidden_state.shape torch.Size([24, 105, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([24, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([24, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([24, 84, 300])\n",
      "after illabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([24, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([24, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([24, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([24, 84, 300])\n",
      "after illabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([24, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([24, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([24, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([24, 84, 300])\n",
      "after illabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([24, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([24, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([24, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([24, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([24, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([24, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([24, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([24, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([24, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([24, 84, 300])\n",
      "after illabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([24, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([24, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([24, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([24, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([24, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([24, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([24, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([24, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([24, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([24, 84, 300])\n",
      "after illabelling layer: depth, lll_word_score.shape\n",
      "\t 4, torch.Size([24, 84, 6])\n",
      "Entering Model.on_validation_epoch_end method\n",
      "Entering ExMetric.__call__() method.\n",
      "len(self.osentL_to_exs) before merge= 0\n",
      "len(self.osentL_to_exs) after merge= 24\n",
      "Entering ExMetric.get_score_d() method.\n",
      "\n",
      "Scores at end of epoch 0:\n",
      "OrderedDict([('AUC', 0.0007), ('F1', 0.0085), ('last_F1', 0.0085), ('epoch_acc', 0.0085)])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cf4c383b46748869a6409a20b05be55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering Model.training_step method, batch_idx=0\n",
      "\n",
      "ll_osent_icode.shape torch.Size([24, 121])\n",
      "after start_model, lll_hidden_state.shape torch.Size([24, 121, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([24, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([24, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([24, 86, 300])\n",
      "after illabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([24, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([24, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([24, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([24, 86, 300])\n",
      "after illabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([24, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([24, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([24, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([24, 86, 300])\n",
      "after illabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([24, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([24, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([24, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([24, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([24, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([24, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([24, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([24, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([24, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([24, 86, 300])\n",
      "after illabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([24, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([24, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([24, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([24, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([24, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([24, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([24, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([24, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([24, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([24, 86, 300])\n",
      "after illabelling layer: depth, lll_word_score.shape\n",
      "\t 4, torch.Size([24, 86, 6])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering Model.validation_step method, batch_idx=0\n",
      "\n",
      "ll_osent_icode.shape torch.Size([24, 105])\n",
      "after start_model, lll_hidden_state.shape torch.Size([24, 105, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([24, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([24, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([24, 84, 300])\n",
      "after illabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([24, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([24, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([24, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([24, 84, 300])\n",
      "after illabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([24, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([24, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([24, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([24, 84, 300])\n",
      "after illabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([24, 84, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 1: 'epoch_acc' reached 0.00200 (best 0.00200), saving model to '/home/studio-lab-user/sagemaker-studiolab-notebooks/SentenceAx/weights/ex_model/epoch=00_epoch_acc=0.002.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering Model.on_validation_epoch_end method\n",
      "Entering ExMetric.__call__() method.\n",
      "len(self.osentL_to_exs) before merge= 0\n",
      "len(self.osentL_to_exs) after merge= 24\n",
      "Entering ExMetric.get_score_d() method.\n",
      "\n",
      "Scores at end of epoch 0:\n",
      "OrderedDict([('AUC', 0.0004), ('F1', 0.002), ('last_F1', 0.002), ('epoch_acc', 0.002)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_train_batches=1)` was configured so 1 batch per epoch will be used.\n",
      "`Trainer(limit_val_batches=1)` was configured so 1 batch will be used.\n",
      "`Trainer(limit_test_batches=1)` was configured so 1 batch will be used.\n",
      "Restoring states from the checkpoint path at weights/ex_model/epoch=00_epoch_acc=0.002.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** model name=  test\n",
      "hidden size= 768\n",
      "num_iterative_layers=  2\n",
      "num_encoder_layers=  10\n",
      "total num layers=  12\n",
      "iterative_transformer= ModuleList(\n",
      "  (0-1): 2 x BertLayer(\n",
      "    (attention): BertAttention(\n",
      "      (self): BertSelfAttention(\n",
      "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (output): BertSelfOutput(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (intermediate): BertIntermediate(\n",
      "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (intermediate_act_fn): GELUActivation()\n",
      "    )\n",
      "    (output): BertOutput(\n",
      "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Retiring current log file by changing its name\n",
      "logs/ex/test_6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded model weights from the checkpoint at weights/ex_model/epoch=00_epoch_acc=0.002.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e37ecdda447940deadd97d089bf61c98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering Model.test_step method, batch_idx=0\n",
      "\n",
      "ll_osent_icode.shape torch.Size([24, 77])\n",
      "after start_model, lll_hidden_state.shape torch.Size([24, 77, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 77, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 77, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 77, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 77, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 77, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 77, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([24, 66, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([24, 66, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([24, 66, 300])\n",
      "after illabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([24, 66, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 77, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 77, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 77, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 77, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 77, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 77, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([24, 66, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([24, 66, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([24, 66, 300])\n",
      "after illabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([24, 66, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 77, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 77, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 77, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 77, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 77, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 77, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([24, 66, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([24, 66, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([24, 66, 300])\n",
      "after illabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([24, 66, 6])\n",
      "Entering Model.on_test_epoch_end method\n",
      "Entering ExMetric.__call__() method.\n",
      "len(self.osentL_to_exs) before merge= 0\n",
      "len(self.osentL_to_exs) after merge= 24\n",
      "Entering ExMetric.get_score_d() method.\n",
      "\n",
      "Scores at end of epoch 0:\n",
      "OrderedDict([('AUC', 0.0001), ('F1', 0.0008), ('last_F1', 0.0008), ('epoch_acc', 0.0008)])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         epoch_acc         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">          0.0008           </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        epoch_acc        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m         0.0008          \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints: ['weights/ex_model/epoch=00_epoch_acc=0.002.ckpt']\n"
     ]
    }
   ],
   "source": [
    "main(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0274617be27b4e47809d69db6954b863": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_7a26a58673f7440d812a2b0800f412ab",
       "style": "IPY_MODEL_f7b47246d1d348d2a0fb59b0d35e5b2e",
       "value": " 1/1 [00:04&lt;00:00,  0.21it/s]"
      }
     },
     "02d4985ce4e1454b811854e256c3d081": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "128b4d4404314ddc9f6651aff644186a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "199bfd30a5854316903224e90a6205f8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "1a9d278c2f6f4ae69c6dd1a1dca7a6f0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_ecb511f31bda4045b1ca29fee92cf1c2",
       "max": 1,
       "style": "IPY_MODEL_ca8ecf2b531e48fa8e507c546ae98384",
       "value": 1
      }
     },
     "1c1980eb18b247b9829e52f96d28f0ea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_b9de6207ae1643af98a0270e77c9a095",
       "style": "IPY_MODEL_199bfd30a5854316903224e90a6205f8",
       "value": "Validation DataLoader 0: 100%"
      }
     },
     "1cab976f41624c08a631b919c85d480e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_e1681f1e0cc94db7b8f67327c7fa3424",
       "style": "IPY_MODEL_bc27481b86af4d34879362d92d47dcdc",
       "value": " 1/1 [00:03&lt;00:00,  0.28it/s]"
      }
     },
     "260b23a080a042bcb4f8898cdafdb0a2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "100%"
      }
     },
     "270e3ec34c9b424b949a15c331163c59": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "342f5493ca3c4966b7f607235f6d4a90": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "39474b27ac624eebbff98ef12536e5d1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "visibility": "hidden",
       "width": "100%"
      }
     },
     "4b16bb43aad848c0886478b3def7b320": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "4d2ff94cd8f84dd1bf8e3565e0089afb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_88fcb231fe734659be94aade6d97cf3c",
       "style": "IPY_MODEL_ad98588b6522471986432456f759ffa6",
       "value": "Epoch 0: 100%"
      }
     },
     "556d2a1e2b054193884e209c0852c85e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "5f52a08bd8a74a05bcee2555994f44c4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_e16475d92c5f4bf6b2c65abc52f1441e",
       "style": "IPY_MODEL_128b4d4404314ddc9f6651aff644186a",
       "value": "Testing DataLoader 0: 100%"
      }
     },
     "65e5af5521994e9395c42ae30dc58f3f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "6cafe7bffbd54143893d69c2fcdd0637": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "visibility": "hidden",
       "width": "100%"
      }
     },
     "6cf4c383b46748869a6409a20b05be55": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_4d2ff94cd8f84dd1bf8e3565e0089afb",
        "IPY_MODEL_1a9d278c2f6f4ae69c6dd1a1dca7a6f0",
        "IPY_MODEL_93d20ab802fc4d448844a972d4779f73"
       ],
       "layout": "IPY_MODEL_260b23a080a042bcb4f8898cdafdb0a2"
      }
     },
     "7374617c15d64c4ea826db6af8104151": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "7817344c320445cfbfc0d3be1567a084": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "785295acb0124b1a8fd5031dfdc216f7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_4b16bb43aad848c0886478b3def7b320",
       "max": 1,
       "style": "IPY_MODEL_556d2a1e2b054193884e209c0852c85e",
       "value": 1
      }
     },
     "79850f2a87de433f8252bf28da698f2f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_f70fe33b110c47349c8028140eac88c3",
       "style": "IPY_MODEL_65e5af5521994e9395c42ae30dc58f3f",
       "value": " 1/1 [00:03&lt;00:00,  0.32it/s]"
      }
     },
     "7a26a58673f7440d812a2b0800f412ab": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "88fcb231fe734659be94aade6d97cf3c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8c57497036a4452a815f7faec09f3bca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "93d20ab802fc4d448844a972d4779f73": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_270e3ec34c9b424b949a15c331163c59",
       "style": "IPY_MODEL_8c57497036a4452a815f7faec09f3bca",
       "value": " 1/1 [00:22&lt;00:00,  0.04it/s, v_num=part, train_step_loss=8.560, epoch_acc=0.002]"
      }
     },
     "ad98588b6522471986432456f759ffa6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "b9de6207ae1643af98a0270e77c9a095": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bc27481b86af4d34879362d92d47dcdc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "ca8ecf2b531e48fa8e507c546ae98384": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "d6e5e277628946e18bcb38f00f6f528a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d9d7181b9a004ddba3cc5b206d804551": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_fd4516b0d1b04a21a3ebbb53f6184a1b",
       "max": 1,
       "style": "IPY_MODEL_7817344c320445cfbfc0d3be1567a084",
       "value": 1
      }
     },
     "db78aa67ced94e12ab4257a6ed49bdd2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "100%"
      }
     },
     "dd3c9ac40c5543079b64715b5f375ba7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_d6e5e277628946e18bcb38f00f6f528a",
       "style": "IPY_MODEL_02d4985ce4e1454b811854e256c3d081",
       "value": "Sanity Checking DataLoader 0: 100%"
      }
     },
     "e16475d92c5f4bf6b2c65abc52f1441e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e1681f1e0cc94db7b8f67327c7fa3424": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e37ecdda447940deadd97d089bf61c98": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_5f52a08bd8a74a05bcee2555994f44c4",
        "IPY_MODEL_d9d7181b9a004ddba3cc5b206d804551",
        "IPY_MODEL_79850f2a87de433f8252bf28da698f2f"
       ],
       "layout": "IPY_MODEL_db78aa67ced94e12ab4257a6ed49bdd2"
      }
     },
     "eb2e36ee53414ce5b42535da4b1a2082": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_7374617c15d64c4ea826db6af8104151",
       "max": 1,
       "style": "IPY_MODEL_342f5493ca3c4966b7f607235f6d4a90",
       "value": 1
      }
     },
     "ecb511f31bda4045b1ca29fee92cf1c2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "f70fe33b110c47349c8028140eac88c3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f7b47246d1d348d2a0fb59b0d35e5b2e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "fd4516b0d1b04a21a3ebbb53f6184a1b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
