{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07c438f4-4a6c-48f1-be15-b60ad25888ca",
   "metadata": {},
   "source": [
    "# ex-train_test(pid=1) warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bdaa0e0-3004-4eaa-9877-bbca287eccd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/SentenceAx\n"
     ]
    }
   ],
   "source": [
    "# this makes sure it starts looking for things from the SentenceAx folder down.\n",
    "import os\n",
    "import sys\n",
    "os.chdir('../')\n",
    "sys.path.insert(0,os.getcwd())\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0f9fa23-d7c2-4c5a-a16f-38dfd02c2f89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(os.environ[\"TOKENIZERS_PARALLELISM\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf61af3b-4c82-4860-9641-e631e5107e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightning version is 2.1.0 so it is >= 2.0.1 as required.\n"
     ]
    }
   ],
   "source": [
    "from Params import *\n",
    "from ActionConductor import *\n",
    "\n",
    "\n",
    "def main(pid):\n",
    "    params = Params(pid)\n",
    "    params.d[\"refresh_cache\"] = True\n",
    "    params.d[\"gpus\"] = 0\n",
    "    params.d[\"num_epochs\"] = 1\n",
    "    params.d[\"num_steps_per_epoch\"] = 1\n",
    "    params.d[\"model_str\"] = \"bert-base-cased\"\n",
    "    params.describe_self()\n",
    "    \n",
    "    # in sax_globals.py file, \n",
    "    # set EXTAGS_TRAIN_FP = \"tests/small_extags.txt\" for this warmup run\n",
    "    print(\"EXTAGS_TRAIN_FP=\", EXTAGS_TRAIN_FP)\n",
    "    \n",
    "    conductor = ActionConductor(params, verbose=True)\n",
    "    conductor.delete_all_checkpoints()\n",
    "    print(\"checkpoints:\", conductor.get_all_checkpoint_fp())\n",
    "    conductor.run()\n",
    "    print(\"checkpoints:\", conductor.get_all_checkpoint_fp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a2a9f60-9297-4129-8dd0-edc71196421d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************** new params\n",
      "new params: pid=1, task='ex', action='train_test'\n",
      "params=\n",
      "{'accumulate_grad_batches': 1,\n",
      " 'action': 'train_test',\n",
      " 'batch_size': 24,\n",
      " 'best_checkpoint_fp': '',\n",
      " 'con_weight_str': '1',\n",
      " 'do_rescoring': False,\n",
      " 'dropout_fun': 0.0,\n",
      " 'gpus': 0,\n",
      " 'gradient_clip_val': 5,\n",
      " 'lr': 2e-05,\n",
      " 'model_str': 'bert-base-cased',\n",
      " 'num_epochs': 1,\n",
      " 'num_extractions': 5,\n",
      " 'num_iterative_layers': 2,\n",
      " 'num_steps_per_epoch': 1,\n",
      " 'optimizer': 'adamW',\n",
      " 'refresh_cache': True,\n",
      " 'save_k': 1,\n",
      " 'task': 'ex',\n",
      " 'val_check_interval': 1.0,\n",
      " 'verbose': False,\n",
      " 'wreg': 0,\n",
      " 'write_allen_file': True,\n",
      " 'write_extags_file': True}\n",
      "EXTAGS_TRAIN_FP= tests/small_extags.txt\n",
      "\n",
      "MInput started reading 'tests/small_extags.txt'\n",
      "...\n",
      "1. Line 364 has no valid extractions.\n",
      "2. Line 375 has no valid extractions.\n",
      "3. Line 450 has no valid extractions.\n",
      "4. Line 521 has no valid extractions.\n",
      "5. Line 794 has no valid extractions.\n",
      "6. Line 1326 has no valid extractions.\n",
      "7. Line 1337 has no valid extractions.\n",
      "8. Line 1339 has no valid extractions.\n",
      "9. Line 1456 has no valid extractions.\n",
      "MInput finished reading 'tests/small_extags.txt'\n",
      "number of lines= 1471\n",
      "number of used samples=  465\n",
      "number of omitted samples=  9\n",
      "\n",
      "\n",
      "MInput started reading 'input_data/carb-data/dev.txt'\n",
      "...\n",
      "MInput finished reading 'input_data/carb-data/dev.txt'\n",
      "number of lines= 1283\n",
      "number of used samples=  641\n",
      "number of omitted samples=  0\n",
      "\n",
      "\n",
      "MInput started reading 'input_data/carb-data/test.txt'\n",
      "...\n",
      "MInput finished reading 'input_data/carb-data/test.txt'\n",
      "number of lines= 1283\n",
      "number of used samples=  641\n",
      "number of omitted samples=  0\n",
      "\n",
      "PaddedMInput omitting these extractions: sample= 96, depths=[5, 6, 7, 8, 9]\n",
      "PaddedMInput omitting these extractions: sample= 133, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 383, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 458, depths=[5, 6]\n",
      "An error occurred: [Errno 2] No such file or directory: 'weights/ex_model'\n",
      "checkpoints: []\n",
      "****** model name=  train\n",
      "hidden size= 768\n",
      "num_iterative_layers=  2\n",
      "num_encoder_layers=  10\n",
      "total num layers=  12\n",
      "iterative_transformer= ModuleList(\n",
      "  (0-1): 2 x BertLayer(\n",
      "    (attention): BertAttention(\n",
      "      (self): BertSelfAttention(\n",
      "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (output): BertSelfOutput(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (intermediate): BertIntermediate(\n",
      "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (intermediate_act_fn): GELUActivation()\n",
      "    )\n",
      "    (output): BertOutput(\n",
      "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_train_batches=1)` was configured so 1 batch per epoch will be used.\n",
      "`Trainer(limit_val_batches=1)` was configured so 1 batch will be used.\n",
      "`Trainer(limit_test_batches=1)` was configured so 1 batch will be used.\n",
      "\n",
      "  | Name                  | Type             | Params\n",
      "-----------------------------------------------------------\n",
      "0 | start_model           | BertModel        | 94.1 M\n",
      "1 | iterative_transformer | ModuleList       | 14.2 M\n",
      "2 | dropout_fun           | Dropout          | 0     \n",
      "3 | embedding             | Embedding        | 76.8 K\n",
      "4 | merge_layer           | Linear           | 230 K \n",
      "5 | ilabelling_layer      | Linear           | 1.8 K \n",
      "6 | loss_fun              | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------------------\n",
      "108 M     Trainable params\n",
      "0         Non-trainable params\n",
      "108 M     Total params\n",
      "434.478   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering Model.validation_step method, batch_idx=0\n",
      "\n",
      "ll_osent_icode.shape torch.Size([24, 105])\n",
      "after start_model, lll_hidden_state.shape torch.Size([24, 105, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([24, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([24, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([24, 84, 300])\n",
      "after illabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([24, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([24, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([24, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([24, 84, 300])\n",
      "after illabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([24, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([24, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([24, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([24, 84, 300])\n",
      "after illabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([24, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([24, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([24, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([24, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([24, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([24, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([24, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([24, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([24, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([24, 84, 300])\n",
      "after illabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([24, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([24, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([24, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([24, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([24, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([24, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([24, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([24, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([24, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([24, 84, 300])\n",
      "after illabelling layer: depth, lll_word_score.shape\n",
      "\t 4, torch.Size([24, 84, 6])\n",
      "Entering Model.on_validation_epoch_end method\n",
      "Entering ExMetric.__call__() method.\n",
      "len(self.osentL_to_exs) before merge= 0\n",
      "len(self.osentL_to_exs) after merge= 24\n",
      "Entering ExMetric.get_score_d() method.\n",
      "\n",
      "Scores at end of epoch 0:\n",
      "OrderedDict([('AUC', 0.0005), ('F1', 0.0111), ('last_F1', 0.0111), ('epoch_acc', 0.0111)])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3f69195c4174e93832e1dd30a92b41e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering Model.training_step method, batch_idx=0\n",
      "\n",
      "ll_osent_icode.shape torch.Size([24, 121])\n",
      "after start_model, lll_hidden_state.shape torch.Size([24, 121, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([24, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([24, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([24, 86, 300])\n",
      "after illabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([24, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([24, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([24, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([24, 86, 300])\n",
      "after illabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([24, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([24, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([24, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([24, 86, 300])\n",
      "after illabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([24, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([24, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([24, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([24, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([24, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([24, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 3, torch.Size([24, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([24, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([24, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 3, torch.Size([24, 86, 300])\n",
      "after illabelling layer: depth, lll_word_score.shape\n",
      "\t 3, torch.Size([24, 86, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([24, 121, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([24, 121, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([24, 121, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([24, 121, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([24, 121, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 4, torch.Size([24, 121, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([24, 86, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([24, 86, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 4, torch.Size([24, 86, 300])\n",
      "after illabelling layer: depth, lll_word_score.shape\n",
      "\t 4, torch.Size([24, 86, 6])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering Model.validation_step method, batch_idx=0\n",
      "\n",
      "ll_osent_icode.shape torch.Size([24, 105])\n",
      "after start_model, lll_hidden_state.shape torch.Size([24, 105, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([24, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([24, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([24, 84, 300])\n",
      "after illabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([24, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([24, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([24, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([24, 84, 300])\n",
      "after illabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([24, 84, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 105, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 105, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 105, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 105, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 105, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 105, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([24, 84, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([24, 84, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([24, 84, 300])\n",
      "after illabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([24, 84, 6])\n",
      "Entering Model.on_validation_epoch_end method\n",
      "Entering ExMetric.__call__() method.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 1: 'epoch_acc' reached 0.00760 (best 0.00760), saving model to '/home/studio-lab-user/sagemaker-studiolab-notebooks/SentenceAx/weights/ex_model/epoch=00_epoch_acc=0.008.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(self.osentL_to_exs) before merge= 0\n",
      "len(self.osentL_to_exs) after merge= 24\n",
      "Entering ExMetric.get_score_d() method.\n",
      "\n",
      "Scores at end of epoch 0:\n",
      "OrderedDict([('AUC', 0.0006), ('F1', 0.0076), ('last_F1', 0.0076), ('epoch_acc', 0.0076)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** model name=  test\n",
      "hidden size= 768\n",
      "num_iterative_layers=  2\n",
      "num_encoder_layers=  10\n",
      "total num layers=  12\n",
      "iterative_transformer= ModuleList(\n",
      "  (0-1): 2 x BertLayer(\n",
      "    (attention): BertAttention(\n",
      "      (self): BertSelfAttention(\n",
      "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (output): BertSelfOutput(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (intermediate): BertIntermediate(\n",
      "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (intermediate_act_fn): GELUActivation()\n",
      "    )\n",
      "    (output): BertOutput(\n",
      "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_train_batches=1)` was configured so 1 batch per epoch will be used.\n",
      "`Trainer(limit_val_batches=1)` was configured so 1 batch will be used.\n",
      "`Trainer(limit_test_batches=1)` was configured so 1 batch will be used.\n",
      "Restoring states from the checkpoint path at weights/ex_model/epoch=00_epoch_acc=0.008.ckpt\n",
      "Loaded model weights from the checkpoint at weights/ex_model/epoch=00_epoch_acc=0.008.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7253d9d78ba49efbe550def74a8f8d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering Model.test_step method, batch_idx=0\n",
      "\n",
      "ll_osent_icode.shape torch.Size([24, 77])\n",
      "after start_model, lll_hidden_state.shape torch.Size([24, 77, 768])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 77, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 77, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 77, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 77, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 77, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 0, torch.Size([24, 77, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([24, 66, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([24, 66, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 0, torch.Size([24, 66, 300])\n",
      "after illabelling layer: depth, lll_word_score.shape\n",
      "\t 0, torch.Size([24, 66, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 77, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 77, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 77, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 77, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 77, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 1, torch.Size([24, 77, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([24, 66, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([24, 66, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 1, torch.Size([24, 66, 300])\n",
      "after illabelling layer: depth, lll_word_score.shape\n",
      "\t 1, torch.Size([24, 66, 6])\n",
      "*********** Starting iterative layer=0\n",
      "before iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 77, 768])\n",
      "after iterative layer 0: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 77, 768])\n",
      "*********** Starting iterative layer=1\n",
      "before iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 77, 768])\n",
      "after iterative layer 1: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 77, 768])\n",
      "before dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 77, 768])\n",
      "after dropout: depth, lll_hidden_state.shape\n",
      "\t 2, torch.Size([24, 77, 768])\n",
      "before merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([24, 66, 768])\n",
      "after merge layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([24, 66, 300])\n",
      "before ilabelling layer: depth, lll_word_hidden_state.shape\n",
      "\t 2, torch.Size([24, 66, 300])\n",
      "after illabelling layer: depth, lll_word_score.shape\n",
      "\t 2, torch.Size([24, 66, 6])\n",
      "Entering Model.on_test_epoch_end method\n",
      "Entering ExMetric.__call__() method.\n",
      "len(self.osentL_to_exs) before merge= 0\n",
      "len(self.osentL_to_exs) after merge= 24\n",
      "Entering ExMetric.get_score_d() method.\n",
      "\n",
      "Scores at end of epoch 0:\n",
      "OrderedDict([('AUC', 0.0005), ('F1', 0.0055), ('last_F1', 0.0055), ('epoch_acc', 0.0055)])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         epoch_acc         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">          0.0055           </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        epoch_acc        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m         0.0055          \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints: ['weights/ex_model/epoch=00_epoch_acc=0.008.ckpt']\n"
     ]
    }
   ],
   "source": [
    "main(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0071a94cb56b4fcca71b8305c27f0da8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_c90eb34321b14c0aa94f525748f3985c",
       "max": 1,
       "style": "IPY_MODEL_fd556aa5e84b41c4b306236acf29d757",
       "value": 1
      }
     },
     "0274d7720c3c4f1294f4021f0dc86355": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "02cf89be3479423cb4f4e099fc2a247a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "100%"
      }
     },
     "0d221cffe05f42a6aa5c0b3f48c04eba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "23136a71982c437e8e8eb0e46e3ce9b4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_ec5628cd1b9248fda667e45b3caa6bc1",
       "style": "IPY_MODEL_ce67a0cc06114f09b3b47683a6c133a4",
       "value": "Testing DataLoader 0: 100%"
      }
     },
     "33237986355d4c10960505ade0c28b70": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_8c79d1136d4541bd90256d21d1c23670",
       "style": "IPY_MODEL_0d221cffe05f42a6aa5c0b3f48c04eba",
       "value": "Validation DataLoader 0: 100%"
      }
     },
     "4a29f07862284dad810e9e2efa177ce6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4bcf4d221e3e47d38b80e66aea6657c5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_61af2204830944f98b24d1ecf1350771",
       "style": "IPY_MODEL_89d20668aed34a6dba2d66d0e0a84a85",
       "value": "Sanity Checking DataLoader 0: 100%"
      }
     },
     "50e9b88576fe4b8f9e5c73a03db22072": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "538c11ce4f5c43bf9c08594bdd0dcaba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "61af2204830944f98b24d1ecf1350771": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6ed6f65b09234845969d77559e821833": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "777a54f3c86c47b78023c3df8d023699": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7cf2939a26f94e20b34fa56fdc0bd341": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_ff4efd5052b84628a2735d3faf850031",
       "style": "IPY_MODEL_6ed6f65b09234845969d77559e821833",
       "value": "Epoch 0: 100%"
      }
     },
     "8758c88bfc814aa693dc990607039139": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "87626da6dea145d0a16961ce71d4e5d0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "89d20668aed34a6dba2d66d0e0a84a85": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "8a05f305d2ae4ad3bb0b56b93b095508": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_9c9a8844e1514f96a995a964e5528016",
       "style": "IPY_MODEL_e35d7d4262dc4f6ea962472ab162f5ed",
       "value": " 1/1 [00:04&lt;00:00,  0.22it/s]"
      }
     },
     "8c79d1136d4541bd90256d21d1c23670": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8fa255d371b14bacb2b3c9a3abe92e22": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "visibility": "hidden",
       "width": "100%"
      }
     },
     "92ec5dcf4283489884e54d87b4b930d9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_baaacc2cd6cf4e79ab984d80c7a2ce0d",
       "style": "IPY_MODEL_538c11ce4f5c43bf9c08594bdd0dcaba",
       "value": " 1/1 [00:05&lt;00:00,  0.17it/s]"
      }
     },
     "976bfc9940b64f5bb556a3a52c251521": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "9c9a8844e1514f96a995a964e5528016": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a3f69195c4174e93832e1dd30a92b41e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_7cf2939a26f94e20b34fa56fdc0bd341",
        "IPY_MODEL_cc2a2e07c36544f48c08534a588c6a96",
        "IPY_MODEL_aedcd75120fd483f840f3b89d0c4424e"
       ],
       "layout": "IPY_MODEL_c51893ad17084e8bab2204f50095ae15"
      }
     },
     "aedcd75120fd483f840f3b89d0c4424e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_777a54f3c86c47b78023c3df8d023699",
       "style": "IPY_MODEL_976bfc9940b64f5bb556a3a52c251521",
       "value": " 1/1 [00:31&lt;00:00,  0.03it/s, v_num=part, train_step_loss=9.250, epoch_acc=0.0076]"
      }
     },
     "b0da7f3b679d4c088d5c1fa11a9419c7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_fbd7a0fc36f145e9885fee481d4f523d",
       "max": 1,
       "style": "IPY_MODEL_0274d7720c3c4f1294f4021f0dc86355",
       "value": 1
      }
     },
     "b5071fa9084b460cb6de2c450d62a238": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_4a29f07862284dad810e9e2efa177ce6",
       "style": "IPY_MODEL_87626da6dea145d0a16961ce71d4e5d0",
       "value": " 1/1 [00:04&lt;00:00,  0.24it/s]"
      }
     },
     "baaacc2cd6cf4e79ab984d80c7a2ce0d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c51893ad17084e8bab2204f50095ae15": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "100%"
      }
     },
     "c7253d9d78ba49efbe550def74a8f8d4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_23136a71982c437e8e8eb0e46e3ce9b4",
        "IPY_MODEL_b0da7f3b679d4c088d5c1fa11a9419c7",
        "IPY_MODEL_b5071fa9084b460cb6de2c450d62a238"
       ],
       "layout": "IPY_MODEL_02cf89be3479423cb4f4e099fc2a247a"
      }
     },
     "c90eb34321b14c0aa94f525748f3985c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "cc2a2e07c36544f48c08534a588c6a96": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_8758c88bfc814aa693dc990607039139",
       "max": 1,
       "style": "IPY_MODEL_df85056cfb8d4c7b9900566f76d4eda3",
       "value": 1
      }
     },
     "ce67a0cc06114f09b3b47683a6c133a4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "d9c19bb7e9ab4b05ad9e30ca0db851cf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "df85056cfb8d4c7b9900566f76d4eda3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "e35d7d4262dc4f6ea962472ab162f5ed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "e7454c948f0f4198a674b962ed71a456": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_d9c19bb7e9ab4b05ad9e30ca0db851cf",
       "max": 1,
       "style": "IPY_MODEL_50e9b88576fe4b8f9e5c73a03db22072",
       "value": 1
      }
     },
     "ec5628cd1b9248fda667e45b3caa6bc1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f5fef681b9254742a60ff73fbed194ae": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "visibility": "hidden",
       "width": "100%"
      }
     },
     "fbd7a0fc36f145e9885fee481d4f523d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "fd556aa5e84b41c4b306236acf29d757": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "ff4efd5052b84628a2735d3faf850031": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
