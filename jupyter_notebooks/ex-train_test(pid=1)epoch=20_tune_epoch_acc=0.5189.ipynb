{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00cfba6a-81d7-49fa-85cc-bdf1d7c182c2",
   "metadata": {},
   "source": [
    "# ex-train_test(pid=1)\n",
    "\n",
    "SentenceAx uses 2 NNs, one for task=\"ex\" and another for task=\"cc\". This notebook trains the fullly-fledged (not a warmup) NN for the task=\"ex\". \n",
    "\n",
    "<font color='red'>**After running this notebook, append the suffix \".best\" to the checkpoint file (in the `weights/ex_model` directory) that this notebook outputs. Otherwise, the checkpoint generated by this run of this notebook will be erased in the next run. Furthermore, notebooks for predicting that need a weights file, won't find one, as they are designed to look for a weights file whose name ends in \"best\".**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bdaa0e0-3004-4eaa-9877-bbca287eccd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nick Marino\\Documents\\SentenceAx\n"
     ]
    }
   ],
   "source": [
    "# this makes sure it starts looking for things from the SentenceAx folder down.\n",
    "import os\n",
    "import sys\n",
    "os.chdir('../')\n",
    "sys.path.insert(0,os.getcwd())\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1faf75af-7251-4011-9c49-de1049ee9471",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(os.environ[\"TOKENIZERS_PARALLELISM\"])\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "print(os.environ[\"CUDA_LAUNCH_BLOCKING\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf61af3b-4c82-4860-9641-e631e5107e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Params import *\n",
    "from ActionConductor import *\n",
    "\n",
    "\n",
    "def main(pid):\n",
    "    params = Params(pid)\n",
    "    params.d[\"refresh_cache\"] = True\n",
    "    params.d[\"gpus\"] = 1\n",
    "    params.describe_self()\n",
    "    conductor = ActionConductor(params)\n",
    "    conductor.delete_all_checkpoints()\n",
    "    print(\"checkpoints:\", conductor.get_all_checkpoint_fp())\n",
    "    conductor.run()\n",
    "    print(\"checkpoints:\", conductor.get_all_checkpoint_fp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a2a9f60-9297-4129-8dd0-edc71196421d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************** new params\n",
      "new params: pid=1, task='ex', action='train_test'\n",
      "params=\n",
      "{'accumulate_grad_batches': 1,\n",
      " 'action': 'train_test',\n",
      " 'batch_size': 24,\n",
      " 'con_weight_str': '1',\n",
      " 'dropout_fun': 0.0,\n",
      " 'gpus': 1,\n",
      " 'gradient_clip_val': 5,\n",
      " 'lr': 2e-05,\n",
      " 'model_str': 'bert-base-cased',\n",
      " 'num_epochs': 30,\n",
      " 'num_iterative_layers': 2,\n",
      " 'num_steps_per_epoch': None,\n",
      " 'optimizer': 'adamW',\n",
      " 'refresh_cache': True,\n",
      " 'save_k': 1,\n",
      " 'small_train': False,\n",
      " 'task': 'ex',\n",
      " 'val_check_interval': 1.0,\n",
      " 'verbose': False,\n",
      " 'weights_dir': 'weights',\n",
      " 'wreg': 0}\n",
      "lightning version is 2.2.0 so it is >= 2.0.1 as required.\n",
      "SEED= 777\n",
      "\n",
      "MInput started reading 'input_data/openie-data/openie4_labels'\n",
      "...\n",
      "1. Line 1910 has > 100 words. length=105. first 60 words:\n",
      "Mr. Burke 's Enemies often endeavoured to convince the World\n",
      "2. Line 2105 has > 100 words. length=136. first 60 words:\n",
      "In that very short space of time they had completely pulled \n",
      "3. Line 2169 has > 100 words. length=120. first 60 words:\n",
      "Burke said , no , Sir , not more than usual -- You have and \n",
      "4. Line 7150 has > 100 words. length=106. first 60 words:\n",
      "The government led by Prime Minister Benjamin Disraeli , con\n",
      "5. Line 7567 has > 100 words. length=110. first 60 words:\n",
      "Abbot 's publications , though always of the most thorough a\n",
      "6. Line 7872 has > 100 words. length=111. first 60 words:\n",
      "Elizabeth I of England lords , the law of nature moves Eliza\n",
      "7. Line 8431 has > 100 words. length=128. first 60 words:\n",
      "Expert system was the first tool showing the AI defined by E\n",
      "8. Line 11019 has > 100 words. length=108. first 60 words:\n",
      "On the other hand , when Donald Mains , a New York City poli\n",
      "9. Line 12993 has > 100 words. length=124. first 60 words:\n",
      "John Beaufort and John Beaufort, 1st Earl of Somerset wife M\n",
      "10. Line 13916 has > 100 words. length=108. first 60 words:\n",
      "A cardinal 's secretary wrote : `` In this painting there ar\n",
      "11. Line 15602 has > 100 words. length=102. first 60 words:\n",
      "If the British seemed inclined to recognize the Confederacy \n",
      "12. Line 16325 has > 100 words. length=127. first 60 words:\n",
      "g protein = 0.39 g fat = 0.13 g carbs = 12.2 g fiber = 4.6 g\n",
      "13. Line 17240 has > 100 words. length=382. first 60 words:\n",
      "Eugene has fielded a team in all but five of the NWL 's seas\n",
      "14. Line 22209 has > 100 words. length=104. first 60 words:\n",
      "For instance , in the tritone B -- F , B would be `` mi '' ,\n",
      "15. Line 23726 has > 100 words. length=127. first 60 words:\n",
      "Five examples of this are Manchester ( where the traditional\n",
      "16. Line 25182 has > 100 words. length=107. first 60 words:\n",
      "( 3 ) ( a ) That the de jure Government has recognized the i\n",
      "17. Line 27255 has > 100 words. length=154. first 60 words:\n",
      "Although artists begin the creative process by separating fr\n",
      "18. Line 27284 has > 100 words. length=106. first 60 words:\n",
      "This is the paradox : Otto Rank is out of nature and hopeles\n",
      "19. Line 27298 has > 100 words. length=127. first 60 words:\n",
      "Sheets-Johnstone compares Rank 's thought to that of three m\n",
      "20. Line 30306 has > 100 words. length=117. first 60 words:\n",
      "Appendicitis incorporates the presence of four variables mad\n",
      "21. Line 30597 has > 100 words. length=142. first 60 words:\n",
      "Some key achievements made since the plan 's initial passing\n",
      "22. Line 30859 has > 100 words. length=103. first 60 words:\n",
      "The molar volume of an ideal gas at 100 kPa ( 1 bar ) is 22.\n",
      "23. Line 31697 has > 100 words. length=118. first 60 words:\n",
      "In August 1994 , an official Argentine Defence Ministry repo\n",
      "24. Line 35722 has > 100 words. length=102. first 60 words:\n",
      "Recurring characters on SNL played by Guest include Frankie \n",
      "25. Line 37476 has > 100 words. length=118. first 60 words:\n",
      "They include a Native American in profile and a ribbon readi\n",
      "26. Line 38036 has > 100 words. length=102. first 60 words:\n",
      "On 9 June 2007 , in a failed assault on an IDF position at t\n",
      "27. Line 41132 has > 100 words. length=103. first 60 words:\n",
      "Other movies influenced by or making use of Uncle Tom 's Cab\n",
      "28. Line 42902 has > 100 words. length=122. first 60 words:\n",
      "When the three travellers finally reach the beach - after br\n",
      "29. Line 43210 has > 100 words. length=111. first 60 words:\n",
      "However , local Indians had evidently looted the hiding plac\n",
      "30. Line 43233 has > 100 words. length=116. first 60 words:\n",
      "There is also a record of an Elizabeth Aguirre of Petersfiel\n",
      "31. Line 46052 has > 100 words. length=111. first 60 words:\n",
      "The computer also had a serial bus ( a serial version of the\n",
      "32. Line 46228 has > 100 words. length=111. first 60 words:\n",
      "In 1968 , Paul Ehrlich noted in The Population Bomb that , `\n",
      "33. Line 55166 has > 100 words. length=249. first 60 words:\n",
      "This number grew to 21 in 1900 , 32 in 1950 , and 49 in 2001\n",
      "34. Line 57621 has > 100 words. length=108. first 60 words:\n",
      "Citizen Kane , Some Like The Deer Hunter Hot , , The Godfath\n",
      "35. Line 58485 has > 100 words. length=101. first 60 words:\n",
      "On April 1 , 2009 , Senator Jay Rockefeller ( D-WV ) introdu\n",
      "36. Line 58900 has > 100 words. length=113. first 60 words:\n",
      "Nikephoros was the author of extant treatises on military ta\n",
      "37. Line 59660 has > 100 words. length=103. first 60 words:\n",
      "The author mainly expands upon details in Barrie 's original\n",
      "38. Line 69292 has > 100 words. length=107. first 60 words:\n",
      "But the Prince , subtle and adroit as William the Silent was\n",
      "39. Line 69993 has > 100 words. length=115. first 60 words:\n",
      "The account goes as follows : `` The cardinals dallied with \n",
      "40. Line 79755 has > 100 words. length=106. first 60 words:\n",
      "The principal rivers are the Sakarya which traverses the pro\n",
      "41. Line 85968 has > 100 words. length=366. first 60 words:\n",
      "; Tuan Jim ( Lord Jim , 1900 ) , having inadvertently precip\n",
      "42. Line 86028 has > 100 words. length=120. first 60 words:\n",
      "This may account for his describing the admirable crew of th\n",
      "43. Line 86090 has > 100 words. length=108. first 60 words:\n",
      "Under the circumstances , English could not but become `` th\n",
      "44. Line 89226 has > 100 words. length=101. first 60 words:\n",
      "It was visible in the small things , the almost absurd degre\n",
      "45. Line 89536 has > 100 words. length=109. first 60 words:\n",
      "Tolkien considered languages inseparable from the mythology \n",
      "46. Line 96531 has > 100 words. length=101. first 60 words:\n",
      "The species name troglodytes , Greek for `` cave-dweller '' \n",
      "47. Line 100720 has > 100 words. length=131. first 60 words:\n",
      "At an economic crisis conference in Canberra in 1931 , Jack \n",
      "48. Line 100723 has > 100 words. length=122. first 60 words:\n",
      "We have nine of them , you know , and they are going to live\n",
      "49. Line 100741 has > 100 words. length=102. first 60 words:\n",
      "Key points of the Lang Plan included the reduction of intere\n",
      "50. Line 110357 has > 100 words. length=103. first 60 words:\n",
      "The team made an aggregate net loss in the following seasons\n",
      "51. Line 119633 has > 100 words. length=135. first 60 words:\n",
      "English longbow is the difficulty in using the longbow which\n",
      "52. Line 121658 has > 100 words. length=114. first 60 words:\n",
      "Historical factors and socio-political conditions , however \n",
      "53. Line 124040 has > 100 words. length=113. first 60 words:\n",
      "Places such as Cancun , Galapagos Islands , Machu Picchu , C\n",
      "54. Line 124225 has > 100 words. length=107. first 60 words:\n",
      "of '' lexikos '' ( lexikos ) , `` of or for words '' , from \n",
      "55. Line 124941 has > 100 words. length=101. first 60 words:\n",
      "The conception that in religious matters anyone , however ig\n",
      "56. Line 128771 has > 100 words. length=112. first 60 words:\n",
      "Lex 's attires primary consists of dark colors and is an inq\n",
      "57. Line 129978 has > 100 words. length=109. first 60 words:\n",
      "The unilateral or one-sided Z-transform is simply the Laplac\n",
      "58. Line 130280 has > 100 words. length=115. first 60 words:\n",
      "According to several linguists , neurocognitive research has\n",
      "59. Line 149694 has > 100 words. length=116. first 60 words:\n",
      "Orans concludes that Freeman 's basic criticisms , that Mead\n",
      "60. Line 158274 has > 100 words. length=102. first 60 words:\n",
      "Two examples of which , are the 1993 World Trade Center bomb\n",
      "61. Line 158526 has > 100 words. length=111. first 60 words:\n",
      "When , in 1887 , the French and Italian Governments agreed u\n",
      "62. Line 163756 has > 100 words. length=105. first 60 words:\n",
      "Like other Church Fathers such as Athenagoras , St. Augustin\n",
      "63. Line 169890 has > 100 words. length=118. first 60 words:\n",
      "In 1835 , the English poet William Wordsworth described the \n",
      "64. Line 169994 has > 100 words. length=192. first 60 words:\n",
      "Albania , Andorra , Armenia , Austria , Azerbaijan , Belarus\n",
      "65. Line 172474 has > 100 words. length=104. first 60 words:\n",
      "George Gruen attributes the increased animosity towards Jews\n",
      "66. Line 172840 has > 100 words. length=144. first 60 words:\n",
      "Davidson 1997 p = 30 -- 1 These included Georg Froschmann , \n",
      "67. Line 172969 has > 100 words. length=106. first 60 words:\n",
      "This was addressed in the judgment relating to war crimes an\n",
      "68. Line 173983 has > 100 words. length=126. first 60 words:\n",
      "In Montagu 's list of `` neotenous structural traits in whic\n",
      "69. Line 177351 has > 100 words. length=118. first 60 words:\n",
      "Behavioural prerequisite Navigation competence Local navigat\n",
      "70. Line 180919 has > 100 words. length=114. first 60 words:\n",
      "For example in Genealogical Reflections Ogden Nash writes : \n",
      "71. Line 181935 has > 100 words. length=103. first 60 words:\n",
      "On the signing , Governor Henry said `` Although the events \n",
      "72. Line 188041 has > 100 words. length=128. first 60 words:\n",
      "The 1937 British Methodist Conference located the `` true co\n",
      "73. Line 196690 has > 100 words. length=102. first 60 words:\n",
      "Ships by type : barge carrier 2 , bulk carrier 325 , cargo s\n",
      "74. Line 211951 has > 100 words. length=109. first 60 words:\n",
      "Fresh material having come to light , a new edition of the p\n",
      "75. Line 216399 has > 100 words. length=104. first 60 words:\n",
      "Between summer of 1967 and the end of 1968 , Glass composed \n",
      "76. Line 216730 has > 100 words. length=134. first 60 words:\n",
      "2n CO2 + 2n DH2 + photons - 2 ( CH2O ) n + 2n DO Carbon diox\n",
      "77. Line 217752 has > 100 words. length=118. first 60 words:\n",
      "H , with the cross-stroke high , P , M , with the middle str\n",
      "78. Line 219596 has > 100 words. length=109. first 60 words:\n",
      "These included : Rheinterrasse , Lowenbrau ( Bavarian beer r\n",
      "79. Line 221735 has > 100 words. length=120. first 60 words:\n",
      "Modern contemporary architectural projects by Persians inclu\n",
      "80. Line 237355 has > 100 words. length=110. first 60 words:\n",
      "Long term political and government appointments , such as th\n",
      "81. Line 237861 has > 100 words. length=114. first 60 words:\n",
      "Foreign relations of Saudi Arabia is member of the ABEDA , A\n",
      "82. Line 238414 has > 100 words. length=132. first 60 words:\n",
      "Senegal is member of ACCT , ACP , AfDB , ECA , ECOWAS , FAO \n",
      "83. Line 238945 has > 100 words. length=211. first 60 words:\n",
      "Seychelles is divided in 25 administrative districts ; Anse \n",
      "84. Line 239901 has > 100 words. length=115. first 60 words:\n",
      "The Protectorate Ordinances ( passed in the Colony in 1896 a\n",
      "85. Line 240892 has > 100 words. length=120. first 60 words:\n",
      "In 26 January 2013 , Ms Lee Li Lian became the second woman \n",
      "86. Line 241703 has > 100 words. length=149. first 60 words:\n",
      "Slovakia is member of ACCT ( observer ) , Australia Group , \n",
      "87. Line 242051 has > 100 words. length=131. first 60 words:\n",
      "In Steven Soderbergh review of Full Frontal film critic Roge\n",
      "88. Line 242537 has > 100 words. length=194. first 60 words:\n",
      "Other popular bands , most largely unknown outside Slovenia \n",
      "89. Line 242975 has > 100 words. length=115. first 60 words:\n",
      "Slovenia is member of BIS , CCC , CE , CEI , EAPC , EBRD , E\n",
      "90. Line 250077 has > 100 words. length=110. first 60 words:\n",
      "The versatility of structuralism is such that a literary cri\n",
      "MInput finished reading 'input_data/openie-data/openie4_labels'\n",
      "number of lines= 271794\n",
      "number of used samples=  91187\n",
      "number of omitted samples=  90\n",
      "\n",
      "\n",
      "MInput started reading 'input_data/carb-data/dev.txt'\n",
      "...\n",
      "MInput finished reading 'input_data/carb-data/dev.txt'\n",
      "number of lines= 1283\n",
      "number of used samples=  641\n",
      "number of omitted samples=  0\n",
      "\n",
      "\n",
      "MInput started reading 'input_data/carb-data/test.txt'\n",
      "...\n",
      "MInput finished reading 'input_data/carb-data/test.txt'\n",
      "number of lines= 1283\n",
      "number of used samples=  641\n",
      "number of omitted samples=  0\n",
      "\n",
      "PaddedMInput omitting these extractions: sample= 95, depths=[5, 6, 7, 8, 9]\n",
      "PaddedMInput omitting these extractions: sample= 134, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 232, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 364, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 386, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 409, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 462, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 526, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 589, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 637, depths=[5, 6, 7, 8, 9, 10, 11]\n",
      "PaddedMInput omitting these extractions: sample= 708, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 716, depths=[5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "PaddedMInput omitting these extractions: sample= 729, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 734, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 743, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 810, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 1093, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 1119, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 1136, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 1143, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 1287, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 1288, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 1641, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 1663, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 1713, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 1716, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 1775, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 1792, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 1900, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 1975, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 2086, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 2270, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 2321, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 2373, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 2389, depths=[5, 6, 7, 8, 9]\n",
      "PaddedMInput omitting these extractions: sample= 2481, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 2489, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 2528, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 2622, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 2646, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 2816, depths=[5, 6, 7, 8, 9, 10, 11]\n",
      "PaddedMInput omitting these extractions: sample= 2883, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 2889, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 2899, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 2947, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 3046, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 3104, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 3111, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 3210, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 3240, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 3433, depths=[5, 6, 7, 8, 9]\n",
      "PaddedMInput omitting these extractions: sample= 3612, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 3630, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 3686, depths=[5, 6, 7, 8, 9, 10, 11]\n",
      "PaddedMInput omitting these extractions: sample= 3740, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 3796, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 3855, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 3878, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 3900, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 3961, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 4082, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 4151, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 4260, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 4262, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 4291, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 4330, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 4376, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 4436, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 4470, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 4534, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 4538, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 4612, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 4618, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 4629, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 4640, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 4690, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 4691, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 4925, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 5205, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 5488, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 5489, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 5491, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 5607, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 5766, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 5943, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 6217, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 6323, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 6442, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 6615, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 6619, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 6669, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 6724, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 6778, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 6810, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 7240, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 7401, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 7466, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 7549, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 7615, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 7660, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 7700, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 7850, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 7939, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 7969, depths=[5, 6, 7, 8, 9]\n",
      "PaddedMInput omitting these extractions: sample= 8038, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 8048, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 8103, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 8172, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 8458, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 8545, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 8568, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 8584, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 8817, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 8860, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 9005, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 9115, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 9136, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 9142, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 9148, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 9154, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 9156, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 9264, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 9265, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 9483, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 9900, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 10009, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 10270, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 10304, depths=[5, 6, 7, 8, 9]\n",
      "PaddedMInput omitting these extractions: sample= 10394, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 10508, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 10643, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 10696, depths=[5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "PaddedMInput omitting these extractions: sample= 10702, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 10787, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 10856, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 11215, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 11380, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 11713, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 11780, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 12150, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 12313, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 12333, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 12361, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 12367, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 12512, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 12700, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 12708, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 12740, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 12763, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 12767, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 12793, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 12950, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 13008, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 13074, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 13275, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 13583, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 13612, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 13615, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 13734, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 13794, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 13909, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 13934, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 14006, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 14092, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 14099, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 14155, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 14664, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 14743, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 14745, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 14780, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 14803, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 14937, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 14944, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 14951, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 15072, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 15152, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 15162, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 15220, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 15223, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 15323, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 15421, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 15533, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 15536, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 15560, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 15631, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 15687, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 15706, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 15711, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 15741, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 15777, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 16141, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 16146, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 16211, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 16252, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 16293, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 16715, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 16830, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 16831, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 16855, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 16902, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 17269, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 17305, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 17610, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 17653, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 17848, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 17852, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 17854, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 17876, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 17886, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 17901, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 17916, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 17921, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 17930, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 17972, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 18116, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 18206, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 18436, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 18491, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 18496, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 18507, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 18551, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 18600, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 18602, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 18668, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 18732, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 18827, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 18829, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 18839, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 18856, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 18913, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 18919, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 18922, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 18925, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 19039, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 19047, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 19048, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 19054, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 19074, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 19080, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 19128, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 19167, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 19175, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 19216, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 19265, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 19316, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 19373, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 19378, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 19422, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 19504, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 19507, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 19531, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 19609, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 19673, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 19693, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 19719, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 19807, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 19830, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 19948, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 19998, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 20036, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 20041, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 20058, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 20194, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 20199, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 20203, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 20224, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 20235, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 20298, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 20391, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 20415, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 20440, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 20466, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 20608, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 20676, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 20677, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 20951, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 20956, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 21180, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 21403, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 21454, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 21488, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 21650, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 21688, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 21711, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 21963, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 22183, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 22229, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 22253, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 22262, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 22273, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 22632, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 22876, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 22921, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 22972, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 23186, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 23189, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 23194, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 23416, depths=[5, 6, 7, 8, 9]\n",
      "PaddedMInput omitting these extractions: sample= 23584, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 23674, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 23679, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 23793, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 23861, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 23862, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 23873, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 24252, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 24254, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 24332, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 24475, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 24481, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 24602, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 24693, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 24729, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 24781, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 24961, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 24968, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 25029, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 25039, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 25049, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 25055, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 25077, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 25087, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 25268, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 25334, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 25721, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 25741, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 26094, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 26103, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 26324, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 26360, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 26532, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 26571, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 26572, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 26574, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 26585, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 26661, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 26668, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 26671, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 26676, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 26882, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 26903, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 26909, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 26980, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 27054, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 27081, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 27133, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 27154, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 27196, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 27206, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 27637, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 27652, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 27677, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 27975, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 28000, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 28068, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 28178, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 28266, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 28280, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 28328, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 28468, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 28488, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 28493, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 28575, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 28667, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 28674, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 28729, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 28740, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 28844, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 28946, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 28947, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 28959, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 28960, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 28972, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 29017, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 29110, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 29260, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 29270, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 29273, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 29307, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 29316, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 29546, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 29653, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 29688, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 29737, depths=[5, 6, 7, 8, 9]\n",
      "PaddedMInput omitting these extractions: sample= 29777, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 29782, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 29822, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 29913, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 29980, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 30002, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 30015, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 30030, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 30048, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 30062, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 30068, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 30085, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 30113, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 30243, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 30380, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 30463, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 30498, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 30582, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 30606, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 30758, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 30858, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 30923, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 31010, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 31127, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 31332, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 31368, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 31440, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 31540, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 31629, depths=[5, 6, 7, 8, 9]\n",
      "PaddedMInput omitting these extractions: sample= 31667, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 31683, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 31702, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 31776, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 31822, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 31886, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 31893, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 31970, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 32057, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 32134, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 32337, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 32458, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 32535, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 32937, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 32948, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 32974, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 32982, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 33061, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 33260, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 33296, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 33386, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 33392, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 33393, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 33430, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 33431, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 33631, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 33640, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 33737, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 33749, depths=[5, 6, 7, 8, 9]\n",
      "PaddedMInput omitting these extractions: sample= 33752, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 33797, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 33798, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 33814, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 33853, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 33856, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 33891, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 33899, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 33931, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 33964, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 33971, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 34035, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 34046, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 34078, depths=[5, 6, 7, 8, 9, 10]\n",
      "PaddedMInput omitting these extractions: sample= 34086, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 34282, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 34301, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 34398, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 34797, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 34799, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 34861, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 34875, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 34964, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 34994, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 35026, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 35028, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 35031, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 35038, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 35042, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 35183, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 35223, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 35226, depths=[5, 6, 7, 8, 9, 10]\n",
      "PaddedMInput omitting these extractions: sample= 35276, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 35374, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 35432, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 35479, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 35500, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 35623, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 35626, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 35634, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 35635, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 35724, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 35729, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 35756, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 35780, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 35850, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 36089, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 36146, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 36195, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 36307, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 36333, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 36384, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 36394, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 36406, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 36507, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 36591, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 36601, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 36604, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 36648, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 36657, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 36701, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 36731, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 36858, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 37013, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 37124, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 37208, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 37229, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 37248, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 37274, depths=[5, 6, 7, 8, 9]\n",
      "PaddedMInput omitting these extractions: sample= 37613, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 37633, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 37717, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 37786, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 37789, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 37983, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 38017, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 38144, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 38203, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 38212, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 38314, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 38317, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 38341, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 38384, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 38545, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 38546, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 38580, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 38613, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 38620, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 38624, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 38808, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 38980, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 38993, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 39002, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 39173, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 39331, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 39363, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 39373, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 39419, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 39425, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 39428, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 39479, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 39505, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 39533, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 39548, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 39557, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 39573, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 39674, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 39711, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 39865, depths=[5, 6, 7, 8, 9]\n",
      "PaddedMInput omitting these extractions: sample= 39930, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 39952, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 39963, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 40113, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 40199, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 40250, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 40266, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 40297, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 40299, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 40452, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 40509, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 40552, depths=[5, 6, 7, 8, 9, 10, 11]\n",
      "PaddedMInput omitting these extractions: sample= 40619, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 40718, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 40721, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 40953, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 40980, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 41157, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 41245, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 41282, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 41630, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 41674, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 41793, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 41914, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 42045, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 42104, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 42126, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 42150, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 42151, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 42209, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 42246, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 42253, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 42308, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 42327, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 42370, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 42398, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 42400, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 42408, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 42455, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 42459, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 42463, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 42730, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 42770, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 42779, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 42784, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 42802, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 42803, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 42804, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 42821, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 42833, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 42836, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 42873, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 42893, depths=[5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "PaddedMInput omitting these extractions: sample= 42903, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 43212, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 43221, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 43316, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 43355, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 43374, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 43384, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 43409, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 43415, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 43603, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 43731, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 44188, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 44205, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 44227, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 44503, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 44952, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 45077, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 45265, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 45577, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 45591, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 45677, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 45794, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 45805, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 46269, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 46726, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 46982, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 47061, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 47266, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 47272, depths=[5, 6, 7, 8, 9]\n",
      "PaddedMInput omitting these extractions: sample= 47290, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 47307, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 47436, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 47879, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 47881, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 47931, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 47942, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 47964, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 48218, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 48219, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 48279, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 48387, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 48882, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 48889, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 48915, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 49016, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 49123, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 49136, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 49296, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 49587, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 49612, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 49622, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 49699, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 49739, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 49743, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 49767, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 49795, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 50025, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 50073, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 50161, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 50179, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 50281, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 50408, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 50547, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 50658, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 50659, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 50688, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 50692, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 50695, depths=[5, 6, 7, 8, 9]\n",
      "PaddedMInput omitting these extractions: sample= 50748, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 50779, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 50793, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 50817, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 50902, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 50904, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 50910, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 50998, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 51048, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 51090, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 51115, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 51125, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 51218, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 51226, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 51229, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 51231, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 51258, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 51284, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 51286, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 51289, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 51362, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 51431, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 51501, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 51548, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 51568, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 51638, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 51767, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 51772, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 51774, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 52125, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 52317, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 52713, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 52750, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 52755, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 52979, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 53015, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 53016, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 53017, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 53048, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 53051, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 53327, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 53350, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 53460, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 53468, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 53495, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 53516, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 53574, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 53588, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 53838, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 53851, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 53862, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 54227, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 54252, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 54552, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 54561, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 54659, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 54698, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 54715, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 54789, depths=[5, 6, 7, 8, 9]\n",
      "PaddedMInput omitting these extractions: sample= 54868, depths=[5, 6, 7, 8, 9, 10]\n",
      "PaddedMInput omitting these extractions: sample= 54884, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 54896, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 54968, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 55146, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 55211, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 55248, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 55422, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 55448, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 55861, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 55881, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 55892, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 55915, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 56021, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 56053, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 56057, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 56112, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 56180, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 56417, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 56448, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 56597, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 56622, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 56742, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 56789, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 56889, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 56936, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 57013, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 57075, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 57163, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 57449, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 57626, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 57816, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 57845, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 57914, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 57979, depths=[5, 6, 7, 8, 9, 10, 11]\n",
      "PaddedMInput omitting these extractions: sample= 58008, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 58029, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 58043, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 58110, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 58117, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 58258, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 58284, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 58673, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 58697, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 58705, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 58891, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 58899, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 59308, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 59464, depths=[5, 6, 7, 8, 9]\n",
      "PaddedMInput omitting these extractions: sample= 59698, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 59940, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 60023, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 60043, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 60164, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 60170, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 60261, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 60467, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 60571, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 60784, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 61001, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 61092, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 61112, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 61319, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 61404, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 61408, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 61598, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 61602, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 61654, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 61666, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 62073, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 62343, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 62690, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 62842, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 62850, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 62852, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 62855, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 63047, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 63085, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 63096, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 63245, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 63252, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 63631, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 63681, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 63686, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 63695, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 64067, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 64171, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 64260, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 64321, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 64383, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 64467, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 64507, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 64515, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 64531, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 64543, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 64591, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 64661, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 64760, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 64847, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 64860, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 65274, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 65284, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 65812, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 65881, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 66118, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 66168, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 66214, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 66303, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 66405, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 66435, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 66437, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 66463, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 66596, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 66637, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 66720, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 66770, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 66800, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 66894, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 66895, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 66903, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 66909, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 66921, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 66959, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 66980, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 67006, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 67033, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 67067, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 67180, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 67192, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 67474, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 67620, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 67721, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 67756, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 67758, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 67767, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 67883, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 67887, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 67944, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 67991, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 68038, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 68150, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 68307, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 68561, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 68628, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 68673, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 68789, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 68803, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 68826, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 69197, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 69357, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 69385, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 69406, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 69433, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 69442, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 69501, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 69533, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 69538, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 69539, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 69542, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 69550, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 69562, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 69605, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 69608, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 69609, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 69719, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 69830, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 69838, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 69881, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 69971, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 70025, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 70082, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 70207, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 70301, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 70356, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 70366, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 70372, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 70384, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 70616, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 70723, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 70843, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 70845, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 70851, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 70921, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 70938, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 70944, depths=[5, 6, 7, 8, 9]\n",
      "PaddedMInput omitting these extractions: sample= 71042, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 71069, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 71070, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 71093, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 71115, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 71187, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 71211, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 71305, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 71373, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 71405, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 71466, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 71486, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 71502, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 71649, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 71862, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 71872, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 72011, depths=[5, 6, 7, 8, 9]\n",
      "PaddedMInput omitting these extractions: sample= 72119, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 72143, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 72144, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 72145, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 72170, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 72181, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 72186, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 72189, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 72248, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 72379, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 72385, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 72402, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 72411, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 72415, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 72506, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 72582, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 72715, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 72746, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 72805, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 72825, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 73019, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 73247, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 73262, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 73287, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 73289, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 73293, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 73296, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 73299, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 73397, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 73424, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 73430, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 73467, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 73603, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 73679, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 73782, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 73790, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 73837, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 73838, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 74064, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 74101, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 74157, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 74159, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 74476, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 74559, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 74736, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 74759, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 74786, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 74838, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 74916, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 74930, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 75012, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 75165, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 75530, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 75661, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 75668, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 75771, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 75808, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 75818, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 75848, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 76274, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 76307, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 76616, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 76678, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 76711, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 76805, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 76830, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 77291, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 77315, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 77325, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 77574, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 77673, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 77785, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 77925, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 78028, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 78051, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 78061, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 78083, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 78334, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 78438, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 78454, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 78522, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 78568, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 78694, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 78746, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 78797, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 78889, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 79085, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 79352, depths=[5, 6, 7, 8, 9, 10, 11, 12]\n",
      "PaddedMInput omitting these extractions: sample= 79879, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 80253, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 80266, depths=[5, 6, 7, 8, 9]\n",
      "PaddedMInput omitting these extractions: sample= 80565, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 80675, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 81040, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 81057, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 81403, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 81592, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 81602, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 81675, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 81797, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 81824, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 81868, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 82423, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 82522, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 82567, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 82674, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 82692, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 82885, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 82916, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 82971, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 83249, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 83296, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 83324, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 83434, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 83723, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 83782, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 83801, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 83828, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 83858, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 83862, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 83934, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 83975, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 84060, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 84245, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 84308, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 84452, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 84721, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 84722, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 84774, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 84872, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 85855, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 85994, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 86074, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 86089, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 86094, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 86100, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 86208, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 86230, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 86496, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 86499, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 86526, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 86616, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 86630, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 86817, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 87026, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 87146, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 87245, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 87322, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 87326, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 87373, depths=[5, 6, 7, 8, 9, 10, 11]\n",
      "PaddedMInput omitting these extractions: sample= 87450, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 87500, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 87511, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 87531, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 87593, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 87892, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 88203, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 88273, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 88293, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 88642, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 88653, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 88883, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 88905, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 88919, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 88956, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 89087, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 89126, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 89156, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 89266, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 89277, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 89342, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 89386, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 89435, depths=[5, 6, 7, 8]\n",
      "PaddedMInput omitting these extractions: sample= 89454, depths=[5, 6, 7]\n",
      "PaddedMInput omitting these extractions: sample= 89590, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 89658, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 89668, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 89701, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 90548, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 90568, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 90577, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 90581, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 90723, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 90731, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 90924, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 90969, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 91079, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 91112, depths=[5]\n",
      "PaddedMInput omitting these extractions: sample= 91118, depths=[5, 6, 7, 8, 9]\n",
      "PaddedMInput omitting these extractions: sample= 91119, depths=[5, 6]\n",
      "PaddedMInput omitting these extractions: sample= 91177, depths=[5]\n",
      "checkpoints: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                  | Type             | Params\n",
      "-----------------------------------------------------------\n",
      "0 | base_model            | BertModel        | 94.1 M\n",
      "1 | iterative_transformer | ModuleList       | 14.2 M\n",
      "2 | dropout_fun           | Dropout          | 0     \n",
      "3 | embedding             | Embedding        | 76.8 K\n",
      "4 | merge_layer           | Linear           | 230 K \n",
      "5 | ilabelling_layer      | Linear           | 1.8 K \n",
      "6 | loss_fun              | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------------------\n",
      "108 M     Trainable params\n",
      "0         Non-trainable params\n",
      "108 M     Total params\n",
      "434.478   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fcf83f3576c4de6be2264014df89333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Model.training_step method, batch_idx=0 {'train_loss': 11.5476, 'loss': 11.5476}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Model.validation_step method, batch_idx=0 {'tune_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 3800: 'tune_epoch_acc' reached 0.48230 (best 0.48230), saving model to 'C:\\\\Users\\\\Nick Marino\\\\Documents\\\\SentenceAx\\\\weights\\\\ex_model\\\\epoch=00_tune_epoch_acc=0.4823.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores at end of epoch 0:\n",
      "{'AUC': 0.2708, 'F1': 0.4823, 'epoch_acc': 0.4823, 'last_F1': 0.4823}\n",
      "Inside Model.training_step method, batch_idx=0 {'train_loss': 1.3046, 'loss': 1.3046}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Model.validation_step method, batch_idx=0 {'tune_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 7600: 'tune_epoch_acc' reached 0.49290 (best 0.49290), saving model to 'C:\\\\Users\\\\Nick Marino\\\\Documents\\\\SentenceAx\\\\weights\\\\ex_model\\\\epoch=01_tune_epoch_acc=0.4929.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores at end of epoch 1:\n",
      "{'AUC': 0.294, 'F1': 0.4929, 'epoch_acc': 0.4929, 'last_F1': 0.4928}\n",
      "Inside Model.training_step method, batch_idx=0 {'train_loss': 0.8404, 'loss': 0.8404}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Model.validation_step method, batch_idx=0 {'tune_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 11400: 'tune_epoch_acc' reached 0.50660 (best 0.50660), saving model to 'C:\\\\Users\\\\Nick Marino\\\\Documents\\\\SentenceAx\\\\weights\\\\ex_model\\\\epoch=02_tune_epoch_acc=0.5066.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores at end of epoch 2:\n",
      "{'AUC': 0.3108, 'F1': 0.5066, 'epoch_acc': 0.5066, 'last_F1': 0.5066}\n",
      "Inside Model.training_step method, batch_idx=0 {'train_loss': 0.5414, 'loss': 0.5414}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Model.validation_step method, batch_idx=0 {'tune_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 15200: 'tune_epoch_acc' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores at end of epoch 3:\n",
      "{'AUC': 0.3061, 'F1': 0.504, 'epoch_acc': 0.504, 'last_F1': 0.5039}\n",
      "Inside Model.training_step method, batch_idx=0 {'train_loss': 0.4217, 'loss': 0.4217}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Model.validation_step method, batch_idx=0 {'tune_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 19000: 'tune_epoch_acc' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores at end of epoch 4:\n",
      "{'AUC': 0.3027, 'F1': 0.5045, 'epoch_acc': 0.5045, 'last_F1': 0.5045}\n",
      "Inside Model.training_step method, batch_idx=0 {'train_loss': 0.1545, 'loss': 0.1545}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Model.validation_step method, batch_idx=0 {'tune_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 22800: 'tune_epoch_acc' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores at end of epoch 5:\n",
      "{'AUC': 0.299, 'F1': 0.5027, 'epoch_acc': 0.5027, 'last_F1': 0.5024}\n",
      "Inside Model.training_step method, batch_idx=0 {'train_loss': 0.2182, 'loss': 0.2182}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Model.validation_step method, batch_idx=0 {'tune_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 26600: 'tune_epoch_acc' reached 0.50770 (best 0.50770), saving model to 'C:\\\\Users\\\\Nick Marino\\\\Documents\\\\SentenceAx\\\\weights\\\\ex_model\\\\epoch=06_tune_epoch_acc=0.5077.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores at end of epoch 6:\n",
      "{'AUC': 0.3067, 'F1': 0.5077, 'epoch_acc': 0.5077, 'last_F1': 0.5073}\n",
      "Inside Model.training_step method, batch_idx=0 {'train_loss': 0.0854, 'loss': 0.0854}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Model.validation_step method, batch_idx=0 {'tune_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 30400: 'tune_epoch_acc' reached 0.51480 (best 0.51480), saving model to 'C:\\\\Users\\\\Nick Marino\\\\Documents\\\\SentenceAx\\\\weights\\\\ex_model\\\\epoch=07_tune_epoch_acc=0.5148.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores at end of epoch 7:\n",
      "{'AUC': 0.306, 'F1': 0.5148, 'epoch_acc': 0.5148, 'last_F1': 0.5148}\n",
      "Inside Model.training_step method, batch_idx=0 {'train_loss': 0.1307, 'loss': 0.1307}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Model.validation_step method, batch_idx=0 {'tune_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 34200: 'tune_epoch_acc' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores at end of epoch 8:\n",
      "{'AUC': 0.2986, 'F1': 0.5087, 'epoch_acc': 0.5087, 'last_F1': 0.5087}\n",
      "Inside Model.training_step method, batch_idx=0 {'train_loss': 0.2062, 'loss': 0.2062}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Model.validation_step method, batch_idx=0 {'tune_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 38000: 'tune_epoch_acc' reached 0.51610 (best 0.51610), saving model to 'C:\\\\Users\\\\Nick Marino\\\\Documents\\\\SentenceAx\\\\weights\\\\ex_model\\\\epoch=09_tune_epoch_acc=0.5161.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores at end of epoch 9:\n",
      "{'AUC': 0.3132, 'F1': 0.5161, 'epoch_acc': 0.5161, 'last_F1': 0.5161}\n",
      "Inside Model.training_step method, batch_idx=0 {'train_loss': 0.1528, 'loss': 0.1528}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Model.validation_step method, batch_idx=0 {'tune_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 41800: 'tune_epoch_acc' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores at end of epoch 10:\n",
      "{'AUC': 0.3033, 'F1': 0.5047, 'epoch_acc': 0.5047, 'last_F1': 0.5047}\n",
      "Inside Model.training_step method, batch_idx=0 {'train_loss': 0.1888, 'loss': 0.1888}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Model.validation_step method, batch_idx=0 {'tune_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 45600: 'tune_epoch_acc' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores at end of epoch 11:\n",
      "{'AUC': 0.3072, 'F1': 0.5151, 'epoch_acc': 0.5151, 'last_F1': 0.5151}\n",
      "Inside Model.training_step method, batch_idx=0 {'train_loss': 0.0657, 'loss': 0.0657}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "578ead4c955e49988db0dece80b3e89f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Model.validation_step method, batch_idx=0 {'tune_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 49400: 'tune_epoch_acc' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores at end of epoch 12:\n",
      "{'AUC': 0.3114, 'F1': 0.5121, 'epoch_acc': 0.5121, 'last_F1': 0.5121}\n",
      "Inside Model.training_step method, batch_idx=0 {'train_loss': 0.097, 'loss': 0.097}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c9848d11ba24101a4e57aab45979b57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Model.validation_step method, batch_idx=0 {'tune_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 53200: 'tune_epoch_acc' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores at end of epoch 13:\n",
      "{'AUC': 0.3111, 'F1': 0.5102, 'epoch_acc': 0.5102, 'last_F1': 0.5097}\n",
      "Inside Model.training_step method, batch_idx=0 {'train_loss': 0.1174, 'loss': 0.1174}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "858e431ee178475c8db0e285fb550410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Model.validation_step method, batch_idx=0 {'tune_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 57000: 'tune_epoch_acc' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores at end of epoch 14:\n",
      "{'AUC': 0.3098, 'F1': 0.5116, 'epoch_acc': 0.5116, 'last_F1': 0.5116}\n",
      "Inside Model.training_step method, batch_idx=0 {'train_loss': 0.0833, 'loss': 0.0833}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8b6633853b54f11910bae514e26f1e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Model.validation_step method, batch_idx=0 {'tune_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, global step 60800: 'tune_epoch_acc' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores at end of epoch 15:\n",
      "{'AUC': 0.3117, 'F1': 0.5152, 'epoch_acc': 0.5152, 'last_F1': 0.5152}\n",
      "Inside Model.training_step method, batch_idx=0 {'train_loss': 0.026, 'loss': 0.026}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9119f01e448545d08492811bfc553459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Model.validation_step method, batch_idx=0 {'tune_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, global step 64600: 'tune_epoch_acc' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores at end of epoch 16:\n",
      "{'AUC': 0.3047, 'F1': 0.5145, 'epoch_acc': 0.5145, 'last_F1': 0.5145}\n",
      "Inside Model.training_step method, batch_idx=0 {'train_loss': 0.0301, 'loss': 0.0301}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b9c7fb11bda48de8a8d35c559f702e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Model.validation_step method, batch_idx=0 {'tune_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17, global step 68400: 'tune_epoch_acc' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores at end of epoch 17:\n",
      "{'AUC': 0.3092, 'F1': 0.5109, 'epoch_acc': 0.5109, 'last_F1': 0.5109}\n",
      "Inside Model.training_step method, batch_idx=0 {'train_loss': 0.01, 'loss': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6d5f515a2644d9095c82d5f8a8df5ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Model.validation_step method, batch_idx=0 {'tune_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18, global step 72200: 'tune_epoch_acc' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores at end of epoch 18:\n",
      "{'AUC': 0.3057, 'F1': 0.5078, 'epoch_acc': 0.5078, 'last_F1': 0.5078}\n",
      "Inside Model.training_step method, batch_idx=0 {'train_loss': 0.0114, 'loss': 0.0114}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "549a0910c900494285208a665b858488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Model.validation_step method, batch_idx=0 {'tune_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 76000: 'tune_epoch_acc' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores at end of epoch 19:\n",
      "{'AUC': 0.308, 'F1': 0.5139, 'epoch_acc': 0.5139, 'last_F1': 0.5139}\n",
      "Inside Model.training_step method, batch_idx=0 {'train_loss': 0.0126, 'loss': 0.0126}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc28a9f739ab46d4873ab548aa68bc01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Model.validation_step method, batch_idx=0 {'tune_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20, global step 79800: 'tune_epoch_acc' reached 0.51890 (best 0.51890), saving model to 'C:\\\\Users\\\\Nick Marino\\\\Documents\\\\SentenceAx\\\\weights\\\\ex_model\\\\epoch=20_tune_epoch_acc=0.5189.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores at end of epoch 20:\n",
      "{'AUC': 0.3145, 'F1': 0.5189, 'epoch_acc': 0.5189, 'last_F1': 0.5189}\n",
      "Inside Model.training_step method, batch_idx=0 {'train_loss': 0.0724, 'loss': 0.0724}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ce403eae1c34b2fa2a8b276b1581259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Model.validation_step method, batch_idx=0 {'tune_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21, global step 83600: 'tune_epoch_acc' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores at end of epoch 21:\n",
      "{'AUC': 0.3149, 'F1': 0.5162, 'epoch_acc': 0.5162, 'last_F1': 0.5159}\n",
      "Inside Model.training_step method, batch_idx=0 {'train_loss': 0.0028, 'loss': 0.0028}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d3dfb32643c406a837a04c121059470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Model.validation_step method, batch_idx=0 {'tune_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22, global step 87400: 'tune_epoch_acc' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores at end of epoch 22:\n",
      "{'AUC': 0.3118, 'F1': 0.5133, 'epoch_acc': 0.5133, 'last_F1': 0.5133}\n",
      "Inside Model.training_step method, batch_idx=0 {'train_loss': 0.0259, 'loss': 0.0259}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bf12655dbf74c34859e972d4b2da249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Model.validation_step method, batch_idx=0 {'tune_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23, global step 91200: 'tune_epoch_acc' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores at end of epoch 23:\n",
      "{'AUC': 0.3038, 'F1': 0.5116, 'epoch_acc': 0.5116, 'last_F1': 0.5116}\n",
      "Inside Model.training_step method, batch_idx=0 {'train_loss': 0.0246, 'loss': 0.0246}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83de21597a3542d2abb157642ea418c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Model.validation_step method, batch_idx=0 {'tune_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24, global step 95000: 'tune_epoch_acc' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores at end of epoch 24:\n",
      "{'AUC': 0.3108, 'F1': 0.5156, 'epoch_acc': 0.5156, 'last_F1': 0.5156}\n",
      "Inside Model.training_step method, batch_idx=0 {'train_loss': 0.0128, 'loss': 0.0128}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcd469ac04d445a7b79d03f80671088d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Model.validation_step method, batch_idx=0 {'tune_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25, global step 98800: 'tune_epoch_acc' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores at end of epoch 25:\n",
      "{'AUC': 0.3061, 'F1': 0.5124, 'epoch_acc': 0.5124, 'last_F1': 0.5124}\n",
      "Inside Model.training_step method, batch_idx=0 {'train_loss': 0.0008, 'loss': 0.0008}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96f130820f5b42059272ac92d9bd2397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Model.validation_step method, batch_idx=0 {'tune_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26, global step 102600: 'tune_epoch_acc' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores at end of epoch 26:\n",
      "{'AUC': 0.3068, 'F1': 0.5152, 'epoch_acc': 0.5152, 'last_F1': 0.5152}\n",
      "Inside Model.training_step method, batch_idx=0 {'train_loss': 0.0078, 'loss': 0.0078}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a3faeaf0e7940838a0a7f175869008d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Model.validation_step method, batch_idx=0 {'tune_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27, global step 106400: 'tune_epoch_acc' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores at end of epoch 27:\n",
      "{'AUC': 0.3111, 'F1': 0.5156, 'epoch_acc': 0.5156, 'last_F1': 0.5156}\n",
      "Inside Model.training_step method, batch_idx=0 {'train_loss': 0.0072, 'loss': 0.0072}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc893155d6e4458289e71add2aa140ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Model.validation_step method, batch_idx=0 {'tune_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28, global step 110200: 'tune_epoch_acc' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores at end of epoch 28:\n",
      "{'AUC': 0.3064, 'F1': 0.5149, 'epoch_acc': 0.5149, 'last_F1': 0.5145}\n",
      "Inside Model.training_step method, batch_idx=0 {'train_loss': 0.0094, 'loss': 0.0094}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3833b60ea9604809b2e82fd7cb0c8bf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Model.validation_step method, batch_idx=0 {'tune_loss': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29, global step 114000: 'tune_epoch_acc' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores at end of epoch 29:\n",
      "{'AUC': 0.3099, 'F1': 0.5173, 'epoch_acc': 0.5173, 'last_F1': 0.5173}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Restoring states from the checkpoint path at weights/ex_model/epoch=20_tune_epoch_acc=0.5189.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at weights/ex_model/epoch=20_tune_epoch_acc=0.5189.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e68407cc60cc400ba0fe58d8e831a444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                           | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Model.test_step method, batch_idx=0 {'test_loss': 0.0}\n",
      "\n",
      "Scores at end of epoch 0:\n",
      "{'AUC': 0.3084, 'F1': 0.5055, 'epoch_acc': 0.5055, 'last_F1': 0.5055}\n",
      "────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     test_epoch_acc         0.5055000185966492\n",
      "        test_loss                   0.0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────\n",
      "checkpoints: ['weights/ex_model/epoch=20_tune_epoch_acc=0.5189.ckpt']\n"
     ]
    }
   ],
   "source": [
    "main(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
